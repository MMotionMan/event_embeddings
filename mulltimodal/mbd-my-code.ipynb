{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import hf_hub_download \n\nhf_hub_download(repo_id=\"ai-lab/MBD-mini\", filename=\"ptls.tar.gz\", repo_type=\"dataset\", local_dir=\"/kaggle/working/\")\nhf_hub_download(repo_id=\"ai-lab/MBD-mini\", filename=\"targets.tar.gz\", repo_type=\"dataset\", local_dir=\"/kaggle/working/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:19:52.656656Z","iopub.execute_input":"2025-02-13T20:19:52.656984Z","iopub.status.idle":"2025-02-13T20:20:26.999189Z","shell.execute_reply.started":"2025-02-13T20:19:52.656960Z","shell.execute_reply":"2025-02-13T20:20:26.998376Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ptls.tar.gz:   0%|          | 0.00/1.40G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3355ed1b5bf046bf98bb2c24c5abecb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"targets.tar.gz:   0%|          | 0.00/7.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32cc70cd7d79443a93600e53b1530151"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/targets.tar.gz'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:20:27.000554Z","iopub.execute_input":"2025-02-13T20:20:27.000923Z","iopub.status.idle":"2025-02-13T20:20:32.832676Z","shell.execute_reply.started":"2025-02-13T20:20:27.000888Z","shell.execute_reply":"2025-02-13T20:20:32.831585Z"}},"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.9.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.11.9)\nRequirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.2)\nRequirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.1+cu121)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.1)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.67.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\nRequirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.0.post0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.10)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\nDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.5.0.post0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"79f2120f8d4212aceb2c60b3c89a1b6727c19cff\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:20:32.834578Z","iopub.execute_input":"2025-02-13T20:20:32.834837Z","iopub.status.idle":"2025-02-13T20:20:41.602838Z","shell.execute_reply.started":"2025-02-13T20:20:32.834812Z","shell.execute_reply":"2025-02-13T20:20:41.601605Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtoly-kiri4enko\u001b[0m (\u001b[33mbstu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!pip install pyspark\n!pip install pytorch-lifestream","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:20:41.604537Z","iopub.execute_input":"2025-02-13T20:20:41.604989Z","iopub.status.idle":"2025-02-13T20:20:57.927471Z","shell.execute_reply.started":"2025-02-13T20:20:41.604964Z","shell.execute_reply":"2025-02-13T20:20:57.926300Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\nRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\nCollecting pytorch-lifestream\n  Downloading pytorch-lifestream-0.6.0.tar.gz (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.1.3)\nCollecting hydra-core>=1.1.2 (from pytorch-lifestream)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.26.4)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.3.0)\nRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (17.0.0)\nRequirement already satisfied: pytorch-lightning>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.5.0.post0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.2.2)\nRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.5.1+cu121)\nRequirement already satisfied: torchmetrics>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.6.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (4.47.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2.4.1)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->pytorch-lifestream) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2024.2)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.67.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2024.9.0)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (0.11.9)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.16.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.12.0->pytorch-lifestream) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.27.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.4.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (3.11.10)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (75.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-lifestream) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lifestream) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.5->pytorch-lifestream) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.5->pytorch-lifestream) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2024.12.14)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.18.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pytorch-lifestream\n  Building wheel for pytorch-lifestream (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pytorch-lifestream: filename=pytorch_lifestream-0.6.0-py3-none-any.whl size=274640 sha256=a779485ba87ed39c0d0c66fd7eb61110c0be3280160356c271707a3049d4058b\n  Stored in directory: /root/.cache/pip/wheels/90/76/b4/0a944bc7c5a69201e4d757cc54886971117a2a581740e7f11d\nSuccessfully built pytorch-lifestream\nInstalling collected packages: hydra-core, pytorch-lifestream\nSuccessfully installed hydra-core-1.3.2 pytorch-lifestream-0.6.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!tar -xf ptls.tar.gz\n!tar -xf targets.tar.gz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:20:57.928790Z","iopub.execute_input":"2025-02-13T20:20:57.929164Z","iopub.status.idle":"2025-02-13T20:21:16.760057Z","shell.execute_reply.started":"2025-02-13T20:20:57.929126Z","shell.execute_reply":"2025-02-13T20:21:16.758786Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport pyspark\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nfrom pyspark.sql import types as T\nimport time\nimport datetime\nfrom ptls.data_load.datasets import ParquetDataset, ParquetFiles\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, ArrayType\nfrom tqdm.notebook import tqdm\nfrom ptls.preprocessing import PysparkDataPreprocessor\nimport pytorch_lightning as pl\nfrom ptls.data_load.datasets import MemoryMapDataset\nfrom ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\nfrom ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\nfrom ptls.frames.coles import CoLESModule\nfrom ptls.frames import PtlsDataModule\nfrom ptls.frames.coles import ColesDataset\nfrom ptls.frames.coles.split_strategy import SampleSlices\nimport torch\nimport numpy as np\nimport pandas as pd\nimport calendar\nfrom glob import glob\nfrom ptls.data_load.utils import collate_feature_dict\n\nfrom ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\nfrom datetime import datetime\nfrom ptls.data_load.padded_batch import PaddedBatch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:16.761327Z","iopub.execute_input":"2025-02-13T20:21:16.761725Z","iopub.status.idle":"2025-02-13T20:21:40.650879Z","shell.execute_reply.started":"2025-02-13T20:21:16.761689Z","shell.execute_reply":"2025-02-13T20:21:40.650117Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"spark_conf = pyspark.SparkConf()\nspark_conf.setMaster(\"local[*]\").setAppName(\"JoinModality\")\nspark_conf.set(\"spark.driver.maxResultSize\", \"16g\")\nspark_conf.set(\"spark.executor.memory\", \"32g\")\nspark_conf.set(\"spark.executor.memoryOverhead\", \"16g\")\nspark_conf.set(\"spark.driver.memory\", \"32g\")\nspark_conf.set(\"spark.driver.memoryOverhead\", \"16g\")\nspark_conf.set(\"spark.cores.max\", \"8\")\nspark_conf.set(\"spark.sql.shuffle.partitions\", \"200\")\nspark_conf.set(\"spark.local.dir\", \"../../spark_local_dir\")\n\n\nspark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\nspark.sparkContext.getConf().getAll()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:40.651837Z","iopub.execute_input":"2025-02-13T20:21:40.652403Z","iopub.status.idle":"2025-02-13T20:21:47.068575Z","shell.execute_reply.started":"2025-02-13T20:21:40.652379Z","shell.execute_reply":"2025-02-13T20:21:47.067488Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[('spark.driver.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.executor.memoryOverhead', '16g'),\n ('spark.driver.memory', '32g'),\n ('spark.driver.maxResultSize', '16g'),\n ('spark.app.name', 'JoinModality'),\n ('spark.driver.port', '41293'),\n ('spark.local.dir', '../../spark_local_dir'),\n ('spark.app.id', 'local-1739478106304'),\n ('spark.executor.id', 'driver'),\n ('spark.app.submitTime', '1739478104355'),\n ('spark.executor.memory', '32g'),\n ('spark.app.startTime', '1739478104617'),\n ('spark.rdd.compress', 'True'),\n ('spark.driver.memoryOverhead', '16g'),\n ('spark.executor.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.serializer.objectStreamReset', '100'),\n ('spark.cores.max', '8'),\n ('spark.sql.shuffle.partitions', '200'),\n ('spark.master', 'local[*]'),\n ('spark.submit.pyFiles', ''),\n ('spark.submit.deployMode', 'client'),\n ('spark.driver.host', 'ee0c230c79bf'),\n ('spark.ui.showConsoleProgress', 'true')]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"spark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:47.071787Z","iopub.execute_input":"2025-02-13T20:21:47.072054Z","iopub.status.idle":"2025-02-13T20:21:48.450479Z","shell.execute_reply.started":"2025-02-13T20:21:47.072028Z","shell.execute_reply":"2025-02-13T20:21:48.449405Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7ba8dd091d80>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://ee0c230c79bf:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>JoinModality</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"!mkdir /kaggle/working/mm_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:48.452398Z","iopub.execute_input":"2025-02-13T20:21:48.452712Z","iopub.status.idle":"2025-02-13T20:21:48.600690Z","shell.execute_reply.started":"2025-02-13T20:21:48.452687Z","shell.execute_reply":"2025-02-13T20:21:48.599313Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"TRX_DATA_PATH = '/kaggle/working/ptls/trx/'\nGEO_DATA_PATH = '/kaggle/working/ptls/geo/'\nDIAL_DATA_PATH = '/kaggle/working/ptls/dialog/'\n\nMM_DATA_PATH = '/kaggle/working/mm_dataset'\nMMT_DATA_PATH = '/kaggle/working/mm_dataset_supervised'\n\nTARGETS_DATA_PATH = '/kaggle/working/targets/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:48.602008Z","iopub.execute_input":"2025-02-13T20:21:48.602361Z","iopub.status.idle":"2025-02-13T20:21:48.607749Z","shell.execute_reply.started":"2025-02-13T20:21:48.602304Z","shell.execute_reply":"2025-02-13T20:21:48.606687Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def rename_col(df, prefix, col_id='client_id'):\n    new_column_names = [f\"{prefix}_{col}\" for col in df.columns if col != col_id]\n    old_column_names = [col for col in df.columns if col != col_id]\n    for old_col, new_col in zip(old_column_names, new_column_names):\n        df = df.withColumnRenamed(old_col, new_col)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:48.608946Z","iopub.execute_input":"2025-02-13T20:21:48.609309Z","iopub.status.idle":"2025-02-13T20:21:48.624752Z","shell.execute_reply.started":"2025-02-13T20:21:48.609273Z","shell.execute_reply":"2025-02-13T20:21:48.623615Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from ptls.preprocessing import PysparkDataPreprocessor\nfrom pyspark.sql.functions import explode, col\n\n# preprocessor_dial = PysparkDataPreprocessor(\n#     col_id='client_id',\n#     col_event_time='event_time',\n#     cols_identity=['embedding']\n# )\n\n# preprocessor_trx = PysparkDataPreprocessor(\n#     col_id='client_id',\n#     col_event_time='event_time',\n#     cols_category=[\n#         'event_type',\n#         'event_subtype',\n#         'src_type11',\n#         'src_type12',\n#         'dst_type11',\n#         'dst_type12',\n#         'src_type21',\n#         'src_type22',\n#         'src_type31',\n#         'src_type32',\n#     ],\n#     cols_identity=['amount', 'currency']\n# )\n\n\nfor fold in tqdm(range(0, 5)):\n    trx = spark.read.parquet(os.path.join(TRX_DATA_PATH, f'fold={fold}'))\n    dial = spark.read.parquet(os.path.join(DIAL_DATA_PATH, f'fold={fold}'))\n    \n    trx = rename_col(trx, 'trx')\n    dial = rename_col(dial, 'dial')\n    \n    mm_dataset = trx.join(dial, on='client_id', how='outer').drop(*['trx_src_type21', 'trx_src_type31'])\n\n    mm_dataset.write.mode('overwrite').parquet(os.path.join(MM_DATA_PATH, f'fold={fold}'))\n    \n    del trx\n    del dial\n    del mm_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:48.626010Z","iopub.execute_input":"2025-02-13T20:21:48.626433Z","iopub.status.idle":"2025-02-13T20:22:57.718277Z","shell.execute_reply.started":"2025-02-13T20:21:48.626392Z","shell.execute_reply":"2025-02-13T20:22:57.716752Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e2dff796c84d2bafc4c29fe8e4639d"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\nfrom ptls.data_load import IterableChain\nfrom datetime import datetime\nfrom ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\nfrom ptls.data_load.iterable_processing.feature_filter import FeatureFilter\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\nimport torch\nfrom functools import partial\nfrom torch.utils.data import DataLoader\nfrom ptls.data_load.padded_batch import PaddedBatch\nfrom ptls.data_load.utils import collate_feature_dict\nfrom tqdm import tqdm\n\n\nclass TargetToTorch(IterableProcessingDataset):\n    def __init__(self, col_target):\n        super().__init__()\n        self.col_target = col_target\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features[self.col_target] = np.stack(np.array(features[self.col_target]))\n            features[self.col_target] = torch.tensor(features[self.col_target])\n            yield features\n\nclass DeleteNan(IterableProcessingDataset):\n    def __init__(self, col_name):\n        super().__init__()\n        self.col_name = col_name\n    \n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            if features[self.col_name] is not None:\n                yield features\n\n\nclass DialToTorch(IterableProcessingDataset):\n    def __init__(self, col_time, col_embeds):\n        super().__init__()\n        self._year=2022\n        self.col_embeds = col_embeds\n        self.col_time = col_time\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n            if features[self.col_time] is None:\n                features[self.col_time] = torch.tensor([0])\n            if features[self.col_embeds] is None:\n                features[self.col_embeds] = torch.zeros(768)\n            \n            for key, tens in features.items():\n                if key == self.col_embeds:\n                    features[key] = torch.tensor(tens.tolist())\n\n            yield features\n\nclass GetSplit(IterableProcessingDataset):\n    def __init__(\n        self,\n        start_month,\n        end_month,\n        year=2022,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self.start_month = start_month\n        self.end_month = end_month\n        self._year = year\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            for month in range(self.start_month, self.end_month+1):\n                features = rec[0] if type(rec) is tuple else rec\n                features = features.copy()\n                \n                if month == 12:\n                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n                else:\n                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n                    \n                year_event_time = datetime(self._year, 1, 1).timestamp()\n                \n                mask = features[self._col_time] < month_event_time\n                \n                for key, tensor in features.items():\n                    if key.startswith('target'):\n                        features[key] = tensor[month - 1].tolist()    \n                    elif key != self._col_id:\n                        features[key] = tensor[mask] \n                            \n                features[self._col_id] += '_month=' + str(month)\n\n                yield features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:22:57.719681Z","iopub.execute_input":"2025-02-13T20:22:57.720071Z","iopub.status.idle":"2025-02-13T20:22:57.735371Z","shell.execute_reply.started":"2025-02-13T20:22:57.720033Z","shell.execute_reply":"2025-02-13T20:22:57.734193Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from ptls.data_load.datasets import ParquetDataset\nfrom ptls.data_load.iterable_processing import SeqLenFilter\nfrom ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\ntrain = ParquetDataset(\n    data_files=[\n        os.path.join(MM_DATA_PATH, f'fold={0}'),\n        os.path.join(MM_DATA_PATH, f'fold={1}'),\n        os.path.join(MM_DATA_PATH, f'fold={2}')\n    ],\n    i_filters=[\n        DeleteNan('trx_event_time'),\n        DeleteNan('dial_event_time'),\n        SeqLenFilter(min_seq_len=8),\n        ISeqLenLimit(max_seq_len=128),\n        ToTorch(),\n        DialToTorch(col_time='dial_event_time', col_embeds='dial_embedding'),\n        # GetSplit(\n        #     start_month=1,\n        #     end_month=12,\n        #     col_id='client_id'\n        # )\n    ],\n    shuffle_files=True\n)\nvalid = ParquetDataset(\n    data_files=[\n        os.path.join(MM_DATA_PATH, f'fold={3}')\n    ],\n    i_filters=[\n        DeleteNan('trx_event_time'),\n        DeleteNan('dial_event_time'),\n        SeqLenFilter(min_seq_len=8),\n        ISeqLenLimit(max_seq_len=128),\n        ToTorch(),\n        DialToTorch(col_time='dial_event_time', col_embeds='dial_embedding'),\n        # GetSplit(\n        #     start_month=1,\n        #     end_month=12,\n        #     col_id='client_id'\n        # )\n    ],\n    shuffle_files=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:22:57.736310Z","iopub.execute_input":"2025-02-13T20:22:57.736599Z","iopub.status.idle":"2025-02-13T20:22:59.278743Z","shell.execute_reply.started":"2025-02-13T20:22:57.736579Z","shell.execute_reply":"2025-02-13T20:22:59.277856Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"next(iter(train))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:22:59.279712Z","iopub.execute_input":"2025-02-13T20:22:59.279945Z","iopub.status.idle":"2025-02-13T20:23:00.468698Z","shell.execute_reply.started":"2025-02-13T20:22:59.279925Z","shell.execute_reply":"2025-02-13T20:23:00.467769Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-13-35f55d31d8f5>:58: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  features[key] = torch.tensor(tens.tolist())\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'client_id': '000e047a31e50ba35f71c81962b4eb0b9a2d6080cf23a14f91447317dd14c788',\n 'trx_event_time': tensor([1653212321, 1653469669, 1653548495, 1653724632, 1653976903, 1654150142,\n         1654242596, 1655444259, 1655522300, 1655624414, 1655799111, 1655876123,\n         1655882576, 1656039670, 1656138383, 1656223580, 1656596114, 1656605299,\n         1656656156, 1656705147, 1656835511, 1656892428, 1656917458, 1656930561,\n         1657114146, 1657122681, 1657261902, 1657349967, 1657865226, 1657949365,\n         1657988201, 1658211281, 1658817423, 1658964788, 1659005819, 1659316267,\n         1659354706, 1659509120, 1659510035, 1659599566, 1660392982, 1660462969,\n         1660475549, 1660516728, 1660629900, 1660731542, 1660969768, 1661064107,\n         1661065240, 1661074145, 1661143950, 1661590541, 1661668712, 1661856189,\n         1662445888, 1662533357, 1662723283, 1662970676, 1663055511, 1663141321,\n         1663156346, 1663223349, 1663226110, 1663232930, 1663273613, 1663319977,\n         1663486350, 1663750602, 1663828403, 1663846714, 1664007817, 1664010573,\n         1664013461, 1664253922, 1664278749, 1664291361, 1664613045, 1664619391,\n         1664870115, 1665122706, 1665207428, 1665212978, 1665321235, 1665479667,\n         1665661309, 1665663943, 1665732795, 1665808566, 1665921822, 1665987160,\n         1666070875, 1666512632, 1666946338, 1667043016, 1667112319, 1667118975,\n         1667120571, 1667570623, 1667717928, 1668060638, 1668065995, 1668320525,\n         1668579753, 1668667771, 1668758641, 1668773460, 1668934881, 1668986509,\n         1669020449, 1669251283, 1669275221, 1669412404, 1669544967, 1669606973,\n         1669806631, 1669883305, 1670049538, 1670058901, 1670311589, 1670362676,\n         1670406065, 1670655143, 1670668294, 1671189652, 1671947344, 1672035487,\n         1672377998, 1672381310]),\n 'trx_amount': tensor([6.3919e+03, 1.4296e+03, 2.0671e+04, 2.5652e+03, 9.3705e+04, 6.7648e+04,\n         3.0200e+04, 4.0092e+03, 1.5228e+04, 8.3436e+04, 2.8736e+04, 7.3650e+04,\n         2.1308e+04, 4.2219e+04, 8.0919e+04, 4.6114e+04, 3.7267e+04, 8.0842e+02,\n         1.5894e+05, 6.4381e+01, 4.4583e+03, 5.3091e+00, 2.6597e+04, 2.2346e+04,\n         1.4298e+04, 1.8810e+02, 4.9375e+04, 7.0010e+03, 4.2292e+04, 2.6176e+04,\n         5.4950e+04, 9.1607e+03, 1.6035e+04, 2.5185e+02, 1.0120e+05, 1.0689e+03,\n         7.1928e+01, 2.6624e+04, 1.0425e+05, 2.4688e+04, 1.3536e+04, 6.0703e+04,\n         5.9357e+02, 7.7135e+02, 3.8689e+04, 2.5791e+03, 7.4977e+04, 5.6034e+04,\n         3.8590e+04, 5.9043e+03, 3.3470e+04, 4.1621e+04, 3.8844e+03, 1.2636e+05,\n         8.9189e+04, 5.8182e+03, 4.1468e+01, 9.2811e+03, 1.1402e+04, 7.1360e+03,\n         1.4857e+03, 6.7445e+03, 4.8585e+04, 2.3906e+04, 2.9677e+02, 6.7078e+04,\n         1.0924e+03, 5.2679e+04, 9.8891e+03, 1.0825e+04, 1.9272e+04, 1.3035e+04,\n         2.7241e+04, 1.8884e+04, 9.9929e+04, 5.8841e+04, 2.5435e+04, 2.7911e+03,\n         6.5707e+04, 4.1527e+04, 9.2060e+03, 1.0081e+04, 1.8242e+05, 2.8697e+03,\n         2.9688e+03, 7.7375e+04, 3.2083e+04, 7.8190e+04, 2.4567e+04, 5.0677e+04,\n         1.5648e+04, 5.1399e+04, 1.3210e+05, 1.1278e+04, 3.5150e+04, 3.7900e+04,\n         7.0968e+03, 2.2394e+03, 3.7842e+04, 5.7784e+04, 8.0009e+03, 1.8524e+04,\n         5.2417e+03, 2.0533e+03, 1.5021e+05, 2.1834e+04, 1.4940e+05, 1.0176e+01,\n         8.4687e+04, 1.4291e+04, 1.6848e+03, 7.7983e+04, 1.8058e+03, 5.6838e+04,\n         9.0854e+04, 1.1935e+04, 1.7963e+04, 2.7675e+03, 1.0058e+05, 2.9027e+04,\n         4.7834e+03, 1.4171e+04, 2.4258e+04, 1.0442e+05, 6.6954e+04, 1.1254e+05,\n         6.3890e+04, 3.7296e+04]),\n 'trx_event_type': tensor([ 1, 11,  1, 11,  1, 11, 11, 11, 11,  1,  1,  1,  1,  1,  1,  1,  1, 14,\n          1,  7,  1,  3,  1,  1, 11,  7,  1,  1, 11,  1, 14,  1,  1, 14,  1, 12,\n          1,  1,  1, 11,  1,  1, 12, 23, 11, 24,  1,  1,  1,  1,  1,  1, 24,  1,\n          1,  1,  9, 11, 11, 11, 14,  1, 11, 11, 23,  1,  1,  1,  1,  1, 11,  1,\n          1, 11,  1,  1,  1,  1,  1, 11, 11,  1,  1,  1, 11,  1,  1,  1, 11,  1,\n         11,  1,  1,  1,  1,  1,  1, 11,  1,  1,  1,  1, 11,  1,  1,  1,  1, 20,\n          1,  7,  1,  7,  9,  1,  1,  1,  1,  1, 11,  7,  1, 11,  1,  1, 11,  1,\n          1,  1], dtype=torch.int32),\n 'trx_event_subtype': tensor([ 1, 12,  1, 12,  1, 12, 12, 12, 12,  1,  1,  1,  1,  1,  1,  1,  1, 13,\n          1,  7,  1, 10,  1,  1, 12,  7,  1,  1, 12,  1, 13,  1,  1, 13,  1, 10,\n          1,  1,  1, 12,  1,  1, 10, 28, 12, 25,  1,  1,  1,  1,  1,  1, 25,  1,\n          1,  1,  9, 12, 12, 12, 13,  1, 12, 12, 28,  1,  1,  1,  1,  1, 12,  1,\n          1, 12,  1,  1,  1,  1,  1, 12, 12,  1,  1,  1, 12,  1,  1,  1, 12,  1,\n         12,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1, 12,  1,  1,  1,  1, 21,\n          1,  7,  1,  7,  9,  1,  1,  1,  1,  1, 12,  7,  1, 12,  1,  1, 12,  1,\n          1,  1], dtype=torch.int32),\n 'trx_currency': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32),\n 'trx_src_type11': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  5,\n          1,  1,  1,  3,  1,  1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  5,  1,  3,\n          1,  1,  1,  1,  1,  1,  3, 12,  1,  5,  1,  1,  1,  1,  1,  1,  5,  1,\n          1,  1,  3,  1,  1,  1,  5,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,\n          1,  4,  1,  4,  3,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,  1,  1,\n          1,  1], dtype=torch.int32),\n 'trx_src_type12': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10,\n          1,  1,  1, 11,  1,  1,  1,  1,  1,  1,  1,  1, 10,  1,  1, 10,  1, 16,\n          1,  1,  1,  1,  1,  1, 16, 26,  1, 18,  1,  1,  1,  1,  1,  1, 10,  1,\n          1,  1, 11,  1,  1,  1, 10,  1,  1,  1, 26,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 42,\n          1, 42,  1, 42, 11,  1,  1,  1,  1,  1,  1, 42,  1,  1,  1,  1,  1,  1,\n          1,  1], dtype=torch.int32),\n 'trx_dst_type11': tensor([ 1,  2,  1,  2,  1,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  8,\n          1,  4,  2,  3,  1,  1,  2,  4,  1,  1,  2,  1,  8,  1,  1,  8,  1,  3,\n          1,  1,  1,  2,  1,  1,  3,  6,  2, 14,  1,  1,  1,  1,  1,  1, 14,  1,\n          1,  1,  1,  2,  2,  2,  8,  1,  2,  2,  6,  1,  1,  1,  1,  1,  2,  1,\n          1,  2,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  2,  1,  1,  1,  2,  1,\n          2,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  2,  1,  1,  1,  1,  4,\n          1,  4,  1,  4,  1,  1,  1,  1,  1,  1,  2,  4,  1,  2,  1,  1,  2,  1,\n          1,  1], dtype=torch.int32),\n 'trx_dst_type12': tensor([ 1,  4,  1,  4,  1,  4,  4,  4,  4,  1,  1,  1,  1,  1,  1,  1,  1,  9,\n          1,  5,  4,  3,  1,  1,  4,  5,  1,  1,  4,  1,  9,  1,  1,  9,  1,  3,\n          1,  1,  1,  4,  1,  1,  3, 15,  4, 32,  1,  1,  1,  1,  1,  1, 31,  1,\n          1,  1,  1,  4,  4,  4,  9,  1,  4,  4, 15,  1,  1,  1,  1,  1,  4,  1,\n          1,  4,  1,  1,  1,  1,  1,  4,  4,  1,  1,  1,  4,  1,  1,  1,  4,  1,\n          4,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,  4,  1,  1,  1,  1,  5,\n          1,  5,  1,  5,  1,  1,  1,  1,  1,  1,  4,  5,  1,  4,  1,  1,  4,  1,\n          1,  1], dtype=torch.int32),\n 'trx_src_type22': tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15], dtype=torch.int32),\n 'trx_src_type32': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3], dtype=torch.int32),\n 'dial_event_time': tensor([1667213771]),\n 'dial_embedding': tensor([[ 0.5861, -0.3624,  0.5261, -0.5438, -0.2685,  0.5052,  0.2834,  0.4190,\n          -0.5069,  0.4342, -0.5596, -0.4165, -0.5128, -0.4477,  0.4005, -0.3564,\n           0.9367,  0.5482,  0.5752, -0.5924, -0.9999, -0.4553, -0.4756, -0.2858,\n          -0.4542,  0.4579, -0.5306,  0.5763,  0.4072, -0.5507,  0.4816, -0.9999,\n           0.8942,  0.8512,  0.5379, -0.2830,  0.4242,  0.4279,  0.5744, -0.5520,\n          -0.4574,  0.3011, -0.5977,  0.4685, -0.5702, -0.5493, -0.2036,  0.5517,\n          -0.2600,  0.5740, -0.3852,  0.3830,  0.6128,  0.2233,  0.5534,  0.5785,\n           0.5214,  0.4274,  0.4434, -0.5086,  0.3429,  0.4888,  0.5443, -0.3093,\n          -0.4718, -0.4604,  0.4748, -0.1131,  0.6723, -0.5209, -0.4090, -0.5265,\n          -0.5291,  0.3209,  0.4723, -0.5205,  0.4216,  0.4908,  0.2925, -0.3250,\n          -0.4206, -0.7109, -0.2802,  0.4853, -0.2644,  0.5333,  0.6922, -0.4806,\n           0.4276, -0.5071,  0.2759,  0.6659, -0.4066,  0.5073, -0.5610, -0.4424,\n          -0.9836, -0.2547, -0.4766, -0.4950, -0.4152,  0.2143, -0.2988, -0.4649,\n          -0.2053, -0.3578,  0.2733,  0.4088, -0.5775,  0.3068,  0.1190, -0.5278,\n          -0.2837,  0.4028, -0.5610,  0.9996, -0.5159,  0.2074,  0.4073, -0.4323,\n          -0.6783,  0.9999,  0.5825, -0.5939,  0.4641,  0.4465, -0.7847,  0.5311,\n           0.2978,  0.5613,  0.2563, -0.5978, -0.5349, -0.3108, -0.9774, -0.4356,\n          -0.2445,  0.2390, -0.7515, -0.3209,  0.4189,  0.7822,  0.4417, -0.4908,\n          -0.3642, -0.5881,  0.5898, -0.4833,  0.9999,  0.8437, -0.4305, -0.4449,\n           0.9742, -0.7187, -0.5570, -0.5667, -0.2908, -0.6654,  0.5696,  0.4708,\n           0.2299, -0.2437, -0.2352, -0.5892,  0.4449, -0.7925, -0.4650,  0.5268,\n           0.4424,  0.4256, -0.2799,  0.5738,  0.2303, -0.4899, -0.3055,  0.5518,\n           0.5547, -0.3024, -0.4425, -0.3010,  0.5755, -0.2540, -0.6094,  0.2545,\n          -0.4039, -0.4536,  0.2732, -0.2794, -0.2134,  0.3605, -0.5655,  0.5051,\n          -0.2373,  0.5691,  0.4781,  0.5484, -0.4919,  0.5442,  0.5184,  0.3190,\n           0.4020,  0.5604,  0.2690,  0.2720, -0.1514, -0.8740,  0.5640,  0.2282,\n           0.5825, -0.4297, -0.4595, -0.5986,  0.7133,  0.5644, -0.4290,  0.5799,\n           0.4677, -0.3966, -0.2379,  0.2750, -0.5737, -0.4735, -0.6723, -0.2290,\n          -0.3731,  0.2899,  0.5666,  0.5472,  0.4719, -0.3473, -0.4044, -0.5750,\n           0.4988,  0.3224, -0.4241,  0.9622, -0.4960,  0.4951, -0.6204, -0.2002,\n           0.5004, -0.4473,  0.3534,  0.9981,  0.5915, -0.5929,  0.2141,  0.5235,\n           0.4127, -0.4852,  0.2814, -0.7078,  0.8895,  0.3350,  0.3309, -0.9999,\n           0.2284,  0.4753,  0.4738,  0.5750,  0.7411,  0.4167,  0.2167,  0.9890,\n          -0.7167, -0.4181, -0.5469, -0.3179, -0.5162, -0.3995, -0.5421, -0.3820,\n          -0.5879, -0.3544, -0.4313,  0.5687,  0.5259, -0.9999,  0.9861,  0.2978,\n          -0.4123,  0.3404,  0.3029, -0.9999,  0.5873, -0.4763, -0.4491,  0.4682,\n          -0.7298, -0.4405,  0.3728,  0.4636,  0.4103,  0.7629,  0.2825,  0.6111,\n          -0.2700,  0.5570,  0.4258, -0.2703,  0.5048, -0.3718,  0.4427,  0.5000,\n          -0.3880,  0.2419, -0.7589,  0.4016,  0.4849,  0.2516,  0.5588, -0.2321,\n           0.5626, -0.9518,  0.4120, -0.4960, -0.5822, -0.2814,  0.5170, -0.3016,\n          -0.4367,  0.2766, -0.3659,  0.9999,  0.3906, -0.2080, -0.5234,  0.5445,\n           0.6110, -0.3485, -0.9085, -0.4407,  0.6765,  0.4597,  0.3374,  0.5293,\n           0.2881,  0.5995, -0.4262, -0.4500,  0.4242, -0.4294,  0.4591, -0.3307,\n          -0.5171,  0.2104, -0.5734, -0.2853, -0.9831,  0.7806,  0.5669,  0.4246,\n           0.3095,  0.2425, -0.4888,  0.7457,  0.5884, -0.2294, -0.2935, -0.5426,\n          -0.4315,  0.2088, -0.3161, -0.6658,  0.3455, -0.8386,  0.4230, -0.3614,\n          -0.2521, -0.5357,  0.4403, -0.9994, -0.5849,  0.5051, -0.4014,  0.2712,\n          -0.4976, -0.3280,  0.4393,  0.3005, -0.3626,  0.5813, -0.2320,  0.2017,\n          -0.2799,  0.2625,  0.9553,  0.7647,  0.4280, -0.4925,  0.2338, -0.5561,\n          -0.5570,  0.7815,  0.2434, -0.5853,  0.4111,  0.2875,  0.2532, -0.5106,\n           0.5841, -0.5237, -0.5965,  0.5017, -0.4832, -0.4999, -0.2648,  0.3524,\n          -0.5423,  0.4453,  0.2294,  0.5007,  0.5513,  0.4337, -0.4489, -0.4622,\n          -0.5752, -0.3996, -0.4013, -0.5934, -0.4120,  0.9996,  0.5252,  0.2767,\n          -0.5822,  0.2652,  0.4778, -0.4421,  0.2774,  0.5234,  0.4770, -0.4274,\n           0.2748,  0.2298,  0.2514,  0.4907,  0.0338,  0.7211, -0.4497,  0.9454,\n          -0.5396, -0.4283, -1.0000,  0.4414,  0.4585, -0.4232, -0.8226,  0.2202,\n          -0.5483,  0.4803, -0.2946,  0.5505,  0.4166, -0.5301,  0.5341, -0.5999,\n           0.9992, -0.3044,  0.4240,  0.2108,  0.2404, -0.2721, -0.2716, -0.4831,\n           0.4300, -0.3174,  0.2606, -0.9973,  0.4881,  0.5759,  0.7420, -0.2572,\n           0.5161, -0.7540,  0.2939, -0.5914, -0.5516, -0.4356,  0.3300, -0.7793,\n           0.3625, -0.4933,  0.2609, -0.4256,  0.5656, -0.5262,  0.4744, -0.5326,\n           0.4802, -0.5954, -0.3592, -0.4900,  0.3575, -0.4759,  0.9999, -0.5396,\n           0.5924, -0.3922,  0.4913, -0.3123,  0.5754,  0.8927, -0.6059,  0.4827,\n           0.4333, -0.8579,  0.2330, -0.3415, -0.9717, -0.5636,  0.9986,  0.5093,\n           0.2845,  0.4733,  0.6804,  0.2854, -0.5031,  0.2972,  0.9878,  0.3563,\n           0.5358,  0.5462,  0.5679, -0.4424, -0.5594,  0.9999,  0.9991,  0.4327,\n           0.5419, -0.3115, -0.4107, -0.4326,  0.4882,  0.4138,  0.5530, -0.4287,\n           0.2921, -0.4961, -0.2932, -0.4018, -0.3691, -0.4958,  0.3219, -0.5835,\n           0.7667,  0.5315,  0.3219,  0.5166,  0.3368,  0.2982, -0.2269, -0.5099,\n           0.4114, -0.4751, -0.3328, -0.7435,  0.3238, -0.9999, -0.5948, -0.5659,\n          -0.5309,  0.4522,  0.2538,  0.3016, -0.5273, -0.4507, -0.5606,  0.4513,\n           0.3730,  0.5839, -0.2082, -0.5607,  0.3272, -0.5936,  0.3578, -0.4358,\n          -0.4962, -0.9318, -0.5993, -0.2422,  0.2430, -0.3114, -0.5108,  0.2959,\n           0.4307,  0.4478, -0.4178,  0.4407, -0.3849,  0.5814,  0.4145,  0.3379,\n           0.4633, -0.4554, -0.5759, -0.3039, -0.5074, -0.5773,  0.2926, -0.4912,\n           0.2819, -0.5535,  0.2609, -0.2721,  0.5611,  0.4309,  0.3468, -0.2912,\n           0.4501,  0.5319, -0.5520,  0.4128,  0.5642, -0.4493, -0.5643,  0.9999,\n           0.5732,  0.5640,  0.5726, -0.4395,  0.3447,  0.4040,  0.5214, -0.2798,\n           0.9855, -0.3078,  0.3875,  0.5641,  0.4376,  0.5540,  0.5006,  0.5910,\n           0.9419,  0.5235,  0.5448,  0.2698,  0.5181,  0.4146,  0.4539,  0.4099,\n           0.4434,  0.5575, -0.3466,  0.2897, -0.2393, -0.5965, -0.5027, -0.2574,\n          -0.2859,  0.4187, -0.3291, -0.4321, -0.3452,  0.4634, -0.3093,  0.2031,\n          -0.5881, -0.2938,  0.6590, -0.5885,  0.2819, -0.5476,  0.4377, -0.9701,\n           0.2608, -0.4429, -0.5208, -0.5894, -0.9575,  0.5381,  0.3447, -0.0984,\n           0.4709, -0.3323,  0.3772, -0.2111, -0.3031,  0.2520, -0.9999,  0.5172,\n           0.5312, -0.7786,  0.4375,  0.3890,  0.2340,  0.5223, -0.4232, -0.5515,\n          -0.2051,  0.2910, -0.2687,  0.1560,  0.4522, -0.4835, -0.4635,  0.3121,\n          -0.4565,  0.2298,  0.4478, -0.3241,  0.5665, -0.4829,  0.5236, -0.3396,\n           0.5484, -0.4436, -0.4746,  0.3098, -0.6513, -0.5569, -0.5650,  0.3187,\n          -0.5536,  0.2527,  0.5840, -0.4280,  0.4811, -0.3620,  0.4924, -0.4173,\n           0.4827, -0.9703, -0.3637, -0.4463, -0.5855,  0.5833,  0.4425,  0.4373,\n           0.2709, -0.5756,  0.2288, -0.5769,  0.5805,  0.5483, -0.5320,  0.5453,\n          -0.4451,  0.4552, -0.5293,  0.2747, -0.9999, -0.5674,  0.4366,  0.5209,\n           0.5447, -0.4315, -0.2932, -0.4023, -0.5586,  0.2090,  0.2897,  0.5759,\n           0.4908,  0.5862, -0.3009, -0.4104,  0.9801, -0.5944,  0.4421,  0.5800,\n           0.4540,  0.9711,  0.5058,  0.4358,  0.3265, -0.5928,  0.5233,  0.5295]])}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from ptls.data_load.feature_dict import FeatureDict\nfrom collections import defaultdict\nfrom functools import reduce\n\n\nclass MultiModalDiffSplitDataset(FeatureDict, torch.utils.data.Dataset):\n    def __init__(\n        self,\n        data,\n        splitters,\n        source_features,\n        col_id,\n        source_names,\n        col_time='event_time',\n        *args, **kwargs\n    ):\n        \"\"\"\n        Dataset for multimodal learning.\n        Parameters:\n        -----------\n        data:\n            concatinated data with feature dicts.\n        splitter:\n            object from from `ptls.frames.coles.split_strategy`.\n            Used to split original sequence into subsequences which are samples from one client.\n        source_features:\n            list of column names \n        col_id:\n            column name with user_id\n        source_names:\n            column name with name sources\n        col_time:\n            column name with event_time\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        \n        self.data = data\n        self.splitters = splitters\n        self.col_time = col_time\n        self.col_id = col_id\n        self.source_names = source_names\n        self.source_features = source_features\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        feature_arrays = self.data[idx]\n        split_data = self.split_source(feature_arrays)\n        # print(self.get_split(split_data))\n        return self.get_splits(split_data)\n    \n    def __iter__(self):\n        for feature_arrays in self.data:\n            split_data = self.split_source(feature_arrays)\n            yield self.get_splits(split_data)\n            \n    def split_source(self, feature_arrays):\n        res = defaultdict(dict)\n        for feature_name, feature_array in feature_arrays.items():\n            if feature_name == self.col_id:\n                res[self.col_id] = feature_array\n            else:\n                source_name, feature_name_transform = self.get_names(feature_name)\n                res[source_name][feature_name_transform] = feature_array\n        for source in self.source_names:\n            if source not in res:\n                res[source] = {source_feature: torch.tensor([]) for source_feature in self.source_features[source]}\n        # print(f'res = {res}')\n        return res\n    \n    def get_names(self, feature_name):\n        idx_del = feature_name.find('_')\n        return feature_name[:idx_del], feature_name[idx_del + 1:]\n    \n    def get_splits(self, feature_arrays):\n        res = {}\n        for source_name, feature_array in feature_arrays.items():\n            if source_name != self.col_id:\n                local_date = feature_array[self.col_time]\n                if source_name not in self.splitters:\n                    continue\n                indexes = self.splitters[source_name].split(local_date)\n                res[source_name] = [{k: v[ix] for k, v in feature_array.items() if self.is_seq_feature(k, v)} for ix in indexes]\n        return res\n    #Вернуть диалоги с транзакциями (без таргетов)\n    def collate_fn(self, batch, return_dct_labels=False):\n        dict_class_labels = get_dict_class_labels(batch)\n        batch = reduce(lambda x, y: {k: x[k] + y[k] for k in x if k in y}, batch)\n        padded_batch = collate_multimodal_feature_dict(batch)\n        if return_dct_labels:\n            return padded_batch, dict_class_labels\n        return padded_batch, dict_class_labels[list(dict_class_labels.keys())[0]]\n\ndef collate_multimodal_feature_dict(batch):\n    res = {}\n    for source, source_batch in batch.items():\n        res[source] = collate_feature_dict(source_batch)\n    # print(f\"multimodal_feature_dict = {res['trx'].payload['event_time'].size()}\")\n    # print()\n    return res\n\ndef collate_feature_dict(batch):\n    new_x_ = defaultdict(list)\n    for i, x in enumerate(batch):\n        for k, v in x.items():\n            new_x_[k].append(v)\n    \n    seq_col = next(k for k, v in batch[0].items() if FeatureDict.is_seq_feature(k, v))\n    lengths = torch.LongTensor([len(rec[seq_col]) for rec in batch])\n    new_x = {}\n    for k, v in new_x_.items():\n        # print(new_x)\n        if type(v[0]) is torch.Tensor:\n            if k.startswith('target'):\n                new_x[k] = torch.stack(v, dim=0)\n            else:\n                new_x[k] = torch.nn.utils.rnn.pad_sequence(v, batch_first=True)\n        elif type(v[0]) is np.ndarray:\n            new_x[k] = v  # list of arrays[object]\n        else:\n            v = np.array(v)\n            if v.dtype.kind == 'i':\n                new_x[k] = torch.from_numpy(v).long()\n            elif v.dtype.kind == 'f':\n                new_x[k] = torch.from_numpy(v).float()\n            elif v.dtype.kind == 'b':\n                new_x[k] = torch.from_numpy(v).bool()\n            else:\n                new_x[k] = v\n    return PaddedBatch(new_x, lengths)\n    \ndef get_dict_class_labels(batch):\n    res = defaultdict(list)\n    for i, samples in enumerate(batch):\n        for source, values in samples.items():\n            for _ in values:\n                res[source].append(i)\n    for source in res:\n        res[source] = torch.LongTensor(res[source])\n    return dict(res)\n\nclass MultiModalDiffSplitIterableDataset(MultiModalDiffSplitDataset, torch.utils.data.IterableDataset):\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.469701Z","iopub.execute_input":"2025-02-13T20:23:00.470039Z","iopub.status.idle":"2025-02-13T20:23:00.487397Z","shell.execute_reply.started":"2025-02-13T20:23:00.470007Z","shell.execute_reply":"2025-02-13T20:23:00.486256Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from ptls.frames.coles import MultiModalIterableDataset\nfrom lightning.pytorch.loggers import WandbLogger\nimport ptls\n\nwandb_logger = WandbLogger(project=\"MBD_My_Code\", log_model=\"all\")\n\ntrainer = pl.Trainer(\n    logger=wandb_logger,\n    max_epochs=50,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=36\n)\n\ndata_module = PtlsDataModule(\n    train_data=MultiModalDiffSplitIterableDataset(\n        data=train,\n        splitters= {\n            'trx': SampleSlices(\n                split_count=3,\n                cnt_min=16,\n                cnt_max=90\n            ),\n            'dial': SampleSlices(\n                split_count=3,\n                cnt_min=2,\n                cnt_max=10\n            ),\n        },\n        source_features={\n            \"trx\": [\n                \"event_type\",\n                \"event_subtype\",\n                \"src_type11\",\n                \"src_type12\",\n                \"dst_type11\",\n                \"dst_type12\",\n                \"src_type22\",\n                \"src_type32\"\n            ],\n            \"dial\": [\n                \"embedding\"\n            ],\n        },\n        col_id='client_id',\n        col_time='event_time',\n        source_names=['trx', 'dial'],\n    ),\n    valid_data=MultiModalDiffSplitIterableDataset(\n        data=valid,\n        splitters= {\n            'trx': SampleSlices(\n                split_count=2,\n                cnt_min=5,\n                cnt_max=64\n            ),\n            'dial': SampleSlices(\n                split_count=2,\n                cnt_min=2,\n                cnt_max=10\n            ),\n            },\n        source_features={\n            \"trx\": [\n                \"event_type\",\n                \"event_subtype\",\n                \"src_type11\",\n                \"src_type12\",\n                \"dst_type11\",\n                \"dst_type12\",\n                \"src_type22\",\n                \"src_type32\"\n            ],\n            \"dial\": [\n                \"embedding\"\n            ],\n        },\n        col_id='client_id',\n        col_time='event_time',\n        source_names=['trx', 'dial'],\n    ),\n    train_batch_size=256,\n    train_num_workers=0,\n    valid_batch_size=256,\n    valid_num_workers=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.488287Z","iopub.execute_input":"2025-02-13T20:23:00.488580Z","iopub.status.idle":"2025-02-13T20:23:00.723741Z","shell.execute_reply.started":"2025-02-13T20:23:00.488557Z","shell.execute_reply":"2025-02-13T20:23:00.722819Z"}},"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ptls.frames.abs_module import ABSModule\nfrom ptls.frames.coles.metric import metric_recall_top_K, outer_cosine_similarity, outer_pairwise_distance\nfrom ptls.frames.coles.losses import ContrastiveLoss\n\ndef first(iterable, default=None):\n    iterator = iter(iterable)\n    return next(iterator, default)\n\n\nclass M3CoLESModule(ABSModule):\n    \"\"\"\n    Multi-Modal Matching\n    Contrastive Learning for Event Sequences ([CoLES](https://arxiv.org/abs/2002.08232))\n\n    Subsequences are sampled from original sequence.\n    Samples from the same sequence are `positive` examples\n    Samples from the different sequences are `negative` examples\n    Embeddings for all samples are calculated.\n    Paired distances between all embeddings are calculated.\n    The loss function tends to make positive distances smaller and negative ones larger.\n\n    Parameters\n        seq_encoder:\n            Model which calculate embeddings for original raw transaction sequences\n            `seq_encoder` is trained by `CoLESModule` to get better representations of input sequences\n        head:\n            Model which helps to train. Not used during inference\n            Can be normalisation layer which make embedding l2 length equals 1\n            Can be MLP as `projection head` like in SymCLR framework.\n        loss:\n            loss object from `ptls.frames.coles.losses`.\n            There are paired and triplet loss. They are required sampling strategy\n            from `ptls.frames.coles.sampling_strategies`. Sampling strategy takes a relevant pairs or triplets from\n            pairwise distance matrix.\n        validation_metric:\n            Keep None. `ptls.frames.coles.metric.BatchRecallTopK` used by default.\n        optimizer_partial:\n            optimizer init partial. Network parameters are missed.\n        lr_scheduler_partial:\n            scheduler init partial. Optimizer are missed.\n\n    \"\"\"\n    def __init__(self,\n                 seq_encoders=None,\n                 mod_names=None,\n                 head=None,\n                 loss=None,\n                 validation_metric=None,\n                 optimizer_partial=None,\n                 lr_scheduler_partial=None):\n        torch.set_float32_matmul_precision('high')\n        if head is None:\n            head = ptls.nn.Head(use_norm_encoder=True)\n\n        if loss is None:\n            loss = ContrastiveLoss(margin=0.5,\n                                   sampling_strategy=HardNegativePairSelector(neg_count=5))\n\n        if validation_metric is None:\n            validation_metric = BatchRecallTopK(K=4, metric='cosine')\n        \n        for k in seq_encoders.keys():\n            if type(seq_encoders[k]) is str:\n                seq_encoders[k] = seq_encoders[seq_encoders[k]]\n                \n        super().__init__(validation_metric,\n                         first(seq_encoders.values()),\n                         loss,\n                         optimizer_partial,\n                         lr_scheduler_partial)\n        \n        self.seq_encoders = torch.nn.ModuleDict(seq_encoders)\n        self._head = head   \n        self.y_h_cache = {'train':[], 'valid': []}\n        \n    @property\n    def metric_name(self):\n        return 'recall_top_k'\n\n    @property\n    def is_requires_reduced_sequence(self):\n        return True\n    \n    def forward(self, x):\n        res = {}\n        \n        for mod_name in x.keys():\n            # print(f'mod_name = {mod_name}')\n            res[mod_name] = self.seq_encoders[mod_name](x[mod_name])\n        # print(f\"forward res = {res['trx'].size()}\")\n        return res\n\n    def shared_step(self, x, y):\n        y_h = self(x)\n        \n        if self._head is not None:\n            y_h_head = {k: self._head(y_h_k) for k, y_h_k in y_h.items()}\n            y_h = y_h_head\n        # print('share_step........')\n        # print(f\"y_h = {y_h['trx'].size()}\")\n        # print(f'y = {y.size()}')\n        # print('-----------------------')\n        return y_h, y\n    \n    def _one_step(self, batch, _, stage):\n        y_h, y = self.shared_step(*batch)\n        y_h_list = list(y_h.values())\n        # print(\"loss count.....\")\n        # print(f\"y_h_list_obj = {y_h_list[0].size()}\")\n        # print(f\"y_true_loss = {torch.cat([y, y]).size()}\")\n        # print(\"--------------------------\")\n        loss = self._loss(torch.cat(y_h_list), torch.cat([y, y]))\n        self.log(f'loss/{stage}', loss.detach())\n        \n        x, y = batch\n        # print(\"step.............\")\n        # print(f\"x_step = {x['trx'].payload['event_time'].size()}\")\n        # print(f\"y_step_true = {y.size()}\")\n        # print(f\"y_h_step = {y_h['trx'].size()}\")\n        # print(\"-----------------------\")\n        for mod_name, mod_x in x.items():\n            self.log(f'seq_len/{stage}/{mod_name}', x[mod_name].seq_lens.float().mean().detach(), prog_bar=True)\n        \n        if stage == \"valid\":\n            n, d = y_h_list[0].shape\n            y_h_concat = torch.zeros((2*n, d), device = y_h_list[0].device)\n            \n            for i in range(2):\n                y_h_concat[range(i,2*n,2)] = y_h_list[i] \n            # print('valid.......')\n            # print(f'y_h_concat = {y_h_concat[0].size}')\n            # print(f\"y_h_valid = {y_h['trx'].size()}\")\n            # print('------------------------')\n            if len(self.y_h_cache[stage]) <= 380:\n                self.y_h_cache[stage].append((y_h_concat.cpu(), {k: y_h_k.cpu() for k, y_h_k in y_h.items()} , \n                                             {k:x_k.seq_lens.cpu() for k, x_k in x.items()})) \n            # print(self.y_h_cache[stage])\n        # print(f'loss = {loss}')\n        return loss\n    \n    def training_step(self, batch, _):\n        return self._one_step(batch, _, \"train\")\n    \n    def validation_step(self, batch, _):\n        return self._one_step(batch, _, \"valid\")\n    \n    def on_validation_epoch_end(self):        \n        #len_intervals = [(0, 10), (10, 20), (20, 30), (30, 40), (40, 60), (60, 80), (80, 120), (120, 160), (160, 240)]\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=100)\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=50)\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=1)\n        \n        \n        del self.y_h_cache[\"valid\"]\n        self.y_h_cache[\"valid\"] = []\n        \n    def log_recall_top_K(self, y_h_cache, len_intervals=None, stage=\"valid\", K=100):\n        y_h = torch.cat([item[0] for item in y_h_cache], dim = 0)\n        y_h_mods = defaultdict(list)\n        seq_lens_dict = defaultdict(list)\n        \n        for item in y_h_cache:\n            for k, emb in item[1].items():\n                y_h_mods[k].append(emb)\n                \n            for k, l in item[2].items():\n                seq_lens_dict[k].append(l)\n        \n        y_h_mods = {k: torch.cat(el, dim=0) for k ,el in y_h_mods.items()}\n        seq_lens_dict = {k: torch.cat(el) for k ,el in seq_lens_dict.items()}\n\n        #n, _ = y_h.shape\n        #y = torch.zeros((n,)).cpu().long()\n        #y[range(0,n,2)] = torch.arange(0, n//2)\n        #y[range(1,n,2)] = torch.arange(0, n//2)\n        #computed_metric = metric_real_recall_top_K(y_h, y, K=100)\n        y_h_bank, y_h_rmb = list(y_h_mods.values())\n        computed_metric_b2r = metric_recall_top_K_for_embs(y_h_bank, y_h_rmb, torch.arange(y_h_rmb.shape[0]), K=K)\n        computed_metric_r2b = metric_recall_top_K_for_embs(y_h_rmb, y_h_bank, torch.arange(y_h_rmb.shape[0]), K=K)\n        \n        if len_intervals != None:\n            for mod, seq_lens in seq_lens_dict.items():\n                for start, end in len_intervals:\n                    mask = ((seq_lens > start) & (seq_lens <= end))\n\n                    if torch.any(mask):\n                        #y_h_filtered = y_h[mask.repeat_interleave(2)]\n                        y_h_bank_filtered = y_h_bank[mask]\n                        y_h_rmb_filtered = y_h_rmb[mask]\n\n                        #y = torch.div(torch.arange(len(y_h_filtered)), 2, rounding_mode='floor')\n                        #recall = metric_real_recall_top_K(y_h_filtered, y, K=100)\n                        recall_r2b = metric_recall_top_K_for_embs(y_h_rmb_filtered, y_h_bank_filtered, torch.arange(y_h_rmb_filtered.shape[0]), K=100)\n                        recall_b2r = metric_recall_top_K_for_embs(y_h_bank_filtered, y_h_rmb_filtered, torch.arange(y_h_rmb_filtered.shape[0]), K=100)\n\n                        #self.log(f\"{mode}/R@100_len_from_{start}_to_{end}\", recall, prog_bar=True)\n                        print(f\"{stage}/{mod}/r2b_R@100_len_from_{start}_to_{end}\", recall_r2b, prog_bar=True)\n                        self.log(f\"{stage}/{mod}/b2r_R@100_len_from_{start}_to_{end}\", recall_b2r, prog_bar=True)\n        \n        #self.log(f\"{mode}/R@100\", computed_metric, prog_bar=True)\n        self.log(f\"{stage}/click2trx_R@{K}\", computed_metric_r2b, prog_bar=True)\n        self.log(f\"{stage}/trx2click_R@{K}\", computed_metric_b2r, prog_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.724803Z","iopub.execute_input":"2025-02-13T20:23:00.725150Z","iopub.status.idle":"2025-02-13T20:23:00.746399Z","shell.execute_reply.started":"2025-02-13T20:23:00.725112Z","shell.execute_reply":"2025-02-13T20:23:00.745615Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from ptls.nn import TrxEncoder, RnnSeqEncoder\nfrom ptls.frames.coles import CoLESModule\nfrom functools import partial\nimport torch\nfrom ptls.frames.coles import MultiModalSortTimeSeqEncoderContainer\nfrom ptls.nn.trx_encoder.encoders import IdentityEncoder\nfrom ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\nfrom ptls.frames.coles.losses import ContrastiveLoss\nfrom ptls.frames.coles.sampling_strategies import HardNegativePairSelector\n\nhead = ptls.nn.Head(\n    input_size=128,\n    use_norm_encoder=True,\n    hidden_layers_sizes=[128, 128],\n    objective=\"regression\",\n    num_classes=128\n)\n\nloss = ptls.frames.coles.losses.SoftmaxLoss()\n\nseq_encoders = {\n    'trx': RnnSeqEncoder(\n        trx_encoder=TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            linear_projection_size=32,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            },\n            numeric_values={\n                'amount': 'log'\n            }\n        ),\n        type='gru',\n        hidden_size=128\n    ),\n    'dial': RnnSeqEncoder(\n        trx_encoder=TrxEncoder(\n            embeddings_noise=0.003,\n            linear_projection_size=32,\n            custom_embeddings={\n                'embedding': IdentityEncoder(768)\n            }\n        ),\n        type='gru',\n        hidden_size=128\n    )\n}\n\noptimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=1,\n    gamma=0.9\n)\n\n# pl_module = M3CoLESModule(\n#     validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n#         K=1,\n#         metric='cosine',\n#     ),\n#     head=head,\n#     seq_encoders=seq_encoders,\n#     loss=loss,\n#     optimizer_partial=optimizer_partial,\n#     lr_scheduler_partial=lr_scheduler_partial\n# )\n\npl_module = M3CoLESModule(\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n        K=1,\n        metric='cosine',\n    ),\n    head=None,\n    seq_encoders=seq_encoders,\n    loss=None,\n    optimizer_partial=optimizer_partial,\n    lr_scheduler_partial=lr_scheduler_partial\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.747659Z","iopub.execute_input":"2025-02-13T20:23:00.748019Z","iopub.status.idle":"2025-02-13T20:23:00.801283Z","shell.execute_reply.started":"2025-02-13T20:23:00.747985Z","shell.execute_reply":"2025-02-13T20:23:00.800613Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"pl_module","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T14:55:52.889510Z","iopub.execute_input":"2025-02-13T14:55:52.889809Z","iopub.status.idle":"2025-02-13T14:55:52.897188Z","shell.execute_reply.started":"2025-02-13T14:55:52.889789Z","shell.execute_reply":"2025-02-13T14:55:52.896475Z"}},"outputs":[{"execution_count":266,"output_type":"execute_result","data":{"text/plain":"M3CoLESModule(\n  (_loss): ContrastiveLoss()\n  (_seq_encoder): RnnSeqEncoder(\n    (trx_encoder): TrxEncoder(\n      (embeddings): ModuleDict(\n        (event_type): NoisyEmbedding(\n          58, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (event_subtype): NoisyEmbedding(\n          59, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (src_type11): NoisyEmbedding(\n          85, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (src_type12): NoisyEmbedding(\n          349, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (dst_type11): NoisyEmbedding(\n          84, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (dst_type12): NoisyEmbedding(\n          417, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (src_type22): NoisyEmbedding(\n          90, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n        (src_type32): NoisyEmbedding(\n          91, 24, padding_idx=0\n          (dropout): Dropout(p=0, inplace=False)\n        )\n      )\n      (custom_embeddings): ModuleDict(\n        (amount): LogScaler()\n      )\n      (custom_embedding_batch_norm): RBatchNorm(\n        (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (linear_projection_head): Linear(in_features=193, out_features=32, bias=True)\n    )\n    (seq_encoder): RnnEncoder(\n      (rnn): GRU(32, 128, batch_first=True)\n      (reducer): LastStepEncoder()\n    )\n  )\n  (_validation_metric): BatchRecallTopK()\n  (seq_encoders): ModuleDict(\n    (trx): RnnSeqEncoder(\n      (trx_encoder): TrxEncoder(\n        (embeddings): ModuleDict(\n          (event_type): NoisyEmbedding(\n            58, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (event_subtype): NoisyEmbedding(\n            59, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (src_type11): NoisyEmbedding(\n            85, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (src_type12): NoisyEmbedding(\n            349, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (dst_type11): NoisyEmbedding(\n            84, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (dst_type12): NoisyEmbedding(\n            417, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (src_type22): NoisyEmbedding(\n            90, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n          (src_type32): NoisyEmbedding(\n            91, 24, padding_idx=0\n            (dropout): Dropout(p=0, inplace=False)\n          )\n        )\n        (custom_embeddings): ModuleDict(\n          (amount): LogScaler()\n        )\n        (custom_embedding_batch_norm): RBatchNorm(\n          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (linear_projection_head): Linear(in_features=193, out_features=32, bias=True)\n      )\n      (seq_encoder): RnnEncoder(\n        (rnn): GRU(32, 128, batch_first=True)\n        (reducer): LastStepEncoder()\n      )\n    )\n    (dial): RnnSeqEncoder(\n      (trx_encoder): TrxEncoder(\n        (embeddings): ModuleDict()\n        (custom_embeddings): ModuleDict(\n          (embedding): IdentityEncoder()\n        )\n        (custom_embedding_batch_norm): RBatchNorm(\n          (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (linear_projection_head): Linear(in_features=768, out_features=32, bias=True)\n      )\n      (seq_encoder): RnnEncoder(\n        (rnn): GRU(32, 128, batch_first=True)\n        (reducer): LastStepEncoder()\n      )\n    )\n  )\n  (_head): Head(\n    (model): Sequential(\n      (0): L2NormEncoder()\n    )\n  )\n)"},"metadata":{}}],"execution_count":266},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.802194Z","iopub.execute_input":"2025-02-13T20:23:00.802477Z","iopub.status.idle":"2025-02-13T20:23:00.806299Z","shell.execute_reply.started":"2025-02-13T20:23:00.802452Z","shell.execute_reply":"2025-02-13T20:23:00.805436Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def metric_real_recall_top_K(X, y, K, num_pos=1, metric='cosine'):\n    \"\"\"\n        calculate metric R@K\n        X - tensor with size n x d, where n - number of examples, d - size of embedding vectors\n        y - true labels\n        N - count of closest examples, which we consider for recall calcualtion\n        metric: 'cosine' / 'euclidean'.\n            !!! 'euclidean' - to slow for datasets bigger than 100K rows\n    \"\"\"\n    K_adjusted = min(X.size(0) - 1, K)\n    \n    res = []\n\n    n = X.size(0)\n    d = X.size(1)\n    max_size = 2 ** 32\n    batch_size = max(1, max_size // (n * d))\n\n    with torch.no_grad():\n\n        for i in range(1 + (len(X) - 1) // batch_size):\n\n            id_left = i * batch_size\n            id_right = min((i + 1) * batch_size, len(y))\n            y_batch = y[id_left:id_right]\n            print(f\"X = {X}\")\n            print(f\"X[] = {X[id_left:id_right]}\")\n            if metric == 'cosine':\n                pdist = -1 * outer_cosine_similarity(X, X[id_left:id_right])\n            elif metric == 'euclidean':\n                pdist = outer_pairwise_distance(X, X[id_left:id_right])\n            else:\n                raise AttributeError(f'wrong metric \"{metric}\"')\n\n            values, indices = pdist.topk(K_adjusted + 1, 0, largest=False)\n\n            y_rep = y_batch.repeat(K_adjusted, 1)\n            res.append((y[indices[1:]] == y_rep).sum().item())\n\n    return np.sum(res) / len(y) / num_pos\n\ndef cosine_similarity_matrix(x1, x2):\n    x1_norm = x1 / x1.norm(dim=1)[:, None]\n    x2_norm = x2 / x2.norm(dim=1)[:, None]\n    return torch.mm(x1_norm, x2_norm.transpose(0, 1))\n\ndef metric_recall_top_K_for_embs(embs_1, embs_2, true_matches, K=100):\n    similarity_matrix = cosine_similarity_matrix(embs_1, embs_2)\n    K_adjusted = min(len(embs_1), K)\n    top_k = similarity_matrix.topk(k=K_adjusted, dim=1).indices\n    correct_matches = 0\n    for i, indices in enumerate(top_k):\n        if true_matches[i] in indices:\n            correct_matches += 1\n    recall_at_k = correct_matches / len(similarity_matrix)\n    return recall_at_k\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.807104Z","iopub.execute_input":"2025-02-13T20:23:00.807324Z","iopub.status.idle":"2025-02-13T20:23:00.822282Z","shell.execute_reply.started":"2025-02-13T20:23:00.807305Z","shell.execute_reply":"2025-02-13T20:23:00.821528Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:23:40.756786Z","iopub.execute_input":"2025-02-12T13:23:40.757121Z","iopub.status.idle":"2025-02-12T13:49:05.798342Z","shell.execute_reply.started":"2025-02-12T13:23:40.757097Z","shell.execute_reply":"2025-02-12T13:49:05.797021Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20250212_132340-cpz1pfii</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/bstu/MBD_My_Code/runs/cpz1pfii' target=\"_blank\">glorious-thunder-3</a></strong> to <a href='https://wandb.ai/bstu/MBD_My_Code' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/bstu/MBD_My_Code' target=\"_blank\">https://wandb.ai/bstu/MBD_My_Code</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/bstu/MBD_My_Code/runs/cpz1pfii' target=\"_blank\">https://wandb.ai/bstu/MBD_My_Code/runs/cpz1pfii</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33504f86781430589c1a02389217e7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b4114b85de47028bb6e7209f499e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60db138e5bb84acbabbe31a4a4e8dcec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45aba15e2f2e4cacba896c5e741b8dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68277996522b45be874b86920231d175"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26939dfeee94f96b1ca0a1461fecb54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a2a55ebe704bbea52b680a075677e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de9544d147c430db408f65f7e28bbc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a34cc09c8cfa44a0941db8dbd86249cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f86e537d0d43adbabc7b1598bbb3db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6857027714d14a73874fc53f97e1cdc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5752160d0fd14626a9ae24464eb371ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d39e218ce44172a818c9e8746b8570"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0037fe4b1cfd4eacace033f2186c2b69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df7fedf1246340af9b512130d2cd6f0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008253ce68474542bdb58ce1d1b5dccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef04b0a2fe784666851f4bcb29395434"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d6415afdcf4f94aee0ced27df4428b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b795ecdd9504cca9ed62f6e90fdf474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0463700836c04ad09cd756c27aeae9f9"}},"metadata":{}},{"name":"stderr","text":"INFO: \nDetected KeyboardInterrupt, attempting graceful shutdown ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m         )\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mdataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;31m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;31m# refill the consumed batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-073149477800>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_arrays\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0msplit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-35f55d31d8f5>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_embeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                     \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-ab636a42a0fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SubprocessScriptLauncher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sigkill_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"],"ename":"NameError","evalue":"name 'exit' is not defined","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"print(trainer.logged_metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(pl_module.state_dict(), \"embedder.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Downstream Task","metadata":{}},{"cell_type":"markdown","source":"**Get embeddings for last fold**","metadata":{}},{"cell_type":"markdown","source":"**variant 1**","metadata":{}},{"cell_type":"code","source":"inference_dataset = ParquetDataset(\n    data_files=[\n        os.path.join(MM_DATA_PATH, f'fold={4}')\n    ],\n    i_filters=[\n        DeleteNan('trx_event_time'),\n        DeleteNan('dial_event_time'),\n        SeqLenFilter(min_seq_len=1),\n        ISeqLenLimit(max_seq_len=128),\n        ToTorch(),\n        DialToTorch(col_time='dial_event_time', col_embeds='dial_embedding')\n    ],\n    shuffle_files=False\n)\n\ninference_dataset = MultiModalDiffSplitIterableDataset(\n        data=inference_dataset,\n        splitters= {\n            'trx': ptls.frames.coles.split_strategy.NoSplit(),\n            'dial': ptls.frames.coles.split_strategy.NoSplit(),\n        },\n        source_features={\n            \"trx\": [\n                \"event_type\",\n                \"event_subtype\",\n                \"src_type11\",\n                \"src_type12\",\n                \"dst_type11\",\n                \"dst_type12\",\n                \"src_type22\",\n                \"src_type32\",\n                \"event_time\"\n            ],\n            \"dial\": [\n                \"embedding\",\n                \"event_time\"\n            ],\n        },\n        col_id='client_id',\n        col_time='event_time',\n        source_names=['trx', 'dial'],\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:07:41.684381Z","iopub.execute_input":"2025-02-12T14:07:41.684732Z","iopub.status.idle":"2025-02-12T14:07:41.691056Z","shell.execute_reply.started":"2025-02-12T14:07:41.684690Z","shell.execute_reply":"2025-02-12T14:07:41.690345Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def collate_fn_multimodal(batch):\n    dict_class_labels = get_dict_class_labels(batch)\n    batch = reduce(lambda x, y: {k: x[k] + y[k] for k in x if k in y}, batch)\n    padded_batch = collate_multimodal_feature_dict(batch)\n    return padded_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:07:43.248939Z","iopub.execute_input":"2025-02-12T14:07:43.249239Z","iopub.status.idle":"2025-02-12T14:07:43.254514Z","shell.execute_reply.started":"2025-02-12T14:07:43.249216Z","shell.execute_reply":"2025-02-12T14:07:43.253681Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nembeddings_dataloader = DataLoader(\n    inference_dataset, \n    collate_fn=partial(collate_fn_multimodal),\n    shuffle=False,\n    num_workers=0,\n    batch_size=256\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:07:43.387704Z","iopub.execute_input":"2025-02-12T14:07:43.387993Z","iopub.status.idle":"2025-02-12T14:07:43.392608Z","shell.execute_reply.started":"2025-02-12T14:07:43.387967Z","shell.execute_reply":"2025-02-12T14:07:43.391737Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"next(iter(embeddings_dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:07:45.393227Z","iopub.execute_input":"2025-02-12T14:07:45.393554Z","iopub.status.idle":"2025-02-12T14:07:46.553608Z","shell.execute_reply.started":"2025-02-12T14:07:45.393528Z","shell.execute_reply":"2025-02-12T14:07:46.552681Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'trx': <ptls.data_load.padded_batch.PaddedBatch at 0x7acfa978b640>,\n 'dial': <ptls.data_load.padded_batch.PaddedBatch at 0x7acfa97891e0>}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"inference_embeddings = trainer.predict(pl_module, embeddings_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_embeddings[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:07:59.939498Z","iopub.status.idle":"2025-02-12T14:07:59.939740Z","shell.execute_reply":"2025-02-12T14:07:59.939640Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**variant 2**","metadata":{}},{"cell_type":"markdown","source":"# Getting targets","metadata":{}},{"cell_type":"code","source":"TARGETS_DATA_PATH = '/kaggle/working/targets/'\n\npreprocessor_target = PysparkDataPreprocessor(\n    col_id=\"client_id\",\n    col_event_time=\"mon\",\n    event_time_transformation=\"dt_to_timestamp\",\n    cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.823108Z","iopub.execute_input":"2025-02-13T20:23:00.823431Z","iopub.status.idle":"2025-02-13T20:23:00.839052Z","shell.execute_reply.started":"2025-02-13T20:23:00.823407Z","shell.execute_reply":"2025-02-13T20:23:00.838396Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"targets = spark.read.parquet(os.path.join(TARGETS_DATA_PATH , f'fold={fold}'))\nmmt_dataset = spark.read.parquet(os.path.join(MM_DATA_PATH , f'fold={fold}'))\n\ntargets = preprocessor_target.fit_transform(targets).drop(*['event_time' ,'trans_count', 'diff_trans_date'])\nmmt_dataset = mmt_dataset.join(targets, on='client_id', how='left')\nmmt_dataset.write.mode('overwrite').parquet(os.path.join(MMT_DATA_PATH, f'fold={fold}'))\n\ndel mmt_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:23:00.842098Z","iopub.execute_input":"2025-02-13T20:23:00.842377Z","iopub.status.idle":"2025-02-13T20:23:17.831474Z","shell.execute_reply.started":"2025-02-13T20:23:00.842326Z","shell.execute_reply":"2025-02-13T20:23:17.830413Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class MatchingModalities(IterableProcessingDataset):\n    def __init__(\n        self,\n        col_id='client_id',\n        mod1_col_time='trx_event_time',\n        mod2_col_time='dial_event_time',\n        mod1_name='trx',\n        mod2_name='dial'\n    ):\n        super().__init__()\n        self.col_id = col_id\n        self.mod1_col_time = mod1_col_time\n        self.mod2_col_time = mod2_col_time\n        self.mod1_name=mod1_name\n        self.mod2_name=mod2_name\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n            all_event_time, _ = torch.sort(torch.cat((features[self.mod1_col_time], features[self.mod2_col_time])))\n            mod1_mask = torch.isin(all_event_time, features[self.mod1_col_time])\n            mod2_mask = torch.isin(all_event_time, features[self.mod2_col_time])\n            for key, tens in features.items():\n                if key.startswith(self.mod1_name) and key != self.mod1_col_time:\n                    indices = torch.where(~mod1_mask)[0].tolist()\n                    result = []\n                    for i in range(len(mod1_mask)):\n                        if i in indices:\n                            result.append(0)\n                        if i < len(tens):\n                            result.append(tens[i])\n                    features[key] = torch.tensor(result, dtype=features[key].dtype)\n                    # print(f'mod1_size = {features[key].size()}')\n                elif key.startswith(self.mod2_name) and key != self.mod2_col_time:\n                    indices = torch.where(~mod2_mask)[0].tolist()\n                    # print(indices)\n                    result = []\n                    for i in range(len(mod2_mask)):\n                        if i in indices:\n                            result.append(torch.Tensor([0 for i in range(768)]))\n                        if i < len(tens):\n                            result.append(tens[i])\n                    # print(len(result))\n                    # print(result)\n                    features[key] = torch.stack(result, dim=0)\n                    # print(f'mod2_size = {features[key].size()}')\n            features[self.mod1_col_time] = all_event_time\n            features[self.mod2_col_time] = all_event_time\n            \n            yield features   \n\nclass MMToTorch(IterableProcessingDataset):\n    def __init__(\n        self,\n        col_id='client_id'\n    ):\n        super().__init__()\n        self.col_id='client_id'\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n            for key, value in features.items():\n                if key != 'client_id':\n                    features[key] = torch.Tensor(value)\n            yield features\n\nclass DialToTorch(IterableProcessingDataset):\n    def __init__(\n        self,\n        embedding_col='dial_embedding'\n    ):\n        super().__init__()\n        self.embedding_col=embedding_col\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n            features[self.embedding_col] = np.stack(features[self.embedding_col], axis=0).astype(np.int32)\n            features[self.embedding_col] = torch.FloatTensor(features[self.embedding_col])\n            yield features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T23:41:37.460374Z","iopub.execute_input":"2025-02-13T23:41:37.460676Z","iopub.status.idle":"2025-02-13T23:41:37.474138Z","shell.execute_reply.started":"2025-02-13T23:41:37.460652Z","shell.execute_reply":"2025-02-13T23:41:37.473162Z"}},"outputs":[],"execution_count":498},{"cell_type":"code","source":"class GetSplit(IterableProcessingDataset):\n    def __init__(\n        self,\n        start_month,\n        end_month,\n        year=2022,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self.start_month = start_month\n        self.end_month = end_month\n        self._year = year\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            for month in range(self.start_month, self.end_month+1):\n                features = rec[0] if type(rec) is tuple else rec\n                features = features.copy()\n                \n                if month == 12:\n                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n                else:\n                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n                    \n                year_event_time = datetime(self._year, 1, 1).timestamp()\n                \n                mask = features[self._col_time] < month_event_time\n                \n                for key, tensor in features.items():\n                    if key.startswith('target'):\n                        features[key] = tensor[month - 1].tolist()    \n                    elif key != self._col_id:\n                        features[key] = tensor[mask] \n                            \n                features[self._col_id] += '_month=' + str(month)\n\n                yield features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T23:41:37.586062Z","iopub.execute_input":"2025-02-13T23:41:37.586412Z","iopub.status.idle":"2025-02-13T23:41:37.594024Z","shell.execute_reply.started":"2025-02-13T23:41:37.586326Z","shell.execute_reply":"2025-02-13T23:41:37.593180Z"}},"outputs":[],"execution_count":499},{"cell_type":"code","source":"from ptls.frames.coles import MultiModalInferenceIterableDataset\n\ndataset_inf = ParquetDataset(\n    data_files=[\n        os.path.join(MMT_DATA_PATH, f'fold={4}')\n    ],\n    i_filters=[\n        DeleteNan('trx_event_time'),\n        DeleteNan('dial_event_time'),\n        # SeqLenFilter(min_seq_len=1),\n        # ISeqLenLimit(max_seq_len=128),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch(),\n        # MMToTorch('client_id'),\n        DialToTorch(),\n        MatchingModalities(\n            col_id='client_id',\n            mod1_col_time='trx_event_time',\n            mod2_col_time='dial_event_time'\n        ),\n        GetSplit(\n            start_month=1,\n            end_month=12,\n            col_id='client_id',\n            col_time='trx_event_time'\n        )\n    ],\n    shuffle_files=False\n)\n\ndataset_inf = MultiModalInferenceIterableDataset(\n        data=dataset_inf,\n        source_features={\n            \"trx\": [\n                \"event_type\",\n                \"event_subtype\",\n                \"src_type11\",\n                \"src_type12\",\n                \"dst_type11\",\n                \"dst_type12\",\n                \"src_type22\",\n                \"src_type32\"\n            ],\n            \"dial\": [\n                \"embedding\"\n            ],\n        },\n        col_id='client_id',\n        col_time='event_time',\n        source_names=['trx', 'dial'],\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T23:41:37.676754Z","iopub.execute_input":"2025-02-13T23:41:37.677043Z","iopub.status.idle":"2025-02-13T23:41:37.683235Z","shell.execute_reply.started":"2025-02-13T23:41:37.677019Z","shell.execute_reply":"2025-02-13T23:41:37.682372Z"}},"outputs":[],"execution_count":500},{"cell_type":"code","source":"next(iter(dataset_inf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T23:41:37.817907Z","iopub.execute_input":"2025-02-13T23:41:37.818191Z","iopub.status.idle":"2025-02-13T23:41:38.786254Z","shell.execute_reply.started":"2025-02-13T23:41:37.818167Z","shell.execute_reply":"2025-02-13T23:41:38.785321Z"}},"outputs":[{"execution_count":501,"output_type":"execute_result","data":{"text/plain":"{'client_id': ['001755891452af8d541d0466d6995b768904e181a74a65e0adfa7bc45c57475d_month=1'],\n 'trx': [{'event_time': tensor([1611936689, 1612018802, 1612832521, 1613587457, 1613669486, 1614969839,\n           1615293738, 1616354267, 1616585402, 1617910706, 1617995463, 1619289462,\n           1619318787, 1619437601, 1621195367, 1621943545, 1622690253, 1622748925,\n           1623197504, 1623491185, 1623717871, 1624739375, 1625043408, 1625479774,\n           1628078533, 1628264749, 1629393621, 1629914943, 1630241533, 1630960006,\n           1631639042, 1631820719, 1631867063, 1633392592, 1633424276, 1633581407,\n           1633904143, 1634178802, 1634222704, 1634402064, 1634402754, 1634716867,\n           1634750013, 1635441875, 1637454702, 1637952046, 1638550048, 1639297932,\n           1639639847, 1640266108, 1640626342, 1642272787, 1642360376]),\n   'amount': tensor([5.9647e+02, 3.1160e+05, 6.2832e+02, 1.3094e+02, 2.3825e+02, 3.9268e+02,\n           1.9584e+05, 6.8911e+01, 2.5653e+05, 2.3097e+01, 6.5942e+01, 3.5246e+02,\n           3.6777e+03, 0.0000e+00, 1.6971e+01, 2.2842e+05, 1.2833e+04, 9.0352e+01,\n           2.2275e+05, 3.0318e+03, 4.1970e+03, 9.3564e+01, 7.4403e+02, 6.4247e+02,\n           0.0000e+00, 3.4581e+05, 9.3495e+01, 2.0534e+02, 2.4540e+05, 2.3412e+02,\n           2.1592e+02, 1.0377e+01, 4.9970e+02, 4.2596e+03, 1.2815e+04, 5.9536e+02,\n           2.1581e+01, 3.1576e+03, 2.9303e+05, 1.5551e+02, 5.4054e+00, 3.8787e+04,\n           1.5973e+02, 2.9964e+02, 7.1177e+02, 3.9514e+00, 4.4344e+02, 2.7321e+05,\n           1.0055e+04, 2.2024e+05, 3.4442e+02, 2.5337e+02, 9.8461e+01]),\n   'event_type': tensor([ 3,  1,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3,  3,  0,  3,  1,  3,  3,\n            1,  3,  3,  3,  3,  3,  0,  1,  3,  3,  1,  3,  3,  3,  3, 12,  3,  3,\n           23, 14,  1, 12,  3,  1, 14,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3],\n          dtype=torch.int32),\n   'event_subtype': tensor([ 3,  1,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3,  3,  0,  3,  1,  3,  3,\n            1,  3,  3,  3,  3,  3,  0,  1,  3,  3,  1,  3,  3,  3,  3, 10,  3,  3,\n           28, 13,  1, 10,  3,  1, 13,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3],\n          dtype=torch.int32),\n   'currency': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1], dtype=torch.int32),\n   'src_type11': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,\n            1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  3,  1,  1,\n           12,  5,  1,  3,  1,  1,  5,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n          dtype=torch.int32),\n   'src_type12': tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  0,  4,  4,  4,  4,\n            4,  4,  4,  4,  4,  4,  0,  4,  4,  4,  4,  4,  4,  4,  4, 16,  4,  4,\n           62, 10,  4, 16,  4,  4, 10,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n          dtype=torch.int32),\n   'dst_type11': tensor([ 3,  1,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3,  3,  0,  3,  1,  3,  3,\n            1,  3,  3,  3,  3,  3,  0,  1,  3,  3,  1,  3,  3,  3,  6,  3, 18,  6,\n            6,  8,  1,  3,  3,  1,  8,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3],\n          dtype=torch.int32),\n   'dst_type12': tensor([ 3,  1,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3,  3,  0,  3,  1,  3,  3,\n            1,  3,  3,  3,  3,  3,  0,  1,  3,  3,  1,  3,  3,  3, 15,  3, 73, 15,\n           15,  9,  1,  3,  3,  1,  9,  3,  3,  3,  3,  1,  3,  1,  3,  3,  3],\n          dtype=torch.int32),\n   'src_type22': tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n           0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n           5, 5, 5, 5, 5], dtype=torch.int32),\n   'src_type32': tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,  0, 15, 15, 15, 15,\n           15, 15, 15, 15, 15, 15,  0, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n           15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n          dtype=torch.int32)}],\n 'dial': [{'event_time': tensor([1611936689, 1612018802, 1612832521, 1613587457, 1613669486, 1614969839,\n           1615293738, 1616354267, 1616585402, 1617910706, 1617995463, 1619289462,\n           1619318787, 1619437601, 1621195367, 1621943545, 1622690253, 1622748925,\n           1623197504, 1623491185, 1623717871, 1624739375, 1625043408, 1625479774,\n           1628078533, 1628264749, 1629393621, 1629914943, 1630241533, 1630960006,\n           1631639042, 1631820719, 1631867063, 1633392592, 1633424276, 1633581407,\n           1633904143, 1634178802, 1634222704, 1634402064, 1634402754, 1634716867,\n           1634750013, 1635441875, 1637454702, 1637952046, 1638550048, 1639297932,\n           1639639847, 1640266108, 1640626342, 1642272787, 1642360376]),\n   'embedding': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.],\n           [0., 0., 0.,  ..., 0., 0., 0.]])}],\n 'target': [{'1': 0, '2': 0, '3': 0, '4': 0}]}"},"metadata":{}}],"execution_count":501},{"cell_type":"code","source":"cntr = 0\nfor item in dataset_inf:\n    if cntr > 80 and cntr < 82:\n        print(item)\n        print('---------------------------')\n    if cntr > 82:\n        break\n    cntr += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T23:53:28.321275Z","iopub.execute_input":"2025-02-13T23:53:28.321647Z","iopub.status.idle":"2025-02-13T23:53:29.821380Z","shell.execute_reply.started":"2025-02-13T23:53:28.321619Z","shell.execute_reply":"2025-02-13T23:53:29.820509Z"}},"outputs":[{"name":"stdout","text":"{'client_id': ['00720bf69eb71320337ae0102830206e21eb205482898b8021a05fa4da4913bd_month=10'], 'trx': [{'event_time': tensor([1609582021, 1609584439, 1609610403,  ..., 1667210098, 1667224811,\n        1667230486]), 'amount': tensor([3.6500e+04, 2.0009e+06, 9.2271e+02,  ..., 2.3276e+04, 7.3116e+00,\n        3.0420e+04]), 'event_type': tensor([ 1,  1,  3,  ...,  1, 18, 11], dtype=torch.int32), 'event_subtype': tensor([ 2,  1,  3,  ...,  2, 19, 12], dtype=torch.int32), 'currency': tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32), 'src_type11': tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32), 'src_type12': tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32), 'dst_type11': tensor([ 2,  1,  3,  ...,  2, 12,  1], dtype=torch.int32), 'dst_type12': tensor([20,  1,  3,  ..., 20, 16,  1], dtype=torch.int32), 'src_type22': tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32), 'src_type32': tensor([16, 16, 16,  ..., 16, 16, 16], dtype=torch.int32)}], 'dial': [{'event_time': tensor([1609582021, 1609584439, 1609610403,  ..., 1667210098, 1667224811,\n        1667230486]), 'embedding': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])}], 'target': [{'1': 0, '2': 0, '3': 0, '4': 0}]}\n---------------------------\n","output_type":"stream"}],"execution_count":525},{"cell_type":"code","source":"# from ptls.custom_layers import StatPooling\n# from ptls.nn.seq_step import LastStepEncoder\nfrom itertools import chain\n\nclass InferenceModuleMultimodal(pl.LightningModule):\n    def __init__(self, model, pandas_output=True, drop_seq_features=True, model_out_name='out', col_id = 'epk_id'):\n        super().__init__()\n\n        self.model = model\n        self.pandas_output = pandas_output\n        self.drop_seq_features = drop_seq_features\n        self.model_out_name = model_out_name\n        self.col_id = col_id\n\n    def forward(self, x: PaddedBatch):\n        x, batch_ids, _ = x\n\n        #TODO: Проверить batch_ids == col_id. Проверил, совпадают\n        out = self.model(x)\n        x_out = {self.col_id : batch_ids, self.model_out_name: out}\n        if self.pandas_output:\n            return self.to_pandas(x_out)\n        return x_out\n\n    def to_pandas(self, x):\n        expand_cols = []\n        scalar_features = {}\n        if self.model_out_name in x:\n            for k, v in x[self.model_out_name].items():\n                x[k] = v\n        del x[self.model_out_name]\n        for k, v in x.items():\n            if type(v) is torch.Tensor:\n                v = v.cpu().numpy()\n            if type(v) is list or len(v.shape) == 1:\n                scalar_features[k] = v\n            elif len(v.shape) == 2:\n                expand_cols.append(k)\n            else:\n                scalar_features[k] = None\n\n        dataframes = [pd.DataFrame(scalar_features)]\n        for col in expand_cols:\n            v = x[col].cpu().numpy()\n            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n\n        return pd.concat(dataframes, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T23:44:05.386938Z","iopub.execute_input":"2025-02-13T23:44:05.387361Z","iopub.status.idle":"2025-02-13T23:44:05.399588Z","shell.execute_reply.started":"2025-02-13T23:44:05.387313Z","shell.execute_reply":"2025-02-13T23:44:05.398698Z"}},"outputs":[],"execution_count":512},{"cell_type":"code","source":"def collate_multimodal_feature_dict(batch):\n    res = {}\n    for source, source_batch in batch[0].items():\n        # print(f'source = {source}')\n        # print(f'source_batch = {source_batch}')\n        # print(f'source_batch = {source_batch}')\n        if source_batch[0]['event_time'].size() == (1, 0):\n            for key, value in source_batch[0].items():\n                if key.startswith('dial_emb'):\n                    source_batch[0][key] = torch.zeros((1, 768))\n                elif key.startswith('trx') or key.startswith('dial'):\n                    source_batch[0][key] = torch.zeros(1)\n        res[source] = collate_feature_dict(source_batch)\n    # print(f'res = {res}')\n    # print(f'res_dial = {res[\"dial\"].payload}')\n    return res\n\ndef collate_feature_dict_with_target(batch, col_id='client_id', target_col_names=None):\n    batch_ids = []\n    target_cols = []\n    for sample in batch:\n        batch_ids.append(sample[col_id])\n        del sample[col_id]\n        if target_col_names is not None:\n            for target_col in target_col_names:\n                target_cols.append(sample[target_col])\n                del sample[target_col]\n    padded_batch = collate_multimodal_feature_dict(batch)\n    if target_col_names is not None:\n        return padded_batch, batch_ids, target_cols\n    return padded_batch, batch_ids[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:12:13.809074Z","iopub.execute_input":"2025-02-14T00:12:13.809424Z","iopub.status.idle":"2025-02-14T00:12:13.816925Z","shell.execute_reply.started":"2025-02-14T00:12:13.809392Z","shell.execute_reply":"2025-02-14T00:12:13.816105Z"}},"outputs":[],"execution_count":582},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ncollate_fn = partial(\n    collate_feature_dict_with_target,\n    target_col_names=['target']\n)\n\ninference_dl = DataLoader(\n    dataset=dataset_inf,\n    collate_fn=collate_fn,\n    shuffle=False,\n    num_workers=0,\n    batch_size=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:12:13.989470Z","iopub.execute_input":"2025-02-14T00:12:13.989809Z","iopub.status.idle":"2025-02-14T00:12:13.994933Z","shell.execute_reply.started":"2025-02-14T00:12:13.989785Z","shell.execute_reply":"2025-02-14T00:12:13.994068Z"}},"outputs":[],"execution_count":583},{"cell_type":"code","source":"# a = 0\n# next(iter(inference_dl))\n# b = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:12:14.472634Z","iopub.execute_input":"2025-02-14T00:12:14.472924Z","iopub.status.idle":"2025-02-14T00:12:14.477270Z","shell.execute_reply.started":"2025-02-14T00:12:14.472901Z","shell.execute_reply":"2025-02-14T00:12:14.476314Z"}},"outputs":[],"execution_count":584},{"cell_type":"code","source":"inf_module = InferenceModuleMultimodal(\n    model=pl_module,\n    pandas_output=True,\n    col_id='client_id',\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:12:14.715590Z","iopub.execute_input":"2025-02-14T00:12:14.715891Z","iopub.status.idle":"2025-02-14T00:12:14.720715Z","shell.execute_reply.started":"2025-02-14T00:12:14.715867Z","shell.execute_reply":"2025-02-14T00:12:14.719802Z"}},"outputs":[],"execution_count":585},{"cell_type":"code","source":"cntr = 0\nfor item in inference_dl:\n    if cntr == 162:\n        print(item[0])\n        print(item[0]['dial'].payload)\n        print('---------------------------')\n    if cntr > 200:\n        break\n    cntr += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:12:16.217713Z","iopub.execute_input":"2025-02-14T00:12:16.218029Z","iopub.status.idle":"2025-02-14T00:12:20.491230Z","shell.execute_reply.started":"2025-02-14T00:12:16.218006Z","shell.execute_reply":"2025-02-14T00:12:20.490437Z"}},"outputs":[{"name":"stdout","text":"{'trx': <ptls.data_load.padded_batch.PaddedBatch object at 0x7ba28db5b880>, 'dial': <ptls.data_load.padded_batch.PaddedBatch object at 0x7ba28db580a0>}\n{'event_time': tensor([], size=(1, 0), dtype=torch.int64), 'embedding': tensor([], size=(1, 0, 768))}\n---------------------------\n","output_type":"stream"}],"execution_count":586},{"cell_type":"code","source":"cntr = 0\nfor item in inference_dl:\n    if cntr > 80 and cntr < 82:\n        print(item[0])\n        print(item[0]['trx'].payload)\n        print('---------------------------')\n    if cntr > 82:\n        break\n    cntr += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:11:03.531450Z","iopub.execute_input":"2025-02-14T00:11:03.531780Z","iopub.status.idle":"2025-02-14T00:11:05.462754Z","shell.execute_reply.started":"2025-02-14T00:11:03.531749Z","shell.execute_reply":"2025-02-14T00:11:05.461863Z"}},"outputs":[{"name":"stdout","text":"{'trx': <ptls.data_load.padded_batch.PaddedBatch object at 0x7ba28db5ace0>, 'dial': <ptls.data_load.padded_batch.PaddedBatch object at 0x7ba28db5b880>}\n{'event_time': tensor([[1609472973, 1609728676, 1609818706, 1610101269, 1610874609, 1610937003,\n         1611382291, 1611483166, 1611631739, 1611676093, 1611725759, 1611804497,\n         1612015594, 1612272731, 1612416875, 1612626863, 1612631744, 1613440275,\n         1613793421, 1614043273, 1614064401, 1614157487, 1614305304, 1614508599,\n         1614580173, 1614684499, 1614759315, 1614783413, 1614823600, 1615002125,\n         1616210133, 1616583427, 1616667546, 1616855910, 1616896249, 1616921102,\n         1617095354, 1617124791, 1617245557, 1617614703, 1617620793, 1617720347,\n         1617845307, 1617875986, 1618392354, 1618496647, 1618633599, 1619239094,\n         1619593738, 1620193338, 1620274954, 1620539611, 1620796405, 1621131392,\n         1621745137, 1621931251, 1622013754, 1622177303, 1622182215, 1622186992,\n         1622685050, 1622774474, 1623031552, 1623560899, 1623732972, 1623816519,\n         1624512539, 1624685786, 1624859652, 1624940580, 1625020003, 1625022999,\n         1625375593, 1625555571, 1626421137, 1626579213, 1627191309, 1627271394,\n         1627620939, 1627621453, 1628483848, 1628653473, 1628653608, 1629079717,\n         1629256319, 1629264596, 1630142696, 1630382368, 1630559711, 1630659507,\n         1630976209, 1631768736, 1632044843, 1632118284, 1632218357, 1632298990,\n         1632472244, 1632634211, 1632722831, 1632806967, 1632810571, 1633155670,\n         1633239114, 1633743043, 1633764403, 1634269470, 1634660868, 1634803769,\n         1635141329, 1635182675, 1635230291, 1635311592, 1635471643, 1635480364,\n         1635744743, 1635916567, 1636305884, 1636362828, 1636436904, 1636453052,\n         1636518272, 1637034079, 1637124639, 1637383384, 1637507420, 1637630653,\n         1637902024, 1638025096, 1638334458, 1638334670, 1638411839, 1638935020,\n         1640325416, 1640414558, 1640495674, 1640501191, 1640742607, 1640848662,\n         1641049770, 1642485554, 1642602250, 1642661068, 1643277282, 1643339944,\n         1643782079, 1644423998, 1644832402, 1644896156, 1645608056, 1645608729,\n         1645805073, 1646120144, 1646223404, 1646225366, 1646406425, 1646418985,\n         1646724135, 1647071606, 1647339423, 1647844959, 1647929780, 1648002971,\n         1648165334, 1648431305, 1648486438, 1648573192, 1648650585, 1648709477,\n         1648947673, 1649058374, 1649260192, 1649306597, 1649402624, 1649559588,\n         1649639654, 1650093665, 1650292389, 1650344234, 1650611151, 1650772582,\n         1650859351, 1650865657, 1650937758, 1651038155, 1651109883, 1651120816,\n         1651125457, 1651242734, 1651469995, 1651542651, 1651811151, 1651813881,\n         1651853459, 1651893012, 1652005505, 1652058064, 1652412145, 1652426574,\n         1652461972, 1652590282, 1652592293, 1652709813, 1652973358, 1653202416,\n         1653315298, 1653368288, 1653538883, 1653576726, 1653624074, 1653815391,\n         1653971886, 1654140782, 1654222835, 1654224642, 1654230867, 1654270455,\n         1654394950, 1654398790, 1654535451, 1654574202, 1654707581, 1654751128,\n         1654826085, 1654939147, 1655260185, 1655356409, 1655482707, 1655608354,\n         1656178521, 1656294122, 1656312035, 1656472475, 1656571350, 1656661456,\n         1656741866, 1656964957, 1657052791, 1657163840, 1657257669, 1657337040,\n         1657347687, 1657349835, 1657353447, 1657442220, 1657525009, 1658028546,\n         1658384689, 1658554569, 1658897360, 1659153547]]), 'amount': tensor([[4.0844e+03, 2.4176e+03, 2.0895e+04, 2.5980e+04, 3.5968e+03, 4.9441e+04,\n         6.3725e+01, 4.6443e+02, 1.5014e+04, 2.3809e+02, 4.7435e+04, 5.7913e+03,\n         4.6789e+02, 3.5686e+02, 1.5088e+04, 6.0053e+01, 9.6875e+02, 5.0908e+03,\n         2.0223e+03, 2.2077e+03, 3.1601e+03, 3.3788e+03, 3.0407e+04, 1.5899e+03,\n         4.3982e+02, 1.7253e+04, 5.4167e+01, 2.3705e+02, 6.8061e+03, 2.1976e+04,\n         2.5308e+03, 1.1058e+03, 4.4232e+04, 1.8795e+02, 3.0151e+03, 1.3934e+04,\n         2.9047e+04, 1.0204e+02, 3.6729e+04, 6.4918e+04, 1.3507e+04, 1.9204e+02,\n         1.4827e+04, 2.1111e+03, 4.9362e+03, 2.1471e+02, 6.1703e+04, 3.9321e+03,\n         7.1531e+03, 2.7401e+04, 1.3426e+04, 2.6468e+03, 6.3934e+03, 5.7265e+03,\n         5.0295e+04, 5.7384e+04, 5.4507e+03, 3.2434e+04, 2.2868e+04, 0.0000e+00,\n         1.8218e+03, 6.3111e+04, 6.3577e+03, 2.3401e+05, 0.0000e+00, 1.5598e+03,\n         3.7481e+03, 3.0162e+03, 9.9344e+03, 6.9482e+03, 3.5520e+03, 3.8434e+03,\n         8.6753e+04, 1.0238e+04, 1.0804e+03, 3.0198e+02, 3.7022e+03, 2.7651e+04,\n         1.4912e+04, 1.6691e+03, 1.1642e+02, 3.5430e+03, 0.0000e+00, 1.2410e+03,\n         1.7680e+04, 4.4093e+03, 1.8229e+04, 3.1394e+04, 2.3961e+03, 1.4338e+05,\n         4.2091e+03, 5.1323e+03, 5.4976e+02, 8.0681e+04, 1.3600e+03, 6.7688e+03,\n         6.2930e+03, 3.6227e+03, 1.5720e+03, 8.6388e+02, 1.0551e+04, 2.2924e+04,\n         1.2151e+04, 5.4704e+02, 1.2884e+03, 2.0557e+03, 5.7116e+02, 3.9111e+04,\n         1.6406e+03, 1.8377e+02, 1.2017e+04, 2.9697e+05, 2.4545e+04, 6.7141e+03,\n         5.0824e+02, 1.3222e+04, 6.0856e+02, 7.8552e+02, 2.1313e+04, 2.9760e+04,\n         4.0601e+03, 2.7581e+05, 9.0492e+02, 1.5368e+04, 2.7095e+02, 1.8883e+03,\n         1.3500e+04, 1.4060e+03, 1.0256e+02, 8.4007e+02, 3.1394e+03, 3.2689e+03,\n         5.7052e+02, 2.2109e+04, 1.0465e+04, 1.1835e+03, 3.3664e+04, 2.2554e+03,\n         2.4972e+01, 4.2835e+03, 7.4541e+01, 8.2738e+02, 4.5171e+02, 3.6863e+03,\n         3.2751e+04, 5.5919e-01, 1.4022e+03, 1.3119e+04, 1.9532e+04, 1.0924e+03,\n         6.6116e+02, 1.4501e+03, 6.9142e+03, 2.0757e+03, 1.0922e+03, 9.9228e+02,\n         5.8206e+02, 4.0801e+03, 3.3802e+03, 7.0729e+05, 8.3704e+05, 2.7811e+04,\n         5.2045e+02, 1.3139e+01, 1.4090e+03, 2.8967e+01, 4.3489e+04, 1.1380e+04,\n         2.3999e+04, 8.5825e+02, 8.2814e+02, 1.1594e+04, 5.2048e+04, 1.3033e+05,\n         2.7325e+03, 1.3886e+02, 6.6460e+02, 1.4991e+02, 1.7603e+04, 2.9991e+03,\n         1.7409e+05, 2.0054e+04, 7.6906e+03, 1.1506e+04, 2.0473e+02, 4.2731e+03,\n         3.9993e+04, 8.3188e+02, 1.9396e+04, 1.0160e+03, 1.3586e+05, 1.6607e+03,\n         8.8579e+02, 3.4033e+05, 1.6461e+05, 2.2800e+05, 1.8048e+05, 5.0111e+05,\n         1.0554e+03, 1.4626e+05, 2.0953e+04, 2.0393e+02, 7.8466e+01, 3.3135e+04,\n         3.6380e+02, 2.7211e+05, 3.1605e+04, 1.0455e+03, 3.0594e+04, 3.3706e+03,\n         1.3656e+05, 2.5547e+03, 7.7191e+02, 9.7416e+03, 1.7509e+03, 3.1857e+01,\n         3.2716e+02, 1.8242e+04, 1.2432e+03, 7.3262e+04, 1.1834e+03, 2.2495e+04,\n         6.0346e+03, 1.2168e+03, 1.4485e+04, 7.1604e+01, 0.0000e+00, 6.1963e+02,\n         9.8098e+04, 6.7730e+04, 2.1941e+04, 0.0000e+00, 9.9258e+04, 2.2528e+03,\n         2.3936e+02, 2.9784e+02, 0.0000e+00, 1.3673e+04, 2.5754e+03, 2.1569e+04,\n         4.5571e+03, 3.1060e+03, 1.2298e+05, 7.4373e+03, 2.4247e+03, 3.0593e+04,\n         2.0103e+03, 0.0000e+00, 1.3451e+03, 7.3295e+04]]), 'event_type': tensor([[ 1,  7, 10,  7,  7, 11, 11,  7, 11,  3, 11, 11,  3,  3,  1,  3,  3,  7,\n          7,  7,  1,  7,  7,  7,  3, 10,  1,  3,  1, 10,  1,  7, 11,  3,  1, 10,\n          7,  3, 11, 11,  7,  3,  1,  7,  7,  3, 11,  1,  7,  7,  1,  7,  7,  1,\n          1,  1,  7, 11, 10,  0,  7, 11,  7,  1,  0,  1, 10,  7, 10, 10,  7,  7,\n          2,  1,  7,  3,  1,  2,  7,  7,  3,  7,  0,  7,  7,  7, 10, 11, 10, 11,\n          1,  1,  7,  2,  7,  7,  7,  7,  7,  1, 10,  2,  1,  3,  1,  1,  3,  1,\n          7,  3,  7,  1,  7,  1, 10, 11,  3,  1,  1,  4,  7,  1,  1, 10,  3,  7,\n          7,  3,  7,  7,  1,  7,  7, 10, 10,  7, 11,  7,  3,  7,  3,  7,  7,  1,\n         11, 20,  7, 11, 10,  7, 14,  1,  7,  7, 14,  7,  7, 10,  7,  1,  1,  1,\n          7,  7,  3,  3,  2, 11, 11,  7,  3,  1,  2,  1,  1,  3,  3,  3,  1,  1,\n          1,  1, 10,  1,  7,  7,  1,  3,  1,  7,  4,  7,  3,  4,  4,  4,  1,  1,\n          3,  4,  7,  3,  3,  4,  3,  1,  1,  3, 11,  4,  1,  7,  7, 10,  7,  3,\n          7, 10,  3, 11,  3,  1,  7,  7,  1,  3,  0,  3,  4,  2,  7,  0,  2,  7,\n         23, 12,  0,  1, 14,  4,  1,  2,  2,  7,  7,  1,  1,  0, 10, 11]],\n       dtype=torch.int32), 'event_subtype': tensor([[ 1, 43, 11,  7,  7, 12, 12,  7, 12,  3, 12, 12,  3,  3,  1,  3,  3,  7,\n          7,  7,  1,  7,  7,  7,  3, 11,  1,  3,  1, 11,  1,  7, 12,  3,  1, 11,\n          7,  3, 12, 12,  7,  3,  1,  7,  7,  3, 12,  1,  7,  7,  1,  7,  7,  1,\n          1,  1,  7, 12, 11,  0,  7, 12,  7,  1,  0,  1, 11,  7, 11, 11,  7,  7,\n          2,  1,  7,  3,  1,  2,  7,  7,  3,  7,  0,  7,  7,  7, 11, 12, 11, 12,\n          1,  1,  7,  2,  7,  7,  7,  7,  7,  1, 11,  2,  1,  3,  1,  1,  3,  1,\n          7,  3,  7,  1,  7,  1, 11, 12,  3,  1,  1,  4,  7,  1,  1, 11,  3,  7,\n          7,  3,  7,  7,  1,  7,  7, 11, 11,  7, 12,  7,  3,  7,  3,  7,  7,  1,\n         12, 21,  7, 12, 11,  7, 13,  1,  7,  7, 13,  7,  7, 11,  7,  1,  1,  1,\n          7,  7,  3,  3,  2, 12, 12,  7,  3,  1,  2,  1,  1,  3,  3,  3,  1,  1,\n          1,  1, 11,  1,  7,  7,  1,  3,  1,  7,  4,  7,  3,  4,  4,  4,  1,  1,\n          3,  4,  7,  3,  3,  4,  3,  1,  1,  3, 12,  4,  1,  7,  7, 11,  7,  3,\n          7, 11,  3, 12,  3,  1,  7,  7,  1,  3,  0,  3,  4,  4,  7,  0,  4,  7,\n         28, 10,  0,  1, 13,  4,  1,  4,  4,  7,  7,  1,  1,  0, 11, 12]],\n       dtype=torch.int32), 'currency': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 0, 1, 1]], dtype=torch.int32), 'src_type11': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  5,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,\n         12,  3,  0,  1,  5,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1]],\n       dtype=torch.int32), 'src_type12': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1, 10,  1,  1,  1, 10,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,\n         26, 16,  0,  1, 10,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1]],\n       dtype=torch.int32), 'dst_type11': tensor([[ 1, 16,  4,  4,  4,  1,  1,  4,  1,  3,  1,  1,  3,  3,  1,  3,  3,  4,\n          4,  4,  1,  4,  4,  4,  3,  4,  1,  3,  1,  4,  1,  4,  1,  3,  1,  4,\n          4,  3,  1,  1,  4,  3,  1,  4,  4,  3,  1,  1,  4,  4,  1,  4,  4,  1,\n          1,  1,  4,  1,  4,  0,  4,  1,  4,  1,  0,  1,  4,  4,  4,  4,  4,  4,\n          2,  2,  4,  3,  1,  2,  4,  4,  3,  4,  0,  4,  4,  4,  4,  1,  4,  1,\n          1,  1,  4,  2,  4,  4,  4,  4,  4,  1,  4,  2,  1,  3,  1,  1,  3,  1,\n          4,  3,  4,  1,  4,  1,  4,  1,  3,  1,  1,  2,  4,  1,  1,  4,  3,  4,\n          4,  3,  4,  4,  1,  4,  4,  4,  4,  4,  1,  4,  3,  4,  3,  4,  4,  1,\n          1,  4,  4,  1,  4,  4,  8,  1,  4,  4,  8,  4,  4,  4,  4,  2,  1,  1,\n          4,  4,  3,  3,  2,  1,  1,  4,  3,  1,  2,  1,  1,  3,  3,  3,  1,  1,\n          1,  1,  4,  1,  4,  4,  1,  3,  1,  4,  2,  4,  3,  2,  2,  2,  1,  1,\n          3,  2,  4,  3,  3,  2,  3,  1,  1,  3,  1,  2,  1,  4,  4,  4,  4,  3,\n          4,  4,  3,  1,  3,  1,  4,  4,  1,  3,  0,  3,  2,  2,  4,  0,  2,  4,\n          6,  3,  0,  1,  8,  2,  1,  2,  2,  4,  4,  1,  1,  0,  4,  1]],\n       dtype=torch.int32), 'dst_type12': tensor([[ 1, 25,  5,  5,  5,  1,  1,  5,  1,  3,  1,  1,  3,  3,  1,  3,  3,  5,\n          5,  5,  1,  5,  5,  5,  3,  5,  1,  3,  1,  5,  1,  5,  1,  3,  1,  5,\n          5,  3,  1,  1,  5,  3,  1,  5,  5,  3,  1,  1,  5,  5,  1,  5,  5,  1,\n          1,  1,  5,  1,  5,  0,  5,  1,  5,  1,  0,  1,  5,  5,  5,  5,  5,  5,\n          2,  4,  5,  3,  1,  2,  5,  5,  3,  5,  0,  5,  5,  5,  5,  1,  5,  1,\n          1,  1,  5,  2,  5,  5,  5,  5,  5,  1,  5,  2,  1,  3,  1,  1,  3,  1,\n          5,  3,  5,  1,  5,  1,  5,  1,  3,  1,  1,  2,  5,  1,  1,  5,  3,  5,\n          5,  3,  5,  5,  1,  5,  5,  5,  5,  5,  1,  5,  3,  5,  3,  5,  5,  1,\n          1,  5,  5,  1,  5,  5,  9,  1,  5,  5,  9,  5,  5,  5,  5,  4,  1,  1,\n          5,  5,  3,  3,  2,  1,  1,  5,  3,  1,  2,  1,  1,  3,  3,  3,  1,  1,\n          1,  1,  5,  1,  5,  5,  1,  3,  1,  5,  2,  5,  3,  2,  2,  2,  1,  1,\n          3,  2,  5,  3,  3,  2,  3,  1,  1,  3,  1,  2,  1,  5,  5,  5,  5,  3,\n          5,  5,  3,  1,  3,  1,  5,  5,  1,  3,  0,  3,  2,  2,  5,  0,  2,  5,\n         15,  3,  0,  1,  9,  2,  1,  2,  2,  5,  5,  1,  1,  0,  5,  1]],\n       dtype=torch.int32), 'src_type22': tensor([[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21,  0, 21, 21, 21, 21,  0, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21,  0, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 21, 21, 21,  0, 21, 21, 21, 21,  0, 21, 21,\n         21, 21,  0, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,  0, 21, 21]],\n       dtype=torch.int32), 'src_type32': tensor([[46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46,  0, 46, 46, 46, 46,  0, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46,  0, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46,  0, 46, 46, 46, 46,  0, 46, 46,\n         46, 46,  0, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,  0, 46, 46]],\n       dtype=torch.int32)}\n---------------------------\n","output_type":"stream"}],"execution_count":580},{"cell_type":"code","source":"inf_embeddings = pd.concat(trainer.predict(inf_module, inference_dl))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:03:38.638395Z","iopub.execute_input":"2025-02-14T00:03:38.638699Z","iopub.status.idle":"2025-02-14T00:03:42.453127Z","shell.execute_reply.started":"2025-02-14T00:03:38.638675Z","shell.execute_reply":"2025-02-14T00:03:42.451778Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ac657ff585d4f9db141cb257ca1ff89"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-557-d75b301180d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minf_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minf_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         )\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/prediction_loop.py\u001b[0m in \u001b[0;36m_predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         )\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warning_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict returned None if it was on purpose, ignore this warning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mpredict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36mpredict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;31m# For backwards compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-512-cc2478aaeb0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#TODO: Проверить batch_ids == col_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_id\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_out_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-c68805adedd4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# print(f'mod_name = {mod_name}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_encoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# print(f\"forward res = {res['trx'].size()}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ptls/nn/seq_encoder/containers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_0)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrx_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ptls/nn/seq_encoder/rnn_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_0)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Batch can'not have 0 transactions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# prepare initial state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Batch can'not have 0 transactions"],"ename":"AssertionError","evalue":"Batch can'not have 0 transactions","output_type":"error"}],"execution_count":557},{"cell_type":"code","source":"inf_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:03:10.865264Z","iopub.execute_input":"2025-02-14T00:03:10.865632Z","iopub.status.idle":"2025-02-14T00:03:10.892700Z","shell.execute_reply.started":"2025-02-14T00:03:10.865603Z","shell.execute_reply":"2025-02-14T00:03:10.891766Z"}},"outputs":[{"execution_count":556,"output_type":"execute_result","data":{"text/plain":"                                            client_id  trx_0000  trx_0001  \\\n0   [001755891452af8d541d0466d6995b768904e181a74a6...  0.008138 -0.381437   \n1   [001755891452af8d541d0466d6995b768904e181a74a6...       NaN       NaN   \n2   [001755891452af8d541d0466d6995b768904e181a74a6...       NaN       NaN   \n3   [001755891452af8d541d0466d6995b768904e181a74a6...       NaN       NaN   \n0   [001755891452af8d541d0466d6995b768904e181a74a6...  0.005664 -0.386670   \n..                                                ...       ...       ...   \n3   [0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...       NaN       NaN   \n0   [0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3... -0.135283 -0.453365   \n1   [0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...       NaN       NaN   \n2   [0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...       NaN       NaN   \n3   [0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...       NaN       NaN   \n\n    trx_0002  trx_0003  trx_0004  trx_0005  trx_0006  trx_0007  trx_0008  ...  \\\n0  -0.173643  0.040975  0.350735 -0.012193 -0.084212 -0.249949 -0.015709  ...   \n1        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n2        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n3        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n0  -0.143982  0.031381  0.353962 -0.005376 -0.096481 -0.246804 -0.020569  ...   \n..       ...       ...       ...       ...       ...       ...       ...  ...   \n3        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n0  -0.143856 -0.076178  0.477253  0.147498 -0.073590 -0.125378 -0.055532  ...   \n1        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n2        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n3        NaN       NaN       NaN       NaN       NaN       NaN       NaN  ...   \n\n    dial_0118  dial_0119  dial_0120  dial_0121  dial_0122  dial_0123  \\\n0    0.046680  -0.019130   0.021606   0.069314  -0.032143   0.068159   \n1         NaN        NaN        NaN        NaN        NaN        NaN   \n2         NaN        NaN        NaN        NaN        NaN        NaN   \n3         NaN        NaN        NaN        NaN        NaN        NaN   \n0    0.046680  -0.019130   0.021606   0.069314  -0.032143   0.068159   \n..        ...        ...        ...        ...        ...        ...   \n3         NaN        NaN        NaN        NaN        NaN        NaN   \n0    0.046681  -0.019129   0.021605   0.069314  -0.032143   0.068159   \n1         NaN        NaN        NaN        NaN        NaN        NaN   \n2         NaN        NaN        NaN        NaN        NaN        NaN   \n3         NaN        NaN        NaN        NaN        NaN        NaN   \n\n    dial_0124  dial_0125  dial_0126  dial_0127  \n0    0.106310  -0.025588   0.024027   0.075063  \n1         NaN        NaN        NaN        NaN  \n2         NaN        NaN        NaN        NaN  \n3         NaN        NaN        NaN        NaN  \n0    0.106310  -0.025588   0.024027   0.075063  \n..        ...        ...        ...        ...  \n3         NaN        NaN        NaN        NaN  \n0    0.106309  -0.025589   0.024028   0.075064  \n1         NaN        NaN        NaN        NaN  \n2         NaN        NaN        NaN        NaN  \n3         NaN        NaN        NaN        NaN  \n\n[168 rows x 257 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>trx_0000</th>\n      <th>trx_0001</th>\n      <th>trx_0002</th>\n      <th>trx_0003</th>\n      <th>trx_0004</th>\n      <th>trx_0005</th>\n      <th>trx_0006</th>\n      <th>trx_0007</th>\n      <th>trx_0008</th>\n      <th>...</th>\n      <th>dial_0118</th>\n      <th>dial_0119</th>\n      <th>dial_0120</th>\n      <th>dial_0121</th>\n      <th>dial_0122</th>\n      <th>dial_0123</th>\n      <th>dial_0124</th>\n      <th>dial_0125</th>\n      <th>dial_0126</th>\n      <th>dial_0127</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[001755891452af8d541d0466d6995b768904e181a74a6...</td>\n      <td>0.008138</td>\n      <td>-0.381437</td>\n      <td>-0.173643</td>\n      <td>0.040975</td>\n      <td>0.350735</td>\n      <td>-0.012193</td>\n      <td>-0.084212</td>\n      <td>-0.249949</td>\n      <td>-0.015709</td>\n      <td>...</td>\n      <td>0.046680</td>\n      <td>-0.019130</td>\n      <td>0.021606</td>\n      <td>0.069314</td>\n      <td>-0.032143</td>\n      <td>0.068159</td>\n      <td>0.106310</td>\n      <td>-0.025588</td>\n      <td>0.024027</td>\n      <td>0.075063</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[001755891452af8d541d0466d6995b768904e181a74a6...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[001755891452af8d541d0466d6995b768904e181a74a6...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[001755891452af8d541d0466d6995b768904e181a74a6...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[001755891452af8d541d0466d6995b768904e181a74a6...</td>\n      <td>0.005664</td>\n      <td>-0.386670</td>\n      <td>-0.143982</td>\n      <td>0.031381</td>\n      <td>0.353962</td>\n      <td>-0.005376</td>\n      <td>-0.096481</td>\n      <td>-0.246804</td>\n      <td>-0.020569</td>\n      <td>...</td>\n      <td>0.046680</td>\n      <td>-0.019130</td>\n      <td>0.021606</td>\n      <td>0.069314</td>\n      <td>-0.032143</td>\n      <td>0.068159</td>\n      <td>0.106310</td>\n      <td>-0.025588</td>\n      <td>0.024027</td>\n      <td>0.075063</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...</td>\n      <td>-0.135283</td>\n      <td>-0.453365</td>\n      <td>-0.143856</td>\n      <td>-0.076178</td>\n      <td>0.477253</td>\n      <td>0.147498</td>\n      <td>-0.073590</td>\n      <td>-0.125378</td>\n      <td>-0.055532</td>\n      <td>...</td>\n      <td>0.046681</td>\n      <td>-0.019129</td>\n      <td>0.021605</td>\n      <td>0.069314</td>\n      <td>-0.032143</td>\n      <td>0.068159</td>\n      <td>0.106309</td>\n      <td>-0.025589</td>\n      <td>0.024028</td>\n      <td>0.075064</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0141b8fc69c73eae094415c85df4fc3bac87177b0a8d3...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 257 columns</p>\n</div>"},"metadata":{}}],"execution_count":556},{"cell_type":"code","source":"inf_embeddings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**join targets with mm_dataset for test**","metadata":{}},{"cell_type":"code","source":"import random\n\ndef drop_zeros_targets(df, drop_frequency=1):\n    cols_to_drop = []\n    for i in range(len(df)):\n        if len(np.unique(df['target'][i])) == 1 and random.random() < drop_frequency:\n            cols_to_drop.append(i)\n    return df.drop(cols_to_drop).reset_index(drop=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mmt_dataset = drop_zeros_targets(mmt_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mmt_dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import Pool, CatBoostClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inf_train, inf_test = train_test_split(mmt_dataset, test_size=0.2)\ninf_train, inf_val = train_test_split(inf_train, test_size=0.1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_inf_train, y_inf_test = inf_train['target'].to_numpy(), inf_test['target'].to_numpy()\nX_inf_train, X_inf_test = inf_train.drop(columns=['client_id', 'target']).to_numpy(), inf_test.drop(columns=['client_id', 'target']).to_numpy()\nX_inf_val, y_inf_val = inf_val.drop(columns=['client_id', 'target']).to_numpy(), inf_val['target'].to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_inf_train = np.vstack(y_inf_train)\ny_inf_test = np.vstack(y_inf_test)\ny_inf_val = np.vstack(y_inf_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_inf_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Use nn head**","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset\nimport torch.nn as nn\nfrom sklearn.metrics import classification_report\n\nclass LightningModel(pl.LightningModule):\n    def __init__(self, input_size=256, hidden_size=64, output_size=48, lr=0.001):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_size, output_size)\n        )\n        self.criterion = nn.BCEWithLogitsLoss()\n        self.lr = lr\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y = y.float().to(\"cuda:0\")\n        logits = self(x).type(torch.FloatTensor).to(self.device)\n        loss = self.criterion(logits, y.float())\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.lr)\n\n    def predict_step(self, batch, batch_idx):\n        x, _ = batch\n        preds = torch.sigmoid(self(x))\n        return preds\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x).type(torch.FloatTensor).to(self.device)\n        loss = self.criterion(logits, y.float())\n        self.log('val_loss', loss, prog_bar=True)\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x).type(torch.FloatTensor).to(self.device)\n        loss = self.criterion(logits, y.float())\n        preds = (torch.sigmoid(logits) > 0.5).float()\n        acc = (preds == y).float().mean()\n        self.log('test_acc', acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_inf_train_tensor = torch.from_numpy(X_inf_train)\ny_inf_train_tensor = torch.from_numpy(y_inf_train)\n\nX_inf_val_tensor = torch.from_numpy(X_inf_val)\ny_inf_val_tensor = torch.from_numpy(y_inf_val)\n\nX_inf_test_tensor = torch.from_numpy(X_inf_test)\ny_inf_test_tensor = torch.from_numpy(y_inf_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_set = TensorDataset(X_inf_train_tensor, y_inf_train_tensor)\nval_set = TensorDataset(X_inf_val_tensor, y_inf_val_tensor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = LightningModel()\ntrainer = pl.Trainer(\n    max_epochs=15,\n    accelerator=\"cuda\",\n    enable_progress_bar=True\n)\ntrainer.fit(model, train_set, val_set)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ntest_set = TensorDataset(X_inf_test_tensor, y_inf_test_tensor)\nwith torch.no_grad():\n    trainer.test(model, test_set)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Use catboost**","metadata":{}},{"cell_type":"code","source":"# y_inf_train = y_inf_train.transpose()\n# y_inf_test = y_inf_test.transpose()\n# y_inf_val = y_inf_val.transpose()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(y_inf_train, return_counts=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = Pool(X_inf_train, y_inf_train)\nval_dataset = Pool(X_inf_val, y_inf_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = CatBoostClassifier(\n    iterations=500,\n    max_depth=6,\n    learning_rate=0.02,\n    task_type='GPU',\n    devices='0',\n    loss_function='MultiCrossEntropy',\n    verbose=False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(train_dataset, eval_set=val_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = model.predict(X_inf_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(y_inf_test, return_counts=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(preds, return_counts=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_inf_test, preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}