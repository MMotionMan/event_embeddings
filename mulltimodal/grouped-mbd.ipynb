{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import hf_hub_download \n\nhf_hub_download(repo_id=\"ai-lab/MBD-mini\", filename=\"ptls.tar.gz\", repo_type=\"dataset\", local_dir=\"/kaggle/working/\")\nhf_hub_download(repo_id=\"ai-lab/MBD-mini\", filename=\"targets.tar.gz\", repo_type=\"dataset\", local_dir=\"/kaggle/working/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:17:37.366817Z","iopub.execute_input":"2025-01-17T02:17:37.367137Z","iopub.status.idle":"2025-01-17T02:18:11.252231Z","shell.execute_reply.started":"2025-01-17T02:17:37.367115Z","shell.execute_reply":"2025-01-17T02:18:11.251581Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ptls.tar.gz:   0%|          | 0.00/1.40G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21918cac5b8f4099aab2c8b22457f94c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"targets.tar.gz:   0%|          | 0.00/7.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff99e96efdc4b1a9cc407afb18e2987"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/targets.tar.gz'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!pip install pyspark\n!pip install pytorch-lifestream","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:16:39.394628Z","iopub.execute_input":"2025-01-17T02:16:39.395044Z","iopub.status.idle":"2025-01-17T02:17:22.989810Z","shell.execute_reply.started":"2025-01-17T02:16:39.395007Z","shell.execute_reply":"2025-01-17T02:17:22.988977Z"}},"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.4.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pyspark: filename=pyspark-3.5.4-py2.py3-none-any.whl size=317849765 sha256=835b3927a7fda6a2ec615c5773b9494c5cfefd4ef78cb97538b73763a99a397a\n  Stored in directory: /root/.cache/pip/wheels/d9/1c/98/31e395a42d1735d18d42124971ecbbade844b50bb9845b6f4a\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.4\nCollecting pytorch-lifestream\n  Downloading pytorch-lifestream-0.6.0.tar.gz (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.1.0)\nCollecting hydra-core>=1.1.2 (from pytorch-lifestream)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.26.4)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.3.0)\nRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.1.4)\nRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (18.1.0)\nRequirement already satisfied: pytorch-lightning>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.4.0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.2.2)\nRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.4.1+cu121)\nRequirement already satisfied: torchmetrics>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.6.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (4.44.2)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (24.1)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->pytorch-lifestream) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2024.1)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.66.5)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2024.6.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (0.11.9)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.24.7)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.19.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (3.10.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (71.0.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-lifestream) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lifestream) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lifestream) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (4.0.3)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pytorch-lifestream\n  Building wheel for pytorch-lifestream (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pytorch-lifestream: filename=pytorch_lifestream-0.6.0-py3-none-any.whl size=274640 sha256=b94251ff2b7a6a5e1f3f50fa1240cbd3e3ad34f320dafae66a39c1b6bbd930fe\n  Stored in directory: /root/.cache/pip/wheels/90/76/b4/0a944bc7c5a69201e4d757cc54886971117a2a581740e7f11d\nSuccessfully built pytorch-lifestream\nInstalling collected packages: hydra-core, pytorch-lifestream\nSuccessfully installed hydra-core-1.3.2 pytorch-lifestream-0.6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!tar -xf ptls.tar.gz\n!tar -xf targets.tar.gz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:18:11.253244Z","iopub.execute_input":"2025-01-17T02:18:11.253475Z","iopub.status.idle":"2025-01-17T02:18:28.118323Z","shell.execute_reply.started":"2025-01-17T02:18:11.253455Z","shell.execute_reply":"2025-01-17T02:18:28.117204Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport pyspark\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nfrom pyspark.sql import types as T\nimport time\nimport datetime\nfrom ptls.data_load.datasets import ParquetDataset, ParquetFiles\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, ArrayType\nfrom tqdm.notebook import tqdm\nfrom ptls.preprocessing import PysparkDataPreprocessor\nimport pytorch_lightning as pl\nfrom ptls.data_load.datasets import MemoryMapDataset\nfrom ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\nfrom ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\nfrom ptls.frames.coles import CoLESModule\nfrom ptls.frames import PtlsDataModule\nfrom ptls.frames.coles import ColesDataset\nfrom ptls.frames.coles.split_strategy import SampleSlices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:39:48.193306Z","iopub.execute_input":"2025-01-17T02:39:48.193610Z","iopub.status.idle":"2025-01-17T02:39:48.206560Z","shell.execute_reply.started":"2025-01-17T02:39:48.193587Z","shell.execute_reply":"2025-01-17T02:39:48.205858Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"spark_conf = pyspark.SparkConf()\nspark_conf.setMaster(\"local[*]\").setAppName(\"JoinModality\")\nspark_conf.set(\"spark.driver.maxResultSize\", \"16g\")\nspark_conf.set(\"spark.executor.memory\", \"32g\")\nspark_conf.set(\"spark.executor.memoryOverhead\", \"16g\")\nspark_conf.set(\"spark.driver.memory\", \"32g\")\nspark_conf.set(\"spark.driver.memoryOverhead\", \"16g\")\nspark_conf.set(\"spark.cores.max\", \"24\")\nspark_conf.set(\"spark.sql.shuffle.partitions\", \"200\")\nspark_conf.set(\"spark.local.dir\", \"../../spark_local_dir\")\n\n\nspark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\nspark.sparkContext.getConf().getAll()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:39:08.676351Z","iopub.execute_input":"2025-01-17T02:39:08.676812Z","iopub.status.idle":"2025-01-17T02:39:13.186651Z","shell.execute_reply.started":"2025-01-17T02:39:08.676752Z","shell.execute_reply":"2025-01-17T02:39:13.185805Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = _posixsubprocess.fork_exec(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[('spark.driver.port', '46849'),\n ('spark.app.id', 'local-1737081552627'),\n ('spark.driver.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.executor.memoryOverhead', '16g'),\n ('spark.driver.memory', '32g'),\n ('spark.driver.maxResultSize', '16g'),\n ('spark.app.name', 'JoinModality'),\n ('spark.local.dir', '../../spark_local_dir'),\n ('spark.executor.id', 'driver'),\n ('spark.executor.memory', '32g'),\n ('spark.app.startTime', '1737081551539'),\n ('spark.driver.host', '541d7bc79235'),\n ('spark.rdd.compress', 'True'),\n ('spark.driver.memoryOverhead', '16g'),\n ('spark.executor.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.serializer.objectStreamReset', '100'),\n ('spark.sql.shuffle.partitions', '200'),\n ('spark.master', 'local[*]'),\n ('spark.submit.pyFiles', ''),\n ('spark.submit.deployMode', 'client'),\n ('spark.cores.max', '24'),\n ('spark.ui.showConsoleProgress', 'true'),\n ('spark.app.submitTime', '1737081551361')]"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"spark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:39:13.187929Z","iopub.execute_input":"2025-01-17T02:39:13.188169Z","iopub.status.idle":"2025-01-17T02:39:14.138717Z","shell.execute_reply.started":"2025-01-17T02:39:13.188147Z","shell.execute_reply":"2025-01-17T02:39:14.137819Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7f3af49d72e0>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://541d7bc79235:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>JoinModality</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"# With MM Dataset","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/mm_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:39:36.815898Z","iopub.execute_input":"2025-01-17T02:39:36.816209Z","iopub.status.idle":"2025-01-17T02:39:36.985756Z","shell.execute_reply.started":"2025-01-17T02:39:36.816187Z","shell.execute_reply":"2025-01-17T02:39:36.984855Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"TRX_DATA_PATH = '/kaggle/working/ptls/trx/'\nGEO_DATA_PATH = '/kaggle/working/ptls/geo/'\nDIAL_DATA_PATH = '/kaggle/working/ptls/dialog/'\n\nMM_DATA_PATH = '/kaggle/working/mm_dataset'\nMMT_DATA_PATH = '/kaggle/working/mm_dataset_supervised'\n\nTARGETS_DATA_PATH = '/kaggle/working/targets/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:40:09.267154Z","iopub.execute_input":"2025-01-17T02:40:09.267462Z","iopub.status.idle":"2025-01-17T02:40:09.271549Z","shell.execute_reply.started":"2025-01-17T02:40:09.267437Z","shell.execute_reply":"2025-01-17T02:40:09.270609Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def rename_col(df, prefix, col_id='client_id'):\n    new_column_names = [f\"{prefix}_{col}\" for col in df.columns if col != col_id]\n    old_column_names = [col for col in df.columns if col != col_id]\n    for old_col, new_col in zip(old_column_names, new_column_names):\n        df = df.withColumnRenamed(old_col, new_col)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:39:40.025802Z","iopub.execute_input":"2025-01-17T02:39:40.026066Z","iopub.status.idle":"2025-01-17T02:39:40.030818Z","shell.execute_reply.started":"2025-01-17T02:39:40.026046Z","shell.execute_reply":"2025-01-17T02:39:40.029955Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class AddNulls:\n    def __init__(self, max_date, dict_sizes, col_time, col_id, col_target=None, is_null_start=True):\n        \n        self.max_date = int(max_date // 86400)\n        self.dict_sizes = dict_sizes\n        self.col_time = col_time\n        self.col_id = col_id\n        # self.col_target = col_target\n        self.is_null_start = is_null_start\n\n    def step(self, features):\n        \n        event_time_int = np.array(features[self.col_time], dtype=int).tolist()  # Преобразуем значения в целые числа\n        filled_event_time = []\n        event_time_int = [int(event_time_int[i] // 86400) for i in range(len(event_time_int))]\n        prev_time = event_time_int[0]\n\n        # Заполнение пропусков в event_time\n        for time in event_time_int:\n            time = time\n            if time > prev_time + 1:\n                # Если между предыдущим временем и текущим есть пропуск, заполняем пропуски\n                for t in range(prev_time + 1, time):\n                    filled_event_time.append(t)\n            filled_event_time.append(time)\n            prev_time = time\n        for time in range(event_time_int[-1], self.max_date):\n            filled_event_time.append(time)\n\n        # Обработка остальных признаков\n        filled_features = {key: [] for key in self.dict_sizes.keys()}\n\n        event_time_index = 0  # Индекс для event_time\n\n        # Пробегаем по всем значениям в filled_event_time\n        for i in range(len(filled_event_time)):\n            # Если текущий момент времени совпадает с событием в исходном event_time\n            if event_time_index < len(event_time_int) and filled_event_time[i] == event_time_int[event_time_index]:\n                # Для каждого признака сохраняем значение, если оно есть в event_time\n                for key in self.dict_sizes.keys():\n                    filled_features[key].append(features[key][event_time_index])\n                event_time_index += 1\n            else:\n                # Если нет события, заполняем значением из dict_sizes для каждого признака\n                for key in self.dict_sizes.keys():\n                    filled_features[key].append(self.dict_sizes[key])\n\n        filled_features[self.col_time] = filled_event_time\n        filled_features[self.col_id] = features[self.col_id]\n        # filled_features[self.col_target] = features[self.col_target]\n        return filled_features\n\ntrx_dict_sizes = {\n    'trx_amount': 0.0,\n    'trx_event_type': 0,\n    'trx_event_subtype': 0,\n    'trx_currency': 0,\n    'trx_src_type11': 0,\n    'trx_src_type12': 0,\n    'trx_dst_type11': 0,\n    'trx_dst_type12': 0,\n    'trx_src_type21': 0,\n    'trx_src_type22': 0,\n    'trx_src_type31': 0,\n    'trx_src_type32': 0\n}\n\n\ns = \"31/12/2022\"\nmax_date = time.mktime(datetime.datetime.strptime(s, \"%d/%m/%Y\").timetuple())\ntrx_col_time = \"trx_event_time\"\ncol_id = \"client_id\"\n\ntrx_processor = AddNulls(max_date, trx_dict_sizes, trx_col_time, col_id)\n\ndial_dict_sizes = {\n    'dial_embedding': [[0 for i in range(786)]]\n}\ndial_col_time = \"dial_event_time\"\ndial_processor = AddNulls(max_date, dial_dict_sizes, dial_col_time, col_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:39:54.381438Z","iopub.execute_input":"2025-01-17T02:39:54.381742Z","iopub.status.idle":"2025-01-17T02:39:54.393601Z","shell.execute_reply.started":"2025-01-17T02:39:54.381718Z","shell.execute_reply":"2025-01-17T02:39:54.392672Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"**Create multimodal dataset with ADDNULLS**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import array\n\ntargets = spark.read.parquet(os.path.join(TARGETS_DATA_PATH , f'fold={0}'))\ntargets = targets.withColumn(\n    \"targets\",\n    array(targets.target_1, targets.target_2, targets.target_3, targets.target_4)\n)\ntargets.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:45:08.592635Z","iopub.execute_input":"2025-01-17T02:45:08.593049Z","iopub.status.idle":"2025-01-17T02:45:09.069013Z","shell.execute_reply.started":"2025-01-17T02:45:08.593020Z","shell.execute_reply":"2025-01-17T02:45:09.067830Z"}},"outputs":[{"name":"stdout","text":"+--------------------+----------+--------+--------+--------+--------+-----------+---------------+------------+\n|           client_id|       mon|target_1|target_2|target_3|target_4|trans_count|diff_trans_date|     targets|\n+--------------------+----------+--------+--------+--------+--------+-----------+---------------+------------+\n|0011eb856025cc736...|2022-02-28|       0|       0|       0|       0|         32|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-03-31|       0|       0|       0|       0|         69|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-04-30|       0|       0|       0|       0|         97|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-05-31|       0|       0|       0|       0|        125|              1|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-06-30|       0|       0|       0|       0|        156|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-07-31|       0|       0|       0|       0|        192|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-08-31|       1|       0|       0|       0|        220|              1|[1, 0, 0, 0]|\n|0011eb856025cc736...|2022-09-30|       0|       0|       0|       0|        246|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-10-31|       0|       0|       0|       0|        271|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-11-30|       0|       0|       0|       0|        294|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2022-12-31|       0|       0|       0|       0|        318|              0|[0, 0, 0, 0]|\n|0011eb856025cc736...|2023-01-31|       0|       0|       0|       0|        354|              1|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-02-28|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-03-31|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-04-30|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-05-31|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-06-30|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-07-31|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-08-31|       0|       0|       0|       0|          0|           NULL|[0, 0, 0, 0]|\n|0048344bbb66250c6...|2022-09-30|       0|       0|       0|       0|         12|             15|[0, 0, 0, 0]|\n+--------------------+----------+--------+--------+--------+--------+-----------+---------------+------------+\nonly showing top 20 rows\n\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"preprocessor_target = PysparkDataPreprocessor(\n    col_id=\"client_id\",\n    col_event_time=\"mon\",\n    event_time_transformation=\"dt_to_timestamp\",\n    cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n)\n\n\ndef create_infer_schema(data):\n    first_row = data[0]\n    fields = []\n\n    for key, value in first_row.items():\n        if isinstance(value, list):\n            # Если значение — список, то это будет ArrayType\n            if isinstance(value[0], int):\n                fields.append(StructField(key, ArrayType(IntegerType()), True))\n            elif isinstance(value[0], float):\n                fields.append(StructField(key, ArrayType(FloatType()), True))\n            elif isinstance(value[0], str):\n                fields.append(StructField(key, ArrayType(StringType()), True))\n            else:\n                fields.append(StructField(key, ArrayType(StringType()), True))  # Default to StringType\n        else:\n            # Если значение не список, то это обычный тип\n            if isinstance(value, int):\n                fields.append(StructField(key, IntegerType(), True))\n            elif isinstance(value, float):\n                fields.append(StructField(key, FloatType(), True))\n            elif isinstance(value, str):\n                fields.append(StructField(key, StringType(), True))\n            else:\n                fields.append(StructField(key, StringType(), True))  # Default to StringType\n\n    schema = StructType(fields)\n    return schema\n\nfor fold in tqdm(range(0, 5)):\n    trx = spark.read.parquet(os.path.join(TRX_DATA_PATH, f'fold={fold}'))\n    # geo = spark.read.parquet(os.path.join(GEO_DATA_PATH, f'fold={fold}'))\n    dial = spark.read.parquet(os.path.join(DIAL_DATA_PATH, f'fold={fold}'))\n    trx = rename_col(trx, 'trx')\n    # trx = trx.rdd.map(lambda x: trx_processor.step(x.asDict()))\n    # schema = create_infer_schema([trx.first()])\n    # trx = spark.createDataFrame(trx, schema=schema)\n    # geo = rename_col(geo, 'geo')\n    dial = rename_col(dial, 'dial')\n    # dial = dial.rdd.map(lambda x: dial_processor.step(x.asDict()))\n    # schema = create_infer_schema([dial.first()])\n    # dial = spark.createDataFrame(dial, schema=schema)\n    \n    mm_dataset = trx.join(dial, on='client_id', how='outer')\n    \n    targets = spark.read.parquet(os.path.join(TARGETS_DATA_PATH , f'fold={fold}'))\n    targets = targets.withColumn(\n    \"targets\",\n    array(targets.target_1, targets.target_2, targets.target_3, targets.target_4)\n)\n    targets = preprocessor_target.fit_transform(targets)\n\n    mm_dataset = mm_dataset.join(targets, on='client_id', how='left').drop(*[\n        'target_1',\n        'target_2',\n        'target_3',\n        'target_4',\n        'trans_count',\n        'diff_trans_date'\n    ])\n    mm_dataset.write.mode('overwrite').parquet(os.path.join(MMT_DATA_PATH, f'fold={fold}'))\n    del trx\n    del dial\n    del mm_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:51:45.893730Z","iopub.execute_input":"2025-01-17T02:51:45.894174Z","iopub.status.idle":"2025-01-17T02:52:52.434276Z","shell.execute_reply.started":"2025-01-17T02:51:45.894131Z","shell.execute_reply":"2025-01-17T02:52:52.433090Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2478ea2bb8d447ead30681dce90b7dc"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport calendar\nfrom glob import glob\nfrom ptls.data_load.utils import collate_feature_dict\n\nfrom ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\nfrom datetime import datetime\nfrom ptls.data_load.padded_batch import PaddedBatch\n\nclass TargetToTorch(IterableProcessingDataset):\n    def __init__(self, col_target):\n        super().__init__()\n        self.col_target = col_target\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features[self.col_target] = np.stack(np.array(features[self.col_target]))\n            features[self.col_target] = torch.tensor(features[self.col_target])\n            yield features\n\n\nclass GetSplit(IterableProcessingDataset):\n    def __init__(\n        self,\n        start_month,\n        end_month,\n        year=2022,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self.start_month = start_month\n        self.end_month = end_month\n        self._year = year\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            for month in range(self.start_month, self.end_month+1):\n                features = rec[0] if type(rec) is tuple else rec\n                features = features.copy()\n                \n                if month == 12:\n                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n                else:\n                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n                    \n                year_event_time = datetime(self._year, 1, 1).timestamp()\n                \n                mask = features[self._col_time] < month_event_time\n                \n                for key, tensor in features.items():\n                    if key.startswith('target'):\n                        features[key] = tensor[month - 1].tolist()    \n                    elif key != self._col_id:\n                        features[key] = tensor[mask] \n                            \n                features[self._col_id] += '_month=' + str(month)\n\n                yield features\n\ndef collate_feature_dict_with_target(batch, col_id='client_id', target_col_names=None):\n    batch_ids = []\n    target_cols = []\n    for sample in batch:\n        batch_ids.append(sample[col_id])\n        del sample[col_id]\n        \n        if target_col_names is not None:\n            for target_col in target_col_names:\n                target_cols.append(sample[target_col])\n                del sample[target_col]\n            \n    padded_batch = collate_feature_dict(batch)\n    if target_col_names is not None:\n        return padded_batch, batch_ids, target_cols\n    return padded_batch, batch_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T03:00:23.824239Z","iopub.execute_input":"2025-01-17T03:00:23.824592Z","iopub.status.idle":"2025-01-17T03:00:23.834744Z","shell.execute_reply.started":"2025-01-17T03:00:23.824563Z","shell.execute_reply":"2025-01-17T03:00:23.833862Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"from ptls.data_load.datasets import ParquetDataset\nfrom ptls.data_load.iterable_processing import SeqLenFilter\nfrom ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\ntrain = ParquetDataset(\n    data_files=[\n        os.path.join(MMT_DATA_PATH, f'fold={0}'),\n        os.path.join(MMT_DATA_PATH, f'fold={1}'),\n        os.path.join(MMT_DATA_PATH, f'fold={2}')\n    ],\n    i_filters=[\n        SeqLenFilter(min_seq_len=32),\n        ISeqLenLimit(max_seq_len=4096),\n        ToTorch(),\n        TargetToTorch(col_target='targets'),\n    ],\n    shuffle_files=True\n)\nvalid = ParquetDataset(\n    data_files=[\n        os.path.join(MMT_DATA_PATH, f'fold={3}')\n    ],\n    i_filters=[\n        SeqLenFilter(min_seq_len=32),\n        ISeqLenLimit(max_seq_len=4096),\n        ToTorch(),\n        TargetToTorch(col_target='targets'),\n    ],\n    shuffle_files=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:13:14.107950Z","iopub.execute_input":"2025-01-17T04:13:14.108262Z","iopub.status.idle":"2025-01-17T04:13:14.114346Z","shell.execute_reply.started":"2025-01-17T04:13:14.108241Z","shell.execute_reply":"2025-01-17T04:13:14.113517Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"next(iter(train))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:22:19.080449Z","iopub.execute_input":"2025-01-17T04:22:19.080839Z","iopub.status.idle":"2025-01-17T04:22:19.855494Z","shell.execute_reply.started":"2025-01-17T04:22:19.080815Z","shell.execute_reply":"2025-01-17T04:22:19.854740Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"{'client_id': '000e047a31e50ba35f71c81962b4eb0b9a2d6080cf23a14f91447317dd14c788',\n 'trx_event_time': tensor([1609490380, 1610003909, 1610180496, 1610183393, 1610264466, 1610266194,\n         1610442309, 1610519884, 1610612313, 1610687058, 1610867659, 1611209220,\n         1611379348, 1611389622, 1611553654, 1611737692, 1611991352, 1612002459,\n         1612174968, 1612250928, 1612253101, 1612419223, 1612421720, 1612434125,\n         1612504321, 1612589076, 1612673828, 1612773491, 1612868722, 1613018794,\n         1613026708, 1613104541, 1613113892, 1613118370, 1613289751, 1613297280,\n         1613378254, 1613638876, 1613799989, 1613809924, 1613811768, 1613887740,\n         1613901739, 1613978649, 1614057274, 1614495629, 1614495765, 1614581690,\n         1614669285, 1614924793, 1615112066, 1615184054, 1615447812, 1615707336,\n         1616228131, 1616406936, 1616823175, 1617090479, 1617182075, 1617608630,\n         1617695825, 1617698777, 1617784066, 1617880952, 1617962327, 1618044585,\n         1618389235, 1618465706, 1618827876, 1618895869, 1618994376, 1619077204,\n         1619247559, 1619247673, 1619337214, 1619500941, 1619683883, 1620370560,\n         1620545046, 1620714424, 1620893467, 1620972700, 1621059465, 1621154615,\n         1621238643, 1621324362, 1621580676, 1621755872, 1621927903, 1621934779,\n         1622471942, 1622521254, 1622961279, 1623040252, 1623130448, 1623563421,\n         1623744030, 1623921240, 1624348255, 1624605374, 1624689133, 1624780059,\n         1624860686, 1625133125, 1625639722, 1625725009, 1625751355, 1625895833,\n         1626081493, 1626254698, 1627104659, 1627189480, 1627289677, 1627474739,\n         1627636957, 1627713344, 1627803260, 1628321840, 1628322528, 1628323473,\n         1628414655, 1628831350, 1628912211, 1629102351, 1629351716, 1629694997,\n         1630475141, 1630574581, 1630740686, 1631012938, 1631079469, 1631257741,\n         1631339499, 1631510539, 1631598187, 1632207098, 1632293305, 1632918498,\n         1633154865, 1633157317, 1633239038, 1633497011, 1633853017, 1634109634,\n         1634632269, 1634972070, 1635241873, 1635320934, 1635404879, 1635497931,\n         1636100086, 1636439195, 1636445274, 1636525315, 1636528198, 1636604660,\n         1636611808, 1636621630, 1636625643, 1636629976, 1637049961, 1637123110,\n         1637126562, 1637135986, 1637313842, 1637390531, 1638161851, 1638513260,\n         1638687039, 1639034436, 1639133201, 1639202114, 1639225955, 1639634764,\n         1639637477, 1639721171, 1639804851, 1639807979, 1640060720, 1640065386,\n         1640325977, 1640334316, 1640923510, 1641284854, 1641287102, 1641796581,\n         1641893005, 1641895355, 1642140794, 1642230588, 1642507351, 1643024475,\n         1643097527, 1643103240, 1643180580, 1643190659, 1643273304, 1643610098,\n         1643782435, 1643875637, 1644052959, 1644124096, 1644135465, 1644417972,\n         1644560408, 1644571300, 1644758839, 1645253142, 1645343142, 1645618027,\n         1645783492, 1645783675, 1645863798, 1645877082, 1646119273, 1646210620,\n         1646386811, 1646748183, 1646994428, 1647082339, 1647419357, 1647424940,\n         1647491537, 1647584233, 1647602798, 1647751779, 1647774435, 1647798828,\n         1647944168, 1648023470, 1648198250, 1648200371, 1648286284, 1648292470,\n         1648292696, 1648467080, 1648615090, 1648710879, 1648711049, 1649140154,\n         1649410600, 1649480135, 1650545465, 1650698998, 1650800646, 1650955361,\n         1651046974, 1651132200, 1651146933, 1651221331, 1651387231, 1651461829,\n         1651491989, 1651668056, 1651912653, 1652097358, 1652173111, 1652259705,\n         1652423115, 1652782819, 1653212321, 1653469669, 1653548495, 1653724632,\n         1653976903, 1654150142, 1654242596, 1655444259, 1655522300, 1655624414,\n         1655799111, 1655876123, 1655882576, 1656039670, 1656138383, 1656223580,\n         1656596114, 1656605299, 1656656156, 1656705147, 1656835511, 1656892428,\n         1656917458, 1656930561, 1657114146, 1657122681, 1657261902, 1657349967,\n         1657865226, 1657949365, 1657988201, 1658211281, 1658817423, 1658964788,\n         1659005819, 1659316267, 1659354706, 1659509120, 1659510035, 1659599566,\n         1660392982, 1660462969, 1660475549, 1660516728, 1660629900, 1660731542,\n         1660969768, 1661064107, 1661065240, 1661074145, 1661143950, 1661590541,\n         1661668712, 1661856189, 1662445888, 1662533357, 1662723283, 1662970676,\n         1663055511, 1663141321, 1663156346, 1663223349, 1663226110, 1663232930,\n         1663273613, 1663319977, 1663486350, 1663750602, 1663828403, 1663846714,\n         1664007817, 1664010573, 1664013461, 1664253922, 1664278749, 1664291361,\n         1664613045, 1664619391, 1664870115, 1665122706, 1665207428, 1665212978,\n         1665321235, 1665479667, 1665661309, 1665663943, 1665732795, 1665808566,\n         1665921822, 1665987160, 1666070875, 1666512632, 1666946338, 1667043016,\n         1667112319, 1667118975, 1667120571, 1667570623, 1667717928, 1668060638,\n         1668065995, 1668320525, 1668579753, 1668667771, 1668758641, 1668773460,\n         1668934881, 1668986509, 1669020449, 1669251283, 1669275221, 1669412404,\n         1669544967, 1669606973, 1669806631, 1669883305, 1670049538, 1670058901,\n         1670311589, 1670362676, 1670406065, 1670655143, 1670668294, 1671189652,\n         1671947344, 1672035487, 1672377998, 1672381310]),\n 'trx_amount': tensor([5.6921e+04, 2.8823e+05, 1.2259e+04, 7.0645e+04, 1.3922e+05, 4.2446e+05,\n         4.9669e+05, 1.9226e+04, 3.4794e+04, 1.1466e+05, 1.7511e+05, 4.0034e+04,\n         2.6771e+04, 6.0882e+04, 1.0192e+05, 1.0528e+04, 5.5783e+04, 1.1162e+05,\n         1.3566e+05, 1.4161e+04, 7.5178e+04, 8.9562e+04, 1.6687e+05, 8.6521e+04,\n         2.2658e+04, 2.0790e+05, 2.6806e+04, 7.0670e+04, 1.9366e+05, 5.4501e+04,\n         8.0187e+03, 3.0819e+04, 4.4334e+03, 6.4180e+03, 1.2893e+05, 5.1632e+03,\n         1.4774e+05, 3.8426e+04, 1.7049e+04, 2.0272e+04, 6.6494e+04, 4.3542e+04,\n         1.6917e+05, 1.4378e+04, 2.4845e+04, 1.7519e+04, 2.6001e+05, 1.2463e+05,\n         5.7776e+04, 1.6612e+04, 1.7562e+04, 1.0619e+05, 2.4034e+04, 1.7225e+04,\n         4.3468e+04, 5.5850e+04, 8.5482e+04, 5.0161e+04, 4.1405e+05, 1.4469e+04,\n         5.4879e+04, 4.0793e+04, 1.8284e+05, 5.4592e+04, 1.8896e+04, 3.7946e+04,\n         5.4990e+04, 3.9648e+04, 4.8945e+04, 1.6702e+03, 4.9104e+04, 1.2048e+02,\n         2.4196e+04, 2.7991e+05, 1.5602e+04, 2.6299e+04, 2.7525e+05, 4.6218e+04,\n         2.9688e+04, 3.7153e+04, 7.3149e+04, 1.9843e+04, 4.7538e+04, 1.3412e+04,\n         1.0829e+04, 6.8197e+04, 2.8016e+05, 1.1246e+04, 3.5232e+04, 2.7401e+04,\n         6.6953e+04, 4.5507e+04, 2.7359e+05, 1.5857e+04, 7.8157e+04, 2.9930e+04,\n         2.9291e+05, 3.8438e+04, 7.1272e+04, 1.4634e+05, 6.3348e+04, 3.0872e+04,\n         1.3213e+05, 2.2179e+04, 4.4324e+04, 6.4497e+04, 7.3909e+04, 2.6182e+04,\n         5.9390e+04, 8.8033e+04, 3.6730e+03, 2.9725e+04, 7.9824e+04, 4.6272e+04,\n         1.0752e+04, 1.2520e+04, 1.8648e+03, 1.8719e+04, 9.7169e+02, 3.4306e+04,\n         3.8132e+04, 5.2319e+03, 1.5255e+04, 3.1410e+04, 9.0257e+04, 5.5746e+04,\n         5.8261e+04, 3.8362e+03, 7.4363e+04, 6.2464e+04, 5.6055e+04, 2.7843e+04,\n         5.3872e+04, 2.2463e+04, 9.4032e+03, 5.3369e+04, 2.8555e+04, 1.5219e+04,\n         1.6520e+04, 1.3948e+04, 5.0199e+04, 8.0479e+04, 8.5383e+04, 2.6638e+03,\n         4.5105e+04, 1.6108e+04, 7.7621e+04, 1.6007e+04, 3.1720e+02, 2.7962e+04,\n         6.0838e+04, 1.4293e+04, 4.5541e+04, 7.4907e+03, 6.9823e+04, 1.0384e+04,\n         6.4378e+04, 1.5061e+04, 2.7918e+04, 6.5438e+03, 2.7471e+04, 7.1956e+04,\n         8.2600e+04, 2.1056e+04, 4.8512e+04, 2.7947e+04, 5.5580e+04, 3.8640e+04,\n         3.7390e+04, 3.1773e+04, 9.2057e+04, 8.1820e+04, 8.0159e+03, 1.5952e+04,\n         4.3485e+04, 1.2713e+04, 3.5492e+04, 6.3351e+03, 3.0397e+04, 6.3340e+04,\n         5.9056e+03, 1.2203e+05, 1.5836e+05, 2.3940e+04, 5.9929e+04, 2.2369e+04,\n         6.5259e+04, 8.9314e+04, 9.8432e+04, 6.3747e+03, 4.1505e+03, 4.7593e+04,\n         8.8536e+04, 1.2041e+03, 2.6750e+04, 9.1671e+03, 8.8736e+04, 5.6680e+03,\n         4.0140e+04, 7.2653e+04, 9.4783e+03, 1.3392e+05, 4.2001e+03, 2.1718e+04,\n         3.8260e+04, 5.0330e+04, 4.1384e+04, 1.1420e+05, 3.5463e+04, 1.4301e+04,\n         1.1678e+05, 1.2951e+04, 2.1067e+04, 1.8738e+04, 6.7422e+00, 6.7622e+04,\n         1.4125e+04, 2.4191e+04, 1.9781e-01, 3.3399e+04, 2.0160e+04, 1.9564e+04,\n         5.8816e+03, 9.7482e+03, 4.2518e+02, 5.7879e+04, 1.6361e+04, 2.5188e+00,\n         3.3477e+03, 5.7441e+03, 1.9110e+03, 1.6264e+04, 1.8780e+04, 9.2449e+03,\n         4.7700e+04, 1.0649e+05, 1.3043e+04, 2.0847e+04, 6.4506e+04, 1.2730e+04,\n         2.9707e+04, 1.0958e+04, 3.9011e+03, 5.9054e+04, 1.0697e+04, 1.1316e+05,\n         8.5401e+04, 7.1158e+04, 1.4178e+05, 2.0322e+04, 4.5186e+04, 2.8803e+04,\n         1.2374e+04, 4.5042e+04, 5.7686e+04, 3.5296e+04, 8.2266e+04, 4.8700e+03,\n         8.2306e+04, 3.6310e+04, 6.3919e+03, 1.4296e+03, 2.0671e+04, 2.5652e+03,\n         9.3705e+04, 6.7648e+04, 3.0200e+04, 4.0092e+03, 1.5228e+04, 8.3436e+04,\n         2.8736e+04, 7.3650e+04, 2.1308e+04, 4.2219e+04, 8.0919e+04, 4.6114e+04,\n         3.7267e+04, 8.0842e+02, 1.5894e+05, 6.4381e+01, 4.4583e+03, 5.3091e+00,\n         2.6597e+04, 2.2346e+04, 1.4298e+04, 1.8810e+02, 4.9375e+04, 7.0010e+03,\n         4.2292e+04, 2.6176e+04, 5.4950e+04, 9.1607e+03, 1.6035e+04, 2.5185e+02,\n         1.0120e+05, 1.0689e+03, 7.1928e+01, 2.6624e+04, 1.0425e+05, 2.4688e+04,\n         1.3536e+04, 6.0703e+04, 5.9357e+02, 7.7135e+02, 3.8689e+04, 2.5791e+03,\n         7.4977e+04, 5.6034e+04, 3.8590e+04, 5.9043e+03, 3.3470e+04, 4.1621e+04,\n         3.8844e+03, 1.2636e+05, 8.9189e+04, 5.8182e+03, 4.1468e+01, 9.2811e+03,\n         1.1402e+04, 7.1360e+03, 1.4857e+03, 6.7445e+03, 4.8585e+04, 2.3906e+04,\n         2.9677e+02, 6.7078e+04, 1.0924e+03, 5.2679e+04, 9.8891e+03, 1.0825e+04,\n         1.9272e+04, 1.3035e+04, 2.7241e+04, 1.8884e+04, 9.9929e+04, 5.8841e+04,\n         2.5435e+04, 2.7911e+03, 6.5707e+04, 4.1527e+04, 9.2060e+03, 1.0081e+04,\n         1.8242e+05, 2.8697e+03, 2.9688e+03, 7.7375e+04, 3.2083e+04, 7.8190e+04,\n         2.4567e+04, 5.0677e+04, 1.5648e+04, 5.1399e+04, 1.3210e+05, 1.1278e+04,\n         3.5150e+04, 3.7900e+04, 7.0968e+03, 2.2394e+03, 3.7842e+04, 5.7784e+04,\n         8.0009e+03, 1.8524e+04, 5.2417e+03, 2.0533e+03, 1.5021e+05, 2.1834e+04,\n         1.4940e+05, 1.0176e+01, 8.4687e+04, 1.4291e+04, 1.6848e+03, 7.7983e+04,\n         1.8058e+03, 5.6838e+04, 9.0854e+04, 1.1935e+04, 1.7963e+04, 2.7675e+03,\n         1.0058e+05, 2.9027e+04, 4.7834e+03, 1.4171e+04, 2.4258e+04, 1.0442e+05,\n         6.6954e+04, 1.1254e+05, 6.3890e+04, 3.7296e+04]),\n 'trx_event_type': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1, 11,  1,  1,  1,  1,  1,  1,  1, 11,  1,  1,\n          1,  1, 11, 11,  1, 11,  1, 11,  1,  1, 11,  1, 11,  1,  1,  1,  1,  1,\n         11,  1, 11,  1,  1, 11,  1,  1,  1, 11,  1,  1,  1,  1,  1,  1, 11,  1,\n         11,  1,  1, 11,  1,  1,  1,  1, 11,  1, 11,  1,  1,  1,  1,  1, 11, 11,\n          1, 11, 11,  1,  1,  1,  1,  1,  1,  1, 11,  1,  1,  1, 11,  1,  1,  1,\n         11, 11,  1,  1, 11, 11,  1,  1, 11, 11, 11,  1, 11, 11,  1,  1,  1,  4,\n          1, 11,  1,  1,  1, 11, 11,  1,  1, 11,  1, 11,  1,  4,  1, 11, 11, 11,\n          1,  4, 11,  1,  1,  1,  1,  1,  1,  1, 11, 11,  1, 11, 11, 11, 11, 11,\n          1,  1,  1, 11, 11,  1,  1,  1,  1,  1, 11, 11,  1,  1,  1, 11,  1, 11,\n          1,  1, 11,  1, 11, 11,  1,  1,  1,  1, 11,  1,  1,  1, 11, 11,  3,  1,\n         11,  1, 18,  1,  1, 11,  4,  4,  1,  1,  1,  3,  1,  1, 11,  1,  1, 11,\n         11,  1,  1, 11,  1, 11,  1,  4, 11,  1,  4, 11,  1,  1,  1, 11,  1, 11,\n         11,  1,  1, 11,  1,  1, 11,  1,  1, 11,  1, 11,  1, 11, 11, 11, 11,  1,\n          1,  1,  1,  1,  1,  1,  1, 14,  1,  7,  1,  3,  1,  1, 11,  7,  1,  1,\n         11,  1, 14,  1,  1, 14,  1, 12,  1,  1,  1, 11,  1,  1, 12, 23, 11, 24,\n          1,  1,  1,  1,  1,  1, 24,  1,  1,  1,  9, 11, 11, 11, 14,  1, 11, 11,\n         23,  1,  1,  1,  1,  1, 11,  1,  1, 11,  1,  1,  1,  1,  1, 11, 11,  1,\n          1,  1, 11,  1,  1,  1, 11,  1, 11,  1,  1,  1,  1,  1,  1, 11,  1,  1,\n          1,  1, 11,  1,  1,  1,  1, 20,  1,  7,  1,  7,  9,  1,  1,  1,  1,  1,\n         11,  7,  1, 11,  1,  1, 11,  1,  1,  1], dtype=torch.int32),\n 'trx_event_subtype': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,\n          1,  1, 12, 12,  1, 12,  1, 12,  1,  1, 12,  1, 12,  1,  1,  1,  1,  1,\n         12,  1, 12,  1,  1, 12,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1, 12,  1,\n         12,  1,  1, 12,  1,  1,  1,  1, 12,  1, 12,  1,  1,  1,  1,  1, 12, 12,\n          1, 12, 12,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1, 12,  1,  1,  1,\n         12, 12,  1,  1, 12, 12,  1,  1, 12, 12, 12,  1, 12, 12,  1,  1,  1,  4,\n          1, 12,  1,  1,  1, 12, 12,  1,  1, 12,  1, 12,  1,  4,  1, 12, 12, 12,\n          1,  4, 12,  1,  1,  1,  1,  1,  1,  1, 12, 12,  1, 12, 12, 12, 12, 12,\n          1,  1,  1, 12, 12,  1,  1,  1,  1,  1, 12, 12,  1,  1,  1, 12,  1, 12,\n          1,  1, 12,  1, 12, 12,  1,  1,  1,  1, 12,  1,  1,  1, 12, 12,  3,  1,\n         12,  1, 19,  1,  1, 12,  4,  4,  1,  1,  1,  3,  1,  1, 12,  1,  1, 12,\n         12,  1,  1, 12,  1, 12,  1,  4, 12,  1,  4, 12,  1,  1,  1, 12,  1, 12,\n         12,  1,  1, 12,  1,  1, 12,  1,  1, 12,  1, 12,  1, 12, 12, 12, 12,  1,\n          1,  1,  1,  1,  1,  1,  1, 13,  1,  7,  1, 10,  1,  1, 12,  7,  1,  1,\n         12,  1, 13,  1,  1, 13,  1, 10,  1,  1,  1, 12,  1,  1, 10, 28, 12, 25,\n          1,  1,  1,  1,  1,  1, 25,  1,  1,  1,  9, 12, 12, 12, 13,  1, 12, 12,\n         28,  1,  1,  1,  1,  1, 12,  1,  1, 12,  1,  1,  1,  1,  1, 12, 12,  1,\n          1,  1, 12,  1,  1,  1, 12,  1, 12,  1,  1,  1,  1,  1,  1, 12,  1,  1,\n          1,  1, 12,  1,  1,  1,  1, 21,  1,  7,  1,  7,  9,  1,  1,  1,  1,  1,\n         12,  7,  1, 12,  1,  1, 12,  1,  1,  1], dtype=torch.int32),\n 'trx_currency': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1], dtype=torch.int32),\n 'trx_src_type11': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  3,  1,  1,  1,  1,  1,  1,\n          1,  1,  5,  1,  1,  5,  1,  3,  1,  1,  1,  1,  1,  1,  3, 12,  1,  5,\n          1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  3,  1,  1,  1,  5,  1,  1,  1,\n         12,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  4,  1,  4,  1,  4,  3,  1,  1,  1,  1,  1,\n          1,  4,  1,  1,  1,  1,  1,  1,  1,  1], dtype=torch.int32),\n 'trx_src_type12': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1, 10,  1,  1,  1, 11,  1,  1,  1,  1,  1,  1,\n          1,  1, 10,  1,  1, 10,  1, 16,  1,  1,  1,  1,  1,  1, 16, 26,  1, 18,\n          1,  1,  1,  1,  1,  1, 10,  1,  1,  1, 11,  1,  1,  1, 10,  1,  1,  1,\n         26,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1, 42,  1, 42,  1, 42, 11,  1,  1,  1,  1,  1,\n          1, 42,  1,  1,  1,  1,  1,  1,  1,  1], dtype=torch.int32),\n 'trx_dst_type11': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  2,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,\n          1,  1,  2,  2,  1,  2,  1,  2,  1,  1,  2,  1,  2,  1,  1,  1,  1,  1,\n          2,  1,  2,  1,  1,  2,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  2,  1,\n          2,  1,  1,  2,  1,  1,  1,  1,  2,  1,  2,  1,  1,  1,  1,  1,  2,  2,\n          1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  2,  1,  1,  1,\n          2,  2,  1,  1,  2,  2,  1,  1,  2,  2,  2,  1,  2,  2,  1,  1,  1,  2,\n          1,  2,  1,  1,  1,  2,  2,  1,  1,  2,  1,  2,  1,  2,  1,  2,  2,  2,\n          1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  2,  2,  1,  2,  2,  2,  2,  2,\n          1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  2,  1,  2,\n          1,  1,  2,  1,  2,  2,  1,  1,  1,  1,  2,  1,  1,  1,  2,  2,  6,  1,\n          2,  1, 12,  1,  1,  2,  2,  2,  1,  1,  1,  3,  1,  1,  2,  1,  1,  2,\n          2,  1,  1,  2,  1,  2,  1,  2,  2,  1,  2,  2,  1,  1,  1,  2,  1,  2,\n          2,  1,  1,  2,  1,  1,  2,  1,  1,  2,  1,  2,  1,  2,  2,  2,  2,  1,\n          1,  1,  1,  1,  1,  1,  1,  8,  1,  4,  2,  3,  1,  1,  2,  4,  1,  1,\n          2,  1,  8,  1,  1,  8,  1,  3,  1,  1,  1,  2,  1,  1,  3,  6,  2, 14,\n          1,  1,  1,  1,  1,  1, 14,  1,  1,  1,  1,  2,  2,  2,  8,  1,  2,  2,\n          6,  1,  1,  1,  1,  1,  2,  1,  1,  2,  1,  1,  1,  1,  1,  2,  2,  1,\n          1,  1,  2,  1,  1,  1,  2,  1,  2,  1,  1,  1,  1,  1,  1,  2,  1,  1,\n          1,  1,  2,  1,  1,  1,  1,  4,  1,  4,  1,  4,  1,  1,  1,  1,  1,  1,\n          2,  4,  1,  2,  1,  1,  2,  1,  1,  1], dtype=torch.int32),\n 'trx_dst_type12': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  4,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n          1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,  1,  1,  1,  4,  1,  1,\n          1,  1,  4,  4,  1,  4,  1,  4,  1,  1,  4,  1,  4,  1,  1,  1,  1,  1,\n          4,  1,  4,  1,  1,  4,  1,  1,  1,  4,  1,  1,  1,  1,  1,  1,  4,  1,\n          4,  1,  1,  4,  1,  1,  1,  1,  4,  1,  4,  1,  1,  1,  1,  1,  4,  4,\n          1,  4,  4,  1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  4,  1,  1,  1,\n          4,  4,  1,  1,  4,  4,  1,  1,  4,  4,  4,  1,  4,  4,  1,  1,  1,  2,\n          1,  4,  1,  1,  1,  4,  4,  1,  1,  4,  1,  4,  1,  2,  1,  4,  4,  4,\n          1,  2,  4,  1,  1,  1,  1,  1,  1,  1,  4,  4,  1,  4,  4,  4,  4,  4,\n          1,  1,  1,  4,  4,  1,  1,  1,  1,  1,  4,  4,  1,  1,  1,  4,  1,  4,\n          1,  1,  4,  1,  4,  4,  1,  1,  1,  1,  4,  1,  1,  1,  4,  4,  7,  1,\n          4,  1, 16,  1,  1,  4,  2,  2,  1,  1,  1,  3,  1,  1,  4,  1,  1,  4,\n          4,  1,  1,  4,  1,  4,  1,  2,  4,  1,  2,  4,  1,  1,  1,  4,  1,  4,\n          4,  1,  1,  4,  1,  1,  4,  1,  1,  4,  1,  4,  1,  4,  4,  4,  4,  1,\n          1,  1,  1,  1,  1,  1,  1,  9,  1,  5,  4,  3,  1,  1,  4,  5,  1,  1,\n          4,  1,  9,  1,  1,  9,  1,  3,  1,  1,  1,  4,  1,  1,  3, 15,  4, 32,\n          1,  1,  1,  1,  1,  1, 31,  1,  1,  1,  1,  4,  4,  4,  9,  1,  4,  4,\n         15,  1,  1,  1,  1,  1,  4,  1,  1,  4,  1,  1,  1,  1,  1,  4,  4,  1,\n          1,  1,  4,  1,  1,  1,  4,  1,  4,  1,  1,  1,  1,  1,  1,  4,  1,  1,\n          1,  1,  4,  1,  1,  1,  1,  5,  1,  5,  1,  5,  1,  1,  1,  1,  1,  1,\n          4,  5,  1,  4,  1,  1,  4,  1,  1,  1], dtype=torch.int32),\n 'trx_src_type21': tensor([924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924, 924,\n         924, 924, 924, 924, 924, 924, 924, 924, 924, 924], dtype=torch.int32),\n 'trx_src_type22': tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15], dtype=torch.int32),\n 'trx_src_type31': tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n         5, 5, 5, 5], dtype=torch.int32),\n 'trx_src_type32': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n         3, 3, 3, 3], dtype=torch.int32),\n 'dial_event_time': tensor([1667213771]),\n 'dial_embedding': array([array([ 0.5861246 , -0.36235696,  0.5261107 , -0.5437779 , -0.26850584,\n                0.5051648 ,  0.28338927,  0.41900346, -0.5069374 ,  0.43422863,\n               -0.55960166, -0.41654128, -0.5128243 , -0.44769046,  0.40053606,\n               -0.35641098,  0.93669206,  0.5481931 ,  0.5752056 , -0.59243804,\n               -0.99993294, -0.4553127 , -0.4755965 , -0.28578532, -0.45421773,\n                0.45790836, -0.5305849 ,  0.5763296 ,  0.40722546, -0.55071485,\n                0.48157418, -0.99986506,  0.89420944,  0.85124516,  0.53785336,\n               -0.28301242,  0.42422208,  0.42789587,  0.574395  , -0.5519576 ,\n               -0.45743728,  0.30107698, -0.5976625 ,  0.46851674, -0.5701899 ,\n               -0.5492666 , -0.20363942,  0.5516806 , -0.26001537,  0.57397395,\n               -0.38518736,  0.38298297,  0.6127509 ,  0.22332808,  0.55340195,\n                0.57849693,  0.52137786,  0.4273537 ,  0.44340348, -0.5085831 ,\n                0.34285623,  0.48881322,  0.54428583, -0.3092848 , -0.4717679 ,\n               -0.4603833 ,  0.474779  , -0.11308196,  0.67228305, -0.5208953 ,\n               -0.40897432, -0.5264719 , -0.5291363 ,  0.3209452 ,  0.47227862,\n               -0.52053756,  0.42163476,  0.4907758 ,  0.29254127, -0.32504818,\n               -0.4206094 , -0.7108592 , -0.28020987,  0.48530498, -0.26435167,\n                0.53327715,  0.6922063 , -0.48060015,  0.42759693, -0.5071268 ,\n                0.27585465,  0.66592306, -0.40659112,  0.50725627, -0.5610064 ,\n               -0.44241667, -0.9836441 , -0.2547169 , -0.4766274 , -0.49502936,\n               -0.415208  ,  0.2143186 , -0.2987889 , -0.4648824 , -0.20534492,\n               -0.35777408,  0.2732587 ,  0.40882245, -0.57745284,  0.3067664 ,\n                0.11902833, -0.52777123, -0.28370172,  0.4028422 , -0.5609656 ,\n                0.9995529 , -0.5158801 ,  0.20738608,  0.4072816 , -0.4323279 ,\n               -0.67828774,  0.9999037 ,  0.5825434 , -0.5939237 ,  0.46405903,\n                0.4464506 , -0.78469586,  0.5311414 ,  0.2977799 ,  0.5612634 ,\n                0.25632608, -0.5978051 , -0.5349188 , -0.31076846, -0.9774109 ,\n               -0.43564937, -0.24447119,  0.23896879, -0.75152206, -0.32091978,\n                0.4189254 ,  0.78216493,  0.44172898, -0.49081272, -0.3641591 ,\n               -0.5880763 ,  0.5898201 , -0.48325855,  0.9999002 ,  0.8437197 ,\n               -0.43048534, -0.44492632,  0.97420824, -0.7186844 , -0.5570098 ,\n               -0.566698  , -0.29082343, -0.6654258 ,  0.56963426,  0.47081828,\n                0.22990328, -0.24370092, -0.2352102 , -0.5892389 ,  0.44494167,\n               -0.79249465, -0.4650119 ,  0.5267894 ,  0.44243863,  0.42562124,\n               -0.27991283,  0.57379955,  0.230337  , -0.48987812, -0.30551615,\n                0.5517911 ,  0.55468756, -0.30241993, -0.44247684, -0.30100718,\n                0.57546794, -0.2539698 , -0.60943305,  0.25447214, -0.40390274,\n               -0.45362526,  0.2731779 , -0.2794253 , -0.21340702,  0.3604907 ,\n               -0.56548405,  0.50506157, -0.23732822,  0.56906617,  0.47809833,\n                0.54837525, -0.49194512,  0.54415125,  0.51844573,  0.31902882,\n                0.40204218,  0.5603825 ,  0.2689673 ,  0.27197403, -0.1514318 ,\n               -0.8740265 ,  0.56398845,  0.22824559,  0.58251715, -0.42974484,\n               -0.45953518, -0.59861773,  0.71327   ,  0.56439495, -0.42897815,\n                0.5798918 ,  0.46773934, -0.39657062, -0.2378802 ,  0.27502862,\n               -0.5736758 , -0.47352716, -0.6722592 , -0.22896624, -0.3730594 ,\n                0.2899445 ,  0.5665652 ,  0.54721826,  0.4719126 , -0.34729722,\n               -0.40443057, -0.57498276,  0.4987923 ,  0.32244015, -0.4240698 ,\n                0.9622056 , -0.49601206,  0.49510032, -0.6204491 , -0.2002036 ,\n                0.50036454, -0.4473178 ,  0.35344946,  0.99805796,  0.59154534,\n               -0.592942  ,  0.21407627,  0.52354497,  0.41268298, -0.48521772,\n                0.28140298, -0.7078311 ,  0.88948715,  0.33503652,  0.33094987,\n               -0.99991256,  0.22843863,  0.47525615,  0.47381204,  0.57504034,\n                0.7411126 ,  0.4167193 ,  0.21669176,  0.9889838 , -0.7166503 ,\n               -0.41808605, -0.5469158 , -0.31790173, -0.5161778 , -0.39952818,\n               -0.54206043, -0.38202605, -0.58794534, -0.3543715 , -0.43134826,\n                0.5687225 ,  0.52587754, -0.9999406 ,  0.98610145,  0.2978421 ,\n               -0.41232842,  0.3403733 ,  0.30287138, -0.9999293 ,  0.58733404,\n               -0.4763127 , -0.44910252,  0.46822965, -0.7298167 , -0.4405402 ,\n                0.3727704 ,  0.46356004,  0.41030803,  0.7628894 ,  0.28245193,\n                0.61111426, -0.270012  ,  0.556985  ,  0.4257665 , -0.27029333,\n                0.50484437, -0.37183103,  0.44265047,  0.4999595 , -0.38799688,\n                0.2418928 , -0.7589473 ,  0.40163624,  0.4848817 ,  0.25161391,\n                0.5587932 , -0.23211308,  0.5626071 , -0.9517653 ,  0.41198033,\n               -0.49600154, -0.5821968 , -0.2814286 ,  0.516984  , -0.30163562,\n               -0.4367095 ,  0.27661827, -0.36593902,  0.9998878 ,  0.39060387,\n               -0.2079852 , -0.52342796,  0.5444824 ,  0.6110312 , -0.34848997,\n               -0.90854937, -0.44070354,  0.6764547 ,  0.45973173,  0.33737826,\n                0.5293427 ,  0.28811955,  0.5995119 , -0.42617863, -0.44995803,\n                0.42415556, -0.42935234,  0.45914105, -0.33065146, -0.5171092 ,\n                0.21035632, -0.57337546, -0.2853464 , -0.98309255,  0.7806415 ,\n                0.56693906,  0.42464834,  0.30945534,  0.24254538, -0.48878646,\n                0.74568814,  0.5884217 , -0.22935645, -0.2935303 , -0.54258883,\n               -0.43153566,  0.20876761, -0.3160768 , -0.66578454,  0.3454599 ,\n               -0.8386007 ,  0.42304665, -0.3614266 , -0.25206214, -0.53566533,\n                0.44032356, -0.9993904 , -0.5849484 ,  0.5051487 , -0.4014045 ,\n                0.2712141 , -0.49758774, -0.32804248,  0.439332  ,  0.3005358 ,\n               -0.3626039 ,  0.5812951 , -0.23198757,  0.20172097, -0.2798769 ,\n                0.26253918,  0.9553178 ,  0.7647437 ,  0.42802846, -0.49254447,\n                0.23376256, -0.5561056 , -0.55703336,  0.78150815,  0.24342155,\n               -0.5852512 ,  0.41110682,  0.2875263 ,  0.25317842, -0.5106478 ,\n                0.58410656, -0.5237058 , -0.59649444,  0.50167197, -0.48316747,\n               -0.4998591 , -0.26484436,  0.352398  , -0.5422597 ,  0.44525132,\n                0.2294264 ,  0.500678  ,  0.55131745,  0.43372375, -0.44890222,\n               -0.4622135 , -0.5752404 , -0.39962742, -0.40128496, -0.59337896,\n               -0.4119725 ,  0.99958473,  0.525214  ,  0.276669  , -0.58219206,\n                0.26519522,  0.47776082, -0.4421265 ,  0.27740398,  0.5234489 ,\n                0.47695202, -0.42741752,  0.2747813 ,  0.2297865 ,  0.2514265 ,\n                0.49071527,  0.0337517 ,  0.7211127 , -0.44969591,  0.9454418 ,\n               -0.53958184, -0.428276  , -0.999969  ,  0.44138485,  0.45845628,\n               -0.4231656 , -0.8226334 ,  0.22024725, -0.5483288 ,  0.48034722,\n               -0.294564  ,  0.550499  ,  0.41659853, -0.53008765,  0.5340813 ,\n               -0.5998888 ,  0.9991799 , -0.30441016,  0.42399347,  0.2107694 ,\n                0.24043393, -0.27206177, -0.27164498, -0.48306143,  0.4299963 ,\n               -0.3174249 ,  0.26056957, -0.9973354 ,  0.4880585 ,  0.57587236,\n                0.74196154, -0.25717622,  0.51607186, -0.75396067,  0.29390052,\n               -0.5914338 , -0.5515998 , -0.43555593,  0.32998127, -0.779251  ,\n                0.36248282, -0.49330166,  0.26093072, -0.42555988,  0.5656417 ,\n               -0.52615845,  0.47435606, -0.5325759 ,  0.4802042 , -0.5953775 ,\n               -0.35923624, -0.49000388,  0.35745072, -0.47585344,  0.9999318 ,\n               -0.53964347,  0.59239584, -0.39216846,  0.49132696, -0.31227228,\n                0.5754359 ,  0.89274216, -0.6059351 ,  0.48265797,  0.43333396,\n               -0.8579077 ,  0.23299511, -0.34150925, -0.9717488 , -0.5636012 ,\n                0.998555  ,  0.5092944 ,  0.28446692,  0.47331417,  0.68038166,\n                0.2853981 , -0.5030601 ,  0.29718778,  0.98784643,  0.3562716 ,\n                0.53580606,  0.5462418 ,  0.5679387 , -0.44244412, -0.5593543 ,\n                0.9998765 ,  0.9991473 ,  0.43274757,  0.5419471 , -0.3114958 ,\n               -0.41072738, -0.43264133,  0.4881751 ,  0.41381395,  0.5530232 ,\n               -0.42865556,  0.29211476, -0.4960779 , -0.29321975, -0.40178323,\n               -0.36906084, -0.49578995,  0.32192704, -0.58346224,  0.76665676,\n                0.5314921 ,  0.3219142 ,  0.51663333,  0.33679965,  0.29824713,\n               -0.22688775, -0.5098784 ,  0.4113808 , -0.47505322, -0.33284256,\n               -0.7435083 ,  0.32381433, -0.9999319 , -0.5947582 , -0.5659396 ,\n               -0.53087246,  0.4521587 ,  0.25375834,  0.3015906 , -0.5272999 ,\n               -0.45065725, -0.56061333,  0.45126665,  0.3729805 ,  0.583907  ,\n               -0.20818444, -0.56068975,  0.32716087, -0.59359705,  0.35781366,\n               -0.43581912, -0.4961764 , -0.9318475 , -0.599317  , -0.24221212,\n                0.2430013 , -0.31140766, -0.510825  ,  0.29593343,  0.43074352,\n                0.44782898, -0.41783252,  0.4407282 , -0.3849436 ,  0.5814481 ,\n                0.41446984,  0.33788627,  0.46330032, -0.45543963, -0.57591873,\n               -0.30394426, -0.5074441 , -0.5772593 ,  0.29256296, -0.49117184,\n                0.2819134 , -0.5535315 ,  0.26092285, -0.27207208,  0.56112194,\n                0.4309274 ,  0.34684438, -0.29120356,  0.4501213 ,  0.5319446 ,\n               -0.551997  ,  0.41279528,  0.56415117, -0.44929484, -0.56428844,\n                0.99993426,  0.5731602 ,  0.5640116 ,  0.5725814 , -0.43951088,\n                0.3446963 ,  0.40397272,  0.5213565 , -0.279819  ,  0.9855216 ,\n               -0.30784276,  0.3875437 ,  0.56406885,  0.43760437,  0.55397207,\n                0.5006159 ,  0.5909945 ,  0.9419355 ,  0.5235205 ,  0.5447641 ,\n                0.26976952,  0.51807034,  0.41461483,  0.4539236 ,  0.40994993,\n                0.44343123,  0.55746627, -0.34663337,  0.2897193 , -0.23928308,\n               -0.59647053, -0.50267863, -0.25741085, -0.28591922,  0.41869655,\n               -0.32912084, -0.43209034, -0.34517017,  0.46336314, -0.30934733,\n                0.20312954, -0.5881409 , -0.2938434 ,  0.6590139 , -0.58850145,\n                0.28188667, -0.54755133,  0.43771738, -0.97009695,  0.26082945,\n               -0.44286773, -0.5208494 , -0.5894131 , -0.95748043,  0.5381004 ,\n                0.3446926 , -0.09841778,  0.4708557 , -0.33234066,  0.37722695,\n               -0.211097  , -0.30310142,  0.2520331 , -0.9999171 ,  0.5171663 ,\n                0.53120977, -0.7785823 ,  0.4374682 ,  0.38897604,  0.23399888,\n                0.522324  , -0.42322937, -0.5515152 , -0.20512637,  0.29098526,\n               -0.26865247,  0.15604591,  0.4522138 , -0.4834777 , -0.46353045,\n                0.31214085, -0.456542  ,  0.22984654,  0.44777876, -0.32411754,\n                0.5665277 , -0.48291898,  0.5235942 , -0.33955985,  0.5484421 ,\n               -0.44355014, -0.47459188,  0.30981722, -0.6512812 , -0.5568638 ,\n               -0.5649999 ,  0.31866157, -0.5536363 ,  0.25272298,  0.58401746,\n               -0.42804214,  0.48109338, -0.36202648,  0.49238262, -0.41729593,\n                0.48269528, -0.9703076 , -0.36365196, -0.44630864, -0.58547276,\n                0.5833461 ,  0.44245622,  0.43731505,  0.2708788 , -0.57555   ,\n                0.22884914, -0.57688576,  0.58047223,  0.54825974, -0.5320485 ,\n                0.54526454, -0.44506142,  0.45516232, -0.5293222 ,  0.27473924,\n               -0.999903  , -0.5674314 ,  0.43662804,  0.52085376,  0.544718  ,\n               -0.4314669 , -0.29315847, -0.40231112, -0.5586304 ,  0.2090349 ,\n                0.28974694,  0.57587725,  0.49084753,  0.586206  , -0.30094928,\n               -0.410377  ,  0.98006964, -0.5944121 ,  0.4420693 ,  0.5800472 ,\n                0.45402497,  0.9711027 ,  0.50583243,  0.43582195,  0.32653892,\n               -0.59280026,  0.5232956 ,  0.5295302 ], dtype=float32)          ],\n       dtype=object),\n 'event_time': tensor([1646006400, 1648684800, 1651276800, 1653955200, 1656547200, 1659225600,\n         1661904000, 1664496000, 1667174400, 1669766400, 1672444800, 1675123200]),\n 'targets': tensor([[0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0],\n         [0, 0, 0, 0]], dtype=torch.int32)}"},"metadata":{}}],"execution_count":122},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"from ptls.data_load.feature_dict import FeatureDict\nfrom collections import defaultdict\nclass MultiModalDiffSplitDataset(FeatureDict, torch.utils.data.Dataset):\n    def __init__(\n        self,\n        data,\n        splitters,\n        source_features,\n        col_id,\n        source_names,\n        col_time='event_time',\n        *args, **kwargs\n    ):\n        \"\"\"\n        Dataset for multimodal learning.\n        Parameters:\n        -----------\n        data:\n            concatinated data with feature dicts.\n        splitter:\n            object from from `ptls.frames.coles.split_strategy`.\n            Used to split original sequence into subsequences which are samples from one client.\n        source_features:\n            list of column names \n        col_id:\n            column name with user_id\n        source_names:\n            column name with name sources\n        col_time:\n            column name with event_time\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        \n        self.data = data\n        self.splitters = splitters\n        self.col_time = col_time\n        self.col_id = col_id\n        self.source_names = source_names\n        self.source_features = source_features\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        feature_arrays = self.data[idx]\n        split_data = self.split_source(feature_arrays)\n        return self.get_splits(split_data)\n    \n    def __iter__(self):\n        for feature_arrays in self.data:\n            split_data = self.split_source(feature_arrays)\n            yield self.get_splits(split_data)\n            \n    def split_source(self, feature_arrays):\n        res = defaultdict(dict)\n        for feature_name, feature_array in feature_arrays.items():\n            if feature_name == self.col_id:\n                res[self.col_id] = feature_array\n            else:\n                source_name, feature_name_transform = self.get_names(feature_name)\n                res[source_name][feature_name_transform] = feature_array\n        for source in self.source_names:\n            if source not in res:\n                res[source] = {source_feature: torch.tensor([]) for source_feature in self.source_features[source]}\n        return res\n    \n    def get_names(self, feature_name):\n        idx_del = feature_name.find('_')\n        return feature_name[:idx_del], feature_name[idx_del + 1:]\n    \n    def get_splits(self, feature_arrays):\n        res = {}\n        print(feature_arrays)\n        for source_name, feature_array in feature_arrays.items():\n            if source_name != self.col_id:\n                local_date = feature_array[self.col_time]\n                if source_name not in self.splitters:\n                    continue\n                indexes = self.splitters[source_name].split(local_date)\n                res[source_name] = [{k: v[ix] for k, v in feature_array.items() if self.is_seq_feature(k, v)} for ix in indexes]\n        return res\n        \n    def collate_fn(self, batch, return_dct_labels=False):\n        dict_class_labels = get_dict_class_labels(batch)\n        batch = reduce(lambda x, y: {k: x[k] + y[k] for k in x if k in y}, batch)\n        padded_batch = collate_multimodal_feature_dict(batch)\n        if return_dct_labels:\n            return padded_batch, dict_class_labels\n        return padded_batch, dict_class_labels[list(dict_class_labels.keys())[0]]\n\nclass MultiModalDiffSplitIterableDataset(MultiModalDiffSplitDataset, torch.utils.data.IterableDataset):\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:28:52.355652Z","iopub.execute_input":"2025-01-17T04:28:52.356075Z","iopub.status.idle":"2025-01-17T04:28:52.366462Z","shell.execute_reply.started":"2025-01-17T04:28:52.356047Z","shell.execute_reply":"2025-01-17T04:28:52.365633Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"from ptls.frames import PtlsDataModule\nfrom ptls.frames.coles.split_strategy import SampleSlices\ntrainer = pl.Trainer(\n    max_epochs=12,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=512\n)\n\ndata_module = PtlsDataModule(\n    train_data=MultiModalDiffSplitIterableDataset(\n        data=train,\n        splitters={\n            \"trx\": SampleSlices(\n                split_count=2,\n                cnt_min=32,\n                cnt_max=180\n            ),\n            \"dial\": SampleSlices(\n                split_count=2,\n                cnt_min=2,\n                cnt_max=10\n            ),\n        },\n        source_features={\n            \"trx\": [\n                \"trx_event_type\",\n                \"trx_event_subtype\",\n                \"trx_src_type11\",\n                \"trx_src_type12\",\n                \"trx_dst_type11\",\n                \"trx_dst_type12\",\n                \"trx_src_type22\",\n                \"trx_src_type32\",\n                \"trx_event_time\"\n            ],\n            \"dial\": [\n                \"dial_embedding\",\n                \"dial_event_time\"\n            ],\n        },\n        col_id='client_id',\n        col_time='event_time',\n        source_names=['trx', 'dial'],\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:28:52.608978Z","iopub.execute_input":"2025-01-17T04:28:52.609261Z","iopub.status.idle":"2025-01-17T04:28:52.649487Z","shell.execute_reply.started":"2025-01-17T04:28:52.609239Z","shell.execute_reply":"2025-01-17T04:28:52.648874Z"}},"outputs":[],"execution_count":139},{"cell_type":"code","source":"from ptls.frames.abs_module import ABSModule\n\n\ndef first(iterable, default=None):\n    iterator = iter(iterable)\n    return next(iterator, default)\n\n\nclass M3CoLESModule(ABSModule):\n    \"\"\"\n    Multi-Modal Matching\n    Contrastive Learning for Event Sequences ([CoLES](https://arxiv.org/abs/2002.08232))\n\n    Subsequences are sampled from original sequence.\n    Samples from the same sequence are `positive` examples\n    Samples from the different sequences are `negative` examples\n    Embeddings for all samples are calculated.\n    Paired distances between all embeddings are calculated.\n    The loss function tends to make positive distances smaller and negative ones larger.\n\n    Parameters\n        seq_encoder:\n            Model which calculate embeddings for original raw transaction sequences\n            `seq_encoder` is trained by `CoLESModule` to get better representations of input sequences\n        head:\n            Model which helps to train. Not used during inference\n            Can be normalisation layer which make embedding l2 length equals 1\n            Can be MLP as `projection head` like in SymCLR framework.\n        loss:\n            loss object from `ptls.frames.coles.losses`.\n            There are paired and triplet loss. They are required sampling strategy\n            from `ptls.frames.coles.sampling_strategies`. Sampling strategy takes a relevant pairs or triplets from\n            pairwise distance matrix.\n        validation_metric:\n            Keep None. `ptls.frames.coles.metric.BatchRecallTopK` used by default.\n        optimizer_partial:\n            optimizer init partial. Network parameters are missed.\n        lr_scheduler_partial:\n            scheduler init partial. Optimizer are missed.\n\n    \"\"\"\n    def __init__(self,\n                 seq_encoders=None,\n                 mod_names=None,\n                 head=None,\n                 loss=None,\n                 validation_metric=None,\n                 optimizer_partial=None,\n                 lr_scheduler_partial=None):\n        torch.set_float32_matmul_precision('high')\n        if head is None:\n            head = Head(use_norm_encoder=True)\n\n        if loss is None:\n            loss = ContrastiveLoss(margin=0.5,\n                                   sampling_strategy=HardNegativePairSelector(neg_count=5))\n\n        if validation_metric is None:\n            validation_metric = BatchRecallTopK(K=4, metric='cosine')\n        \n        for k in seq_encoders.keys():\n            if type(seq_encoders[k]) is str:\n                seq_encoders[k] = seq_encoders[seq_encoders[k]]\n                \n        super().__init__(validation_metric,\n                         first(seq_encoders.values()),\n                         loss,\n                         optimizer_partial,\n                         lr_scheduler_partial)\n        \n        self.seq_encoders = torch.nn.ModuleDict(seq_encoders)\n        self._head = head   \n        self.y_h_cache = {'train':[], 'valid': []}\n        \n    @property\n    def metric_name(self):\n        return 'recall_top_k'\n\n    @property\n    def is_requires_reduced_sequence(self):\n        return True\n    \n    def forward(self, x):\n        res = {}\n        \n        for mod_name in x.keys():\n            res[mod_name] = self.seq_encoders[mod_name](x[mod_name])\n            \n        return res\n\n    def shared_step(self, x, y):\n        y_h = self(x)\n        \n        if self._head is not None:\n            y_h_head = {k: self._head(y_h_k) for k, y_h_k in y_h.items()}\n            y_h = y_h_head\n            \n        return y_h, y\n    \n    def _one_step(self, batch, _, stage):\n        y_h, y = self.shared_step(*batch)\n        y_h_list = list(y_h.values())\n        loss = self._loss(torch.cat(y_h_list), torch.cat([y, y]))\n        self.log(f'loss/{stage}', loss.detach())\n        \n        x, y = batch\n        for mod_name, mod_x in x.items():\n            self.log(f'seq_len/{stage}/{mod_name}', x[mod_name].seq_lens.float().mean().detach(), prog_bar=True)\n        \n        if stage == \"valid\":\n            n, d = y_h_list[0].shape\n            y_h_concat = torch.zeros((2*n, d), device = y_h_list[0].device)\n            \n            for i in range(2):\n                y_h_concat[range(i,2*n,2)] = y_h_list[i] \n            \n            if len(self.y_h_cache[stage]) <= 380:\n                self.y_h_cache[stage].append((y_h_concat.cpu(), {k: y_h_k.cpu() for k, y_h_k in y_h.items()} , \n                                             {k:x_k.seq_lens.cpu() for k, x_k in x.items()})) \n    \n        return loss\n    \n    def training_step(self, batch, _):\n        return self._one_step(batch, _, \"train\")\n    \n    def validation_step(self, batch, _):\n        return self._one_step(batch, _, \"valid\")\n    \n    def on_validation_epoch_end(self):        \n        #len_intervals = [(0, 10), (10, 20), (20, 30), (30, 40), (40, 60), (60, 80), (80, 120), (120, 160), (160, 240)]\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=100)\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=50)\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=1)\n        \n        \n        del self.y_h_cache[\"valid\"]\n        self.y_h_cache[\"valid\"] = []\n        \n    def log_recall_top_K(self, y_h_cache, len_intervals=None, stage=\"valid\", K=100):\n        y_h = torch.cat([item[0] for item in y_h_cache], dim = 0)\n        y_h_mods = defaultdict(list)\n        seq_lens_dict = defaultdict(list)\n        \n        for item in y_h_cache:\n            for k, emb in item[1].items():\n                y_h_mods[k].append(emb)\n                \n            for k, l in item[2].items():\n                seq_lens_dict[k].append(l)\n        \n        y_h_mods = {k: torch.cat(el, dim=0) for k ,el in y_h_mods.items()}\n        seq_lens_dict = {k: torch.cat(el) for k ,el in seq_lens_dict.items()}\n\n        #n, _ = y_h.shape\n        #y = torch.zeros((n,)).cpu().long()\n        #y[range(0,n,2)] = torch.arange(0, n//2)\n        #y[range(1,n,2)] = torch.arange(0, n//2)\n        #computed_metric = metric_real_recall_top_K(y_h, y, K=100)\n        y_h_bank, y_h_rmb = list(y_h_mods.values())\n        computed_metric_b2r = metric_recall_top_K_for_embs(y_h_bank, y_h_rmb, torch.arange(y_h_rmb.shape[0]), K=K)\n        computed_metric_r2b = metric_recall_top_K_for_embs(y_h_rmb, y_h_bank, torch.arange(y_h_rmb.shape[0]), K=K)\n        \n        if len_intervals != None:\n            for mod, seq_lens in seq_lens_dict.items():\n                for start, end in len_intervals:\n                    mask = ((seq_lens > start) & (seq_lens <= end))\n\n                    if torch.any(mask):\n                        #y_h_filtered = y_h[mask.repeat_interleave(2)]\n                        y_h_bank_filtered = y_h_bank[mask]\n                        y_h_rmb_filtered = y_h_rmb[mask]\n\n                        #y = torch.div(torch.arange(len(y_h_filtered)), 2, rounding_mode='floor')\n                        #recall = metric_real_recall_top_K(y_h_filtered, y, K=100)\n                        recall_r2b = metric_recall_top_K_for_embs(y_h_rmb_filtered, y_h_bank_filtered, torch.arange(y_h_rmb_filtered.shape[0]), K=100)\n                        recall_b2r = metric_recall_top_K_for_embs(y_h_bank_filtered, y_h_rmb_filtered, torch.arange(y_h_rmb_filtered.shape[0]), K=100)\n\n                        #self.log(f\"{mode}/R@100_len_from_{start}_to_{end}\", recall, prog_bar=True)\n                        self.log(f\"{stage}/{mod}/r2b_R@100_len_from_{start}_to_{end}\", recall_r2b, prog_bar=True)\n                        self.log(f\"{stage}/{mod}/b2r_R@100_len_from_{start}_to_{end}\", recall_b2r, prog_bar=True)\n        \n        #self.log(f\"{mode}/R@100\", computed_metric, prog_bar=True)\n        self.log(f\"{stage}/click2trx_R@{K}\", computed_metric_r2b, prog_bar=True)\n        self.log(f\"{stage}/trx2click_R@{K}\", computed_metric_b2r, prog_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:28:53.013637Z","iopub.execute_input":"2025-01-17T04:28:53.013974Z","iopub.status.idle":"2025-01-17T04:28:53.031674Z","shell.execute_reply.started":"2025-01-17T04:28:53.013948Z","shell.execute_reply":"2025-01-17T04:28:53.030645Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"from ptls.frames.coles.metric import BatchRecallTopK\nfrom ptls.nn.trx_encoder.encoders import IdentityEncoder\nimport ptls\nfrom functools import partial\nhead = ptls.nn.Head(\n    input_size=128,\n    use_norm_encoder=True,\n    hidden_layers_sizes=[128, 128],\n    objective=\"regression\",\n    num_classes=128\n)\nseq_encoders = {\n    \"trx\": ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            linear_projection_size=32,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            }\n        ),\n        type=\"gru\",\n        hidden_size=128\n    ),\n    \"dial\": ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            embeddings_noise=0.003,\n            linear_projection_size=32,\n            custom_embeddings={\n                \"embedding\": IdentityEncoder(output_size=768)\n            }\n        ),\n        type=\"gru\",\n        hidden_size=128\n    )\n}\npl_module = M3CoLESModule(\n    validation_metric=BatchRecallTopK(\n        K=1,\n        metric=\"cosine\"\n    ),\n    head=head,\n    seq_encoders=seq_encoders,\n    loss=ptls.frames.coles.losses.SoftmaxLoss(),\n    optimizer_partial=partial(torch.optim.AdamW,\n        lr=0.001,\n        weight_decay=1e-4\n    ),\n    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR,\n        step_size=1,\n        gamma=0.9\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:28:53.770090Z","iopub.execute_input":"2025-01-17T04:28:53.770411Z","iopub.status.idle":"2025-01-17T04:28:53.785526Z","shell.execute_reply.started":"2025-01-17T04:28:53.770382Z","shell.execute_reply":"2025-01-17T04:28:53.784812Z"}},"outputs":[],"execution_count":141},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:28:54.110170Z","iopub.execute_input":"2025-01-17T04:28:54.110471Z","iopub.status.idle":"2025-01-17T04:28:55.138975Z","shell.execute_reply.started":"2025-01-17T04:28:54.110447Z","shell.execute_reply":"2025-01-17T04:28:55.137714Z"}},"outputs":[{"name":"stdout","text":"defaultdict(<class 'dict'>, {'client_id': '000e047a31e50ba35f71c81962b4eb0b9a2d6080cf23a14f91447317dd14c788', 'trx': {'trx_event_type': tensor([]), 'trx_event_subtype': tensor([]), 'trx_src_type11': tensor([]), 'trx_src_type12': tensor([]), 'trx_dst_type11': tensor([]), 'trx_dst_type12': tensor([]), 'trx_src_type22': tensor([]), 'trx_src_type32': tensor([]), 'trx_event_time': tensor([])}, 'dial': {'dial_embedding': tensor([]), 'dial_event_time': tensor([])}})\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-142-ab636a42a0fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36msetup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_select_data_fetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creates the iterator inside the fetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mmax_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msized_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_batches\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmax_batches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_ITERATOR_RETURN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consumed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-138-bcb83747d82e>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_arrays\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0msplit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-138-bcb83747d82e>\u001b[0m in \u001b[0;36mget_splits\u001b[0;34m(self, feature_arrays)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msource_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_array\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mlocal_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msource_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'event_time'"],"ename":"KeyError","evalue":"'event_time'","output_type":"error"}],"execution_count":142},{"cell_type":"code","source":"# from ptls.preprocessing import PysparkDataPreprocessor\n\n# TARGETS_DATA_PATH = '/kaggle/working/targets/'\n# preprocessor_target = PysparkDataPreprocessor(\n#     col_id=\"client_id\",\n#     col_event_time=\"mon\",\n#     event_time_transformation=\"dt_to_timestamp\",\n#     cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n# )\n\n# for fold in tqdm(range(2)):\n    \n#     mm_dataset = spark.read.parquet(os.path.join(MM_DATA_PATH , f'fold={fold}'))\n#     targets = spark.read.parquet(os.path.join(TARGETS_DATA_PATH , f'fold={fold}'))\n#     targets = preprocessor_target.fit_transform(targets)\n    \n#     mm_dataset = mm_dataset.join(targets, on='client_id', how='left').drop(*['event_time', 'trans_count', 'diff_trans_date'])\n#     mm_dataset.write.parquet(os.path.join(MMT_DATA_PATH, f'fold={fold}'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Without mm_dataset","metadata":{}},{"cell_type":"code","source":"spark.read.parquet(os.path.join(DIAL_DATA_PATH, f'fold={1}'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T01:24:18.496776Z","iopub.execute_input":"2025-01-17T01:24:18.497277Z","iopub.status.idle":"2025-01-17T01:24:18.703295Z","shell.execute_reply.started":"2025-01-17T01:24:18.497249Z","shell.execute_reply":"2025-01-17T01:24:18.702080Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataFrame[client_id: string, event_time: array<bigint>, embedding: array<array<float>>]"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"spark.stop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T01:35:31.049398Z","iopub.execute_input":"2025-01-17T01:35:31.049816Z","iopub.status.idle":"2025-01-17T01:35:31.585866Z","shell.execute_reply.started":"2025-01-17T01:35:31.049794Z","shell.execute_reply":"2025-01-17T01:35:31.584869Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"**Get trx embeddings**","metadata":{}},{"cell_type":"code","source":"trx_train = ParquetDataset(ParquetFiles(os.path.join(TRX_DATA_PATH, f'fold={1}')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:19:02.871080Z","iopub.execute_input":"2025-01-17T02:19:02.871401Z","iopub.status.idle":"2025-01-17T02:19:02.876458Z","shell.execute_reply.started":"2025-01-17T02:19:02.871374Z","shell.execute_reply":"2025-01-17T02:19:02.875829Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"map_processed_trx = MemoryMapDataset(\n    data=trx_train,\n    i_filters=[\n        SeqLenFilter(min_seq_len=32),\n        ISeqLenLimit(max_seq_len=4096),\n        ToTorch(),\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:19:03.486293Z","iopub.execute_input":"2025-01-17T02:19:03.486574Z","iopub.status.idle":"2025-01-17T02:19:06.750512Z","shell.execute_reply.started":"2025-01-17T02:19:03.486553Z","shell.execute_reply":"2025-01-17T02:19:06.749596Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"**TrxDataLoader**","metadata":{}},{"cell_type":"code","source":"trx_train = PtlsDataModule(\n    train_data=ColesDataset(map_processed_trx,\n        splitter=SampleSlices(\n            split_count=5,\n            cnt_min=25,\n            cnt_max=200\n        ),\n    ),\n    train_num_workers=16,\n    train_batch_size=256,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:19:06.751732Z","iopub.execute_input":"2025-01-17T02:19:06.752069Z","iopub.status.idle":"2025-01-17T02:19:10.181947Z","shell.execute_reply.started":"2025-01-17T02:19:06.752033Z","shell.execute_reply":"2025-01-17T02:19:10.181258Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"from ptls.nn import TrxEncoder, RnnSeqEncoder\nfrom ptls.frames.coles import CoLESModule\nfrom functools import partial\nimport torch\ntrx_encoder_params = dict(\n    embeddings_noise=0.003,\n    numeric_values={\"amount\": \"log\"},\n    embeddings={\n        'event_type': {\"in\": 58, \"out\": 24},\n        'event_subtype': {\"in\": 59, \"out\": 24},\n        'src_type11': {\"in\": 85, \"out\": 24},\n        'src_type12': {\"in\": 349, \"out\": 24},\n        'dst_type11': {\"in\": 84, \"out\": 24},\n        'dst_type12': {\"in\": 417, \"out\": 24},\n        'src_type22': {\"in\": 90, \"out\": 24},\n        'src_type32': {\"in\": 91, \"out\": 24}\n    }\n)\n\nseq_encoder = RnnSeqEncoder(\n    trx_encoder=TrxEncoder(**trx_encoder_params),\n    hidden_size=256,\n    type=\"gru\",\n)\n\nmodel = CoLESModule(\n    seq_encoder=seq_encoder,\n    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n    lr_scheduler_partial=partial(\n        torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:19:10.183132Z","iopub.execute_input":"2025-01-17T02:19:10.183590Z","iopub.status.idle":"2025-01-17T02:19:10.260809Z","shell.execute_reply.started":"2025-01-17T02:19:10.183561Z","shell.execute_reply":"2025-01-17T02:19:10.260030Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"trainer = pl.Trainer(\n    max_epochs=12,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:19:10.261640Z","iopub.execute_input":"2025-01-17T02:19:10.261882Z","iopub.status.idle":"2025-01-17T02:19:10.322290Z","shell.execute_reply.started":"2025-01-17T02:19:10.261862Z","shell.execute_reply":"2025-01-17T02:19:10.321739Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"trainer.fit(model, trx_train)\nprint(trainer.logged_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T02:19:10.495463Z","iopub.execute_input":"2025-01-17T02:19:10.495675Z","iopub.status.idle":"2025-01-17T02:23:08.151852Z","shell.execute_reply.started":"2025-01-17T02:19:10.495657Z","shell.execute_reply":"2025-01-17T02:23:08.151020Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7255653c3c4b399323a944b24f08cb"}},"metadata":{}},{"name":"stdout","text":"{'loss': tensor(10.6936), 'seq_len': tensor(89.0432)}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**now use pandas over pyspark**","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# FOLD = 1\n# mm_dataset = pd.read_parquet(os.path.join(MM_DATA_PATH, f'fold={FOLD}'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.271259Z","iopub.status.idle":"2025-01-16T21:49:33.271698Z","shell.execute_reply":"2025-01-16T21:49:33.271535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mm_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.272546Z","iopub.status.idle":"2025-01-16T21:49:33.272866Z","shell.execute_reply":"2025-01-16T21:49:33.272730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_emb = mm_dataset['dial_embedding'][1].copy()\n# print(np.array(test_emb).shape)\n# print(np.vstack(test_emb).shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.273540Z","iopub.status.idle":"2025-01-16T21:49:33.273940Z","shell.execute_reply":"2025-01-16T21:49:33.273743Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TRX**\n\n380 - среднее количество элементов\n\n10000 - максимальное\n\n**DIAL**\n\n91 - max\n\n5 - avg","metadata":{}},{"cell_type":"code","source":"# import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.275114Z","iopub.status.idle":"2025-01-16T21:49:33.275522Z","shell.execute_reply":"2025-01-16T21:49:33.275342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_min_max_date(dates_list):\n#     min_date = None\n#     max_date = None\n#     for date_list in mm_dataset['trx_event_time']:\n#         if type(date_list) is np.ndarray:\n#             max_in_list = date_list.max()\n#             min_in_list = date_list.min()\n#             if not min_date or min_in_list < min_date:\n#                 min_date = min_in_list\n#             if not max_date or max_in_list > max_date:\n#                 max_date = max_in_list\n#     return min_date, max_date","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.276499Z","iopub.status.idle":"2025-01-16T21:49:33.276826Z","shell.execute_reply":"2025-01-16T21:49:33.276681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trx_min_date, trx_max_date = get_min_max_date(mm_dataset['trx_event_time'])\n# print(f\"\"\"min_date = {datetime.datetime.fromtimestamp(trx_min_date)}\n# max_date = {datetime.datetime.fromtimestamp(trx_max_date)}\"\"\")\n# print((datetime.datetime.fromtimestamp(trx_max_date) - datetime.datetime.fromtimestamp(trx_min_date)).total_seconds() // 3600)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.277610Z","iopub.status.idle":"2025-01-16T21:49:33.277985Z","shell.execute_reply":"2025-01-16T21:49:33.277804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trx_max_len = mm_dataset['trx_event_time'].str.len().agg(['max'])['max']\n# trx_mean_len = mm_dataset['trx_event_time'].str.len().agg(['mean'])['mean']\n# print(f'trx_max_len = {trx_max_len}\\ntrx_mean_len = {trx_mean_len}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.279003Z","iopub.status.idle":"2025-01-16T21:49:33.279443Z","shell.execute_reply":"2025-01-16T21:49:33.279201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dial_max_len = mm_dataset['dial_event_time'].str.len().agg(['max'])['max']\n# dial_mean_len = mm_dataset['dial_event_time'].str.len().agg(['mean'])['mean']\n# print(f'dial_max_len = {dial_max_len}\\ndial_mean_len = {dial_mean_len}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.280102Z","iopub.status.idle":"2025-01-16T21:49:33.280421Z","shell.execute_reply":"2025-01-16T21:49:33.280300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trx_date_cols = [col for col in mm_dataset.columns if col.startswith(\"trx\")]\n# dial_date_cols = [col for col in mm_dataset.columns if col.startswith(\"dial\")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.281114Z","iopub.status.idle":"2025-01-16T21:49:33.281457Z","shell.execute_reply":"2025-01-16T21:49:33.281324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from tqdm import tqdm\n\n# tqdm.pandas(desc='My bar!')\n\n\n# def add_null(\n#     timestamps_list,\n#     max_date,\n#     *columns,\n    \n# ):\n#     if type(timestamps_list) is np.ndarray:\n#         prev_time = datetime.datetime.fromtimestamp(timestamps_list[0])\n#         filled_event_time = []\n#         for time in timestamps_list:\n#             time = datetime.datetime.fromtimestamp(time)\n#             difference_minutes = int((time - prev_time).total_seconds() // 3600)\n#             if prev_time < time and difference_minutes > 1:\n#                 for minute in range(difference_minutes):\n#                     prev_time += datetime.timedelta(hours=1)\n#                     filled_event_time.append(int(prev_time.timestamp()))\n#             filled_event_time.append(int(time.timestamp()))\n    \n#         event_time_index = 0\n#         new_columns = [[] for i in range(len(columns))]\n#         for i in range(len(filled_event_time)):\n#             if i < len(filled_event_time) - 1 and filled_event_time[i] == timestamps_list[event_time_index]:\n#                 for j in range(len(columns)):\n#                     new_columns[j].append(columns[j][event_time_index])\n#                 event_time_index += 1\n#             else:\n#                 for j in range(len(columns)):\n#                     new_columns[j].append(0)\n                    \n#         return [filled_event_time] + list(new_columns)\n#     else:\n#         return [timestamps_list] + list(columns)\n# cols = [col for col in mm_dataset.columns if col.startswith(\"trx\") and col != 'trx_event_time']\n# cols_with_time = [col for col in mm_dataset.columns if col.startswith(\"trx\")]\n# # add_null(mm_dataset['trx_event_time'][0], *(mm_dataset[col] for col in cols), max_date=trx_max_date)\n# result = mm_dataset.progress_apply(\n#     lambda row: add_null(row[\"trx_event_time\"], trx_max_date, *(row[col] for col in cols)),\n#     axis=1\n# )\n# result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T21:49:33.282140Z","iopub.status.idle":"2025-01-16T21:49:33.282469Z","shell.execute_reply":"2025-01-16T21:49:33.282340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}