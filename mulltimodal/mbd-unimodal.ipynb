{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightning\n!pip install pyspark\n!pip install pytorch-lifestream","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=\"79f2120f8d4212aceb2c60b3c89a1b6727c19cff\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download \n\nhf_hub_download(repo_id=\"ai-lab/MBD-mini\", filename=\"ptls.tar.gz\", repo_type=\"dataset\", local_dir=\"/kaggle/working/\")\nhf_hub_download(repo_id=\"ai-lab/MBD-mini\", filename=\"targets.tar.gz\", repo_type=\"dataset\", local_dir=\"/kaggle/working/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -xf ptls.tar.gz\n!tar -xf targets.tar.gz","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport pyspark\nfrom pyspark.sql import SparkSession\n# import pyspark.sql.functions as F\nfrom pyspark.sql import types as T\nimport time\nimport datetime\nfrom ptls.data_load.datasets import ParquetDataset, ParquetFiles\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, ArrayType\nfrom tqdm.notebook import tqdm\nfrom ptls.preprocessing import PysparkDataPreprocessor\nimport pytorch_lightning as pl\nfrom ptls.data_load.datasets import MemoryMapDataset\nfrom ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\nfrom ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\nfrom ptls.frames.coles import CoLESModule\nfrom ptls.frames import PtlsDataModule\nfrom ptls.frames.coles import ColesDataset\nfrom ptls.frames.coles.split_strategy import SampleSlices\nimport torch\nimport numpy as np\nimport pandas as pd\nimport calendar\nfrom glob import glob\nfrom ptls.data_load.utils import collate_feature_dict\n\nfrom ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\nfrom datetime import datetime\nfrom ptls.data_load.padded_batch import PaddedBatch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 0\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"spark_conf = pyspark.SparkConf()\nspark_conf.setMaster(\"local[*]\").setAppName(\"JoinModality\")\nspark_conf.set(\"spark.driver.maxResultSize\", \"16g\")\nspark_conf.set(\"spark.executor.memory\", \"32g\")\nspark_conf.set(\"spark.executor.memoryOverhead\", \"16g\")\nspark_conf.set(\"spark.driver.memory\", \"32g\")\nspark_conf.set(\"spark.driver.memoryOverhead\", \"16g\")\nspark_conf.set(\"spark.cores.max\", \"8\")\nspark_conf.set(\"spark.sql.shuffle.partitions\", \"200\")\nspark_conf.set(\"spark.local.dir\", \"../../spark_local_dir\")\n\n\nspark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\nspark.sparkContext.getConf().getAll()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/ptls/trx_supervised","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TARGETS_DATA_PATH = '/kaggle/working/targets/'\nTRX_DATA_PATH = '/kaggle/working/ptls/trx/'\nTRX_SUPERVISED_PATH = '/kaggle/working/ptls/trx_supervised/'\n\npreprocessor_target = PysparkDataPreprocessor(\n    col_id=\"client_id\",\n    col_event_time=\"mon\",\n    event_time_transformation=\"dt_to_timestamp\",\n    cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for fold in range(5):\n    targets = spark.read.parquet(os.path.join(TARGETS_DATA_PATH , f'fold={fold}'))\n    trx = spark.read.parquet(os.path.join(TRX_DATA_PATH , f'fold={fold}'))\n    \n    targets = preprocessor_target.fit_transform(targets).drop(*['event_time' ,'trans_count', 'diff_trans_date'])\n    trx = trx.join(targets, on='client_id', how='left')\n    trx.write.mode('overwrite').parquet(os.path.join(TRX_SUPERVISED_PATH, f'fold={fold}'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"spark.stop()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\nfrom ptls.data_load import IterableChain\nfrom datetime import datetime\nfrom ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\nfrom ptls.data_load.iterable_processing.feature_filter import FeatureFilter\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\nimport torch\nfrom functools import partial\nfrom torch.utils.data import DataLoader\nfrom ptls.data_load.padded_batch import PaddedBatch\nfrom ptls.data_load.utils import collate_feature_dict\nfrom tqdm import tqdm\nimport ptls\n\nclass TargetToTorch(IterableProcessingDataset):\n    def __init__(self, col_target):\n        super().__init__()\n        self.col_target = col_target\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features[self.col_target] = np.stack(np.array(features[self.col_target]))\n            features[self.col_target] = torch.tensor(features[self.col_target])\n            yield features\n\nclass DeleteNan(IterableProcessingDataset):\n    def __init__(self, col_name):\n        super().__init__()\n        self.col_name = col_name\n    \n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            if features[self.col_name] is not None:\n                yield features\n\n\nclass DialToTorch(IterableProcessingDataset):\n    def __init__(self, col_time, col_embeds):\n        super().__init__()\n        self._year=2022\n        self.col_embeds = col_embeds\n        self.col_time = col_time\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n            if features[self.col_time] is None:\n                features[self.col_time] = torch.tensor([0])\n            if features[self.col_embeds] is None:\n                features[self.col_embeds] = torch.zeros(768)\n            \n            for key, tens in features.items():\n                if key == self.col_embeds:\n                    features[key] = torch.tensor(tens.tolist())\n\n            yield features\n\nclass GetSplit(IterableProcessingDataset):\n    def __init__(\n        self,\n        start_month,\n        end_month,\n        year=2022,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self.start_month = start_month\n        self.end_month = end_month\n        self._year = year\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            for month in range(self.start_month, self.end_month+1):\n                features = rec[0] if type(rec) is tuple else rec\n                features = features.copy()\n                \n                if month == 12:\n                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n                else:\n                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n                    \n                year_event_time = datetime(self._year, 1, 1).timestamp()\n                \n                mask = features[self._col_time] < month_event_time\n                for key, tensor in features.items():\n                    if key.startswith('target'):\n                        features[key] = tensor[month - 1].tolist()    \n                    elif key != self._col_id:\n                        features[key] = tensor[mask] \n                            \n                features[self._col_id] += '_month=' + str(month)\n\n                yield features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"markdown","source":"**load data**","metadata":{}},{"cell_type":"code","source":"train = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=0'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=1'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=2'),\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch()\n    ],\n    shuffle_files=True\n)\n\nvalid = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_DATA_PATH, 'fold=3')\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# next(iter(train))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Create data module**","metadata":{}},{"cell_type":"code","source":"data_module = ptls.frames.PtlsDataModule(\n    train_data=ptls.frames.coles.ColesIterableDataset(\n        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n            split_count=3,\n            cnt_min=16,\n            cnt_max=180\n        ),\n        data=train\n    ),\n    valid_data=ptls.frames.coles.ColesIterableDataset(\n        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n            split_count=3,\n            cnt_min=16,\n            cnt_max=180\n        ),\n        data=valid\n    ),\n    train_batch_size=64,\n    train_num_workers=0,\n    valid_batch_size=32,\n    valid_num_workers=0\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Baseline CoLES module**","metadata":{}},{"cell_type":"code","source":"optimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=2,\n    gamma=0.9025\n)\n\nseq_encoder = ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            },\n            numeric_values={\n                'amount': 'log'\n            }\n        ),\n        type='gru',\n        hidden_size=256\n    )\n\npl_module = ptls.frames.coles.CoLESModule(\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n        K=4,\n        metric='cosine'\n    ),\n    seq_encoder=seq_encoder,\n    optimizer_partial=optimizer_partial,\n    lr_scheduler_partial=lr_scheduler_partial\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"MBD_My_Code\", log_model=\"all\", name=\"mbd_uni_baseline\")\n\ntrainer = pl.Trainer(\n    logger=wandb_logger,\n    max_epochs=20,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference task**","metadata":{}},{"cell_type":"code","source":"from ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.feature_filter import FeatureFilter\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n\ninference_dataset = ptls.data_load.datasets.ParquetDataset(\n    data_files=[os.path.join(TRX_SUPERVISED_PATH, 'fold=4')],\n    i_filters=[\n        ISeqLenLimit(max_seq_len=4096),\n        ToTorch(),\n        FeatureFilter(\n            keep_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        GetSplit(\n            start_month=1,\n            end_month=12,\n            col_id='client_id'\n        )\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_dl = DataLoader(\n    dataset=inference_dataset,\n    shuffle=False,\n    num_workers=0,\n    batch_size=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport numpy as np\nfrom itertools import chain\nfrom ptls.data_load.padded_batch import PaddedBatch\nfrom datetime import datetime\nfrom ptls.custom_layers import StatPooling\nfrom ptls.nn.seq_step import LastStepEncoder\n\n\nclass InferenceModuleMultimodal(pl.LightningModule):\n    def __init__(\n        self,\n        model,\n        pandas_output=True,\n        col_id='client_id',\n        target_col_names=None,\n        model_out_name='emb',\n        model_type='notab'\n    ):\n        super().__init__()\n\n        self.model = model\n        self.pandas_output = pandas_output\n        self.target_col_names = target_col_names\n        self.col_id = col_id\n        self.model_out_name = model_out_name\n        self.model_type = model_type\n\n        self.stat_pooler = StatPooling()\n        self.last_step = LastStepEncoder()\n\n    def forward(self, x):\n        x_len = len(x)\n        if x_len == 3:\n            x, batch_ids, target_cols = x\n        else: \n            x, batch_ids = x\n        if 'seq_encoder' in dir(self.model):\n            out = self.model.seq_encoder(x)\n        else:\n            out = self.model(x)\n            \n        if x_len == 3:\n            target_cols = torch.tensor(target_cols)\n            x_out = {\n                self.col_id: batch_ids,\n                self.model_out_name: out\n            }\n            if len(target_cols.size()) > 1:\n                for idx, target_col in enumerate(self.target_col_names):\n                    x_out[target_col] = target_cols[:, idx]\n            else: \n                x_out[self.target_col_names[0]] = target_cols[::4]\n        else:\n            x_out = {\n                self.col_id: batch_ids,\n                self.model_out_name: out\n            }\n\n        if self.pandas_output:\n            return self.to_pandas(x_out)\n        return x_out\n\n    @staticmethod\n    def to_pandas(x):\n        expand_cols = []\n        scalar_features = {}\n\n        for k, v in x.items():\n            if type(v) is torch.Tensor:\n                v = v.cpu().numpy()\n\n            if type(v) is list or len(v.shape) == 1:\n                scalar_features[k] = v\n            elif len(v.shape) == 2:\n                expand_cols.append(k)\n            else:\n                scalar_features[k] = None\n\n        dataframes = [pd.DataFrame(scalar_features)]\n        for col in expand_cols:\n            v = x[col].cpu().numpy()\n            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n\n        return pd.concat(dataframes, axis=1)\n\ndef collate_feature_dict_with_target(batch, col_id='client_id', target_col_names=None):\n    batch_ids = []\n    target_cols = []\n    for sample in batch:\n        batch_ids.append(sample[col_id])\n        del sample[col_id]\n        \n        if target_col_names is not None:\n            sample_targets = []\n            for target_col in target_col_names:\n                sample_targets.append(sample[target_col])\n                del sample[target_col]\n            target_cols.append(sample_targets)\n                \n            \n    padded_batch = collate_feature_dict(batch)\n    if target_col_names is not None:\n        return padded_batch, batch_ids, target_cols\n    return padded_batch, batch_ids","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_col_names = [\n    'target_1',\n    'target_2',\n    'target_3',\n    'target_4'\n]\n\ncollate_fn = partial(\n    collate_feature_dict_with_target,\n    target_col_names=target_col_names\n)\n\ninference_dl = DataLoader(\n    dataset=inference_dataset,\n    collate_fn=collate_fn,\n    shuffle=False,\n    num_workers=0,\n    batch_size=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inf_module = InferenceModuleMultimodal(\n    model=pl_module,\n    pandas_output=True,\n    col_id='client_id',\n    target_col_names=target_col_names\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inf_embeddings = pd.concat(trainer.predict(inf_module, inference_dl))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inf_embeddings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**downstream task**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndwns_train, dwns_test = train_test_split(inf_embeddings, test_size=0.2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"targets_train = np.array(\n    [\n        dwns_train['target_1'].to_numpy(),\n        dwns_train['target_2'].to_numpy(),\n        dwns_train['target_3'].to_numpy(),\n        dwns_train['target_4'].to_numpy()\n    ]\n).T\ntargets_test = np.array(\n    [\n        dwns_test['target_1'].to_numpy(),\n        dwns_test['target_2'].to_numpy(),\n        dwns_test['target_3'].to_numpy(),\n        dwns_test['target_4'].to_numpy()\n    ]\n).T\n\ndwns_train = dwns_train.drop(columns=[\n    'client_id',\n    'target_1',\n    'target_2',\n    'target_3',\n    'target_4'\n]).to_numpy()\n\ndwns_test = dwns_test.drop(columns=[\n    'client_id',\n    'target_1',\n    'target_2',\n    'target_3',\n    'target_4'\n]).to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nmodels = [LGBMClassifier(\n    n_estimators=500,\n    boosting_type='gbdt',\n    subsample=0.5,\n    subsample_freq=1,\n    learning_rate=0.02,\n    feature_fraction=0.75,\n    max_depth=6,\n    lambda_l1=1,\n    lambda_l2=1,\n    min_data_in_leaf=50,\n    random_state=42,\n    n_jobs=8,\n    verbose=-1\n) for _ in range(4)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for target_id in range(4):\n    models[target_id].fit(dwns_train, targets_train[:, target_id])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n\nfor i in range(len(models)):\n    preds = models[i].predict_proba(dwns_test)\n    print(f\"ROC-AUC target_{i} = {roc_auc_score(targets_test[:, i], preds[:, 1])}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Regional Attention","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nfrom ptls.data_load import PaddedBatch\nfrom ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\nfrom ptls.nn.seq_encoder.transformer_encoder import TransformerEncoder\nfrom ptls.nn.seq_encoder.longformer_encoder import LongformerEncoder\nfrom ptls.nn.seq_encoder.custom_encoder import Encoder\nfrom ptls.nn.trx_encoder import TrxEncoder\nfrom ptls.nn.seq_encoder.containers import SeqEncoderContainer\nimport torch.nn.functional as F\n\nclass RnnSeqEncoderRegAttn(SeqEncoderContainer):\n    def __init__(self,\n                 trx_encoder=None,\n                 input_size=None,\n                 is_reduce_sequence=True,\n                 **seq_encoder_params,\n                 ):\n        super().__init__(\n            trx_encoder=trx_encoder,\n            seq_encoder_cls=RnnEncoder,\n            input_size=input_size,\n            seq_encoder_params=seq_encoder_params,\n            is_reduce_sequence=is_reduce_sequence,\n        )\n        \n        self.reg_seq_encoder = RnnEncoder(\n            input_size=input_size if input_size is not None else trx_encoder.output_size,\n            is_reduce_sequence=is_reduce_sequence,\n            **seq_encoder_params,\n        )\n\n        self.emb_dim = 256\n        self.regional_attention = nn.MultiheadAttention(\n            embed_dim=self.emb_dim,\n            num_heads=8,\n            dropout=0.3,\n            batch_first=True\n        )\n\n    def forward(self, x, names=None, seq_len=None, h_0=None):\n        # print(f\"x_in = {x.payload['amount'].size()}\")\n        x = self.trx_encoder(x)\n\n        x_new = x.payload\n        \n        segment_length = 10\n        pad_length = (segment_length - (x_new.size()[1] % segment_length)) % segment_length\n        padded_x_new = F.pad(x_new, ((0, 0, 0, pad_length, 0, 0)), 'constant', 0)\n        segmented_tensors = torch.stack(torch.split(padded_x_new, segment_length, dim=1)).to(x_new.device)\n        \n        regional_embeddings = torch.Tensor().to(x.device)\n        for tensor in segmented_tensors:\n            tensor = PaddedBatch(tensor.permute(1, 0, 2), [tensor.size()[0]] * tensor.size()[1])\n            regional_embed = self.reg_seq_encoder(tensor)\n            regional_embeddings = torch.cat((regional_embeddings, regional_embed), 0)\n        \n        regional_embeddings = regional_embeddings[:len(regional_embeddings) - pad_length, :]\n        # layer_norm = nn.LayerNorm([regional_embeddings.size()[0], regional_embeddings.size()[1]])\n        # layer_norm.to(x.device)\n        # regional_embeddings = layer_norm(regional_embeddings)\n        # print(regional_embeddings.size())\n        if regional_embeddings.size()[1] != self.emb_dim:\n            regional_embeddings = F.pad(regional_embeddings, ((0, abs(regional_embeddings.size()[1] - self.emb_dim), 0, 0)), 'constant', 0)\n        x_reg_embed, _ = self.regional_attention(regional_embeddings, regional_embeddings, regional_embeddings)\n        if regional_embeddings.size()[1] != x_new.size()[0]:\n            x_reg_embed = x_reg_embed[:, :-abs(regional_embeddings.size()[1] - x_new.size()[0])]\n        x_reg_embed = x_reg_embed.permute(1, 0)\n        x_reg_embed = x_reg_embed[:, :, None]\n        x_new = x_new + x_reg_embed\n        x_new.to(x.device)\n        x_new = PaddedBatch(x_new, x.seq_lens)\n        # x_new.to(x.device)\n        x = self.seq_encoder(x_new, h_0)\n        # print(f\"rnn_x_size = {x.size()}\")\n        return x\n    \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=2,\n    gamma=0.9025\n)\n\nseq_encoder = RnnSeqEncoderRegAttn(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            },\n            numeric_values={\n                'amount': 'log'\n            }\n        ),\n        type='gru',\n        hidden_size=256\n    )\n\npl_module = ptls.frames.coles.CoLESModule(\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n        K=4,\n        metric='cosine'\n    ),\n    seq_encoder=seq_encoder,\n    optimizer_partial=optimizer_partial,\n    lr_scheduler_partial=lr_scheduler_partial\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"MBD_My_Code\", log_model=\"all\", name=\"mdb_uni_regattn\")\n\ntrainer = pl.Trainer(\n    logger=wandb_logger,\n    max_epochs=15,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**inference**","metadata":{}},{"cell_type":"code","source":"from ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\nfrom ptls.data_load.iterable_processing.feature_filter import FeatureFilter\nfrom ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n\ninference_dataset = ptls.data_load.datasets.ParquetDataset(\n    data_files=[os.path.join(TRX_SUPERVISED_PATH, 'fold=4')],\n    i_filters=[\n        ISeqLenLimit(max_seq_len=4096),\n        ToTorch(),\n        FeatureFilter(\n            keep_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        GetSplit(\n            start_month=1,\n            end_month=12,\n            col_id='client_id'\n        )\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_dl = DataLoader(\n    dataset=inference_dataset,\n    shuffle=False,\n    num_workers=0,\n    batch_size=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport numpy as np\nfrom itertools import chain\nfrom ptls.data_load.padded_batch import PaddedBatch\nfrom datetime import datetime\nfrom ptls.custom_layers import StatPooling\nfrom ptls.nn.seq_step import LastStepEncoder\n\n\nclass InferenceModuleMultimodal(pl.LightningModule):\n    def __init__(\n        self,\n        model,\n        pandas_output=True,\n        col_id='client_id',\n        target_col_names=None,\n        model_out_name='emb',\n        model_type='notab'\n    ):\n        super().__init__()\n\n        self.model = model\n        self.pandas_output = pandas_output\n        self.target_col_names = target_col_names\n        self.col_id = col_id\n        self.model_out_name = model_out_name\n        self.model_type = model_type\n\n        self.stat_pooler = StatPooling()\n        self.last_step = LastStepEncoder()\n\n    def forward(self, x):\n        x_len = len(x)\n        if x_len == 3:\n            x, batch_ids, target_cols = x\n        else: \n            x, batch_ids = x\n        if 'seq_encoder' in dir(self.model):\n            out = self.model.seq_encoder(x)\n        else:\n            out = self.model(x)\n            \n        if x_len == 3:\n            target_cols = torch.tensor(target_cols)\n            x_out = {\n                self.col_id: batch_ids,\n                self.model_out_name: out\n            }\n            if len(target_cols.size()) > 1:\n                for idx, target_col in enumerate(self.target_col_names):\n                    x_out[target_col] = target_cols[:, idx]\n            else: \n                x_out[self.target_col_names[0]] = target_cols[::4]\n        else:\n            x_out = {\n                self.col_id: batch_ids,\n                self.model_out_name: out\n            }\n\n        if self.pandas_output:\n            return self.to_pandas(x_out)\n        return x_out\n\n    @staticmethod\n    def to_pandas(x):\n        expand_cols = []\n        scalar_features = {}\n\n        for k, v in x.items():\n            if type(v) is torch.Tensor:\n                v = v.cpu().numpy()\n\n            if type(v) is list or len(v.shape) == 1:\n                scalar_features[k] = v\n            elif len(v.shape) == 2:\n                expand_cols.append(k)\n            else:\n                scalar_features[k] = None\n\n        dataframes = [pd.DataFrame(scalar_features)]\n        for col in expand_cols:\n            v = x[col].cpu().numpy()\n            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n\n        return pd.concat(dataframes, axis=1)\n\ndef collate_feature_dict_with_target(batch, col_id='client_id', target_col_names=None):\n    batch_ids = []\n    target_cols = []\n    for sample in batch:\n        batch_ids.append(sample[col_id])\n        del sample[col_id]\n        \n        if target_col_names is not None:\n            sample_targets = []\n            for target_col in target_col_names:\n                sample_targets.append(sample[target_col])\n                del sample[target_col]\n            target_cols.append(sample_targets)\n                \n            \n    padded_batch = collate_feature_dict(batch)\n    if target_col_names is not None:\n        return padded_batch, batch_ids, target_cols\n    return padded_batch, batch_ids","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_col_names = [\n    'target_1',\n    'target_2',\n    'target_3',\n    'target_4'\n]\n\ncollate_fn = partial(\n    collate_feature_dict_with_target,\n    target_col_names=target_col_names\n)\n\ninference_dl = DataLoader(\n    dataset=inference_dataset,\n    collate_fn=collate_fn,\n    shuffle=False,\n    num_workers=0,\n    batch_size=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inf_module = InferenceModuleMultimodal(\n    model=pl_module,\n    pandas_output=True,\n    col_id='client_id',\n    target_col_names=target_col_names\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inf_embeddings = pd.concat(trainer.predict(inf_module, inference_dl))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**downstream**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndwns_train, dwns_test = train_test_split(inf_embeddings, test_size=0.2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"targets_train = np.array(\n    [\n        dwns_train['target_1'].to_numpy(),\n        dwns_train['target_2'].to_numpy(),\n        dwns_train['target_3'].to_numpy(),\n        dwns_train['target_4'].to_numpy()\n    ]\n).T\ntargets_test = np.array(\n    [\n        dwns_test['target_1'].to_numpy(),\n        dwns_test['target_2'].to_numpy(),\n        dwns_test['target_3'].to_numpy(),\n        dwns_test['target_4'].to_numpy()\n    ]\n).T\n\ndwns_train = dwns_train.drop(columns=[\n    'client_id',\n    'target_1',\n    'target_2',\n    'target_3',\n    'target_4'\n]).to_numpy()\n\ndwns_test = dwns_test.drop(columns=[\n    'client_id',\n    'target_1',\n    'target_2',\n    'target_3',\n    'target_4'\n]).to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nmodels = [LGBMClassifier(\n    n_estimators=500,\n    boosting_type='gbdt',\n    subsample=0.5,\n    subsample_freq=1,\n    learning_rate=0.02,\n    feature_fraction=0.75,\n    max_depth=6,\n    lambda_l1=1,\n    lambda_l2=1,\n    min_data_in_leaf=50,\n    random_state=42,\n    n_jobs=8,\n    verbose=-1\n) for _ in range(4)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for target_id in range(4):\n    models[target_id].fit(dwns_train, targets_train[:, target_id])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n\nfor i in range(len(models)):\n    preds = models[i].predict_proba(dwns_test)\n    print(f\"ROC-AUC target_{i} = {roc_auc_score(targets_test[:, i], preds[:, 1])}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cross-Attention","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass SplitToPatches(IterableProcessingDataset):\n    \"\"\"\n    Create small and large patches for NN with cross-attention\n    \"\"\"\n    def __init__(\n        self,\n        small_patches_size=3,\n        large_patches_size=12,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self.small_patches_size = small_patches_size\n        self.large_patches_size = large_patches_size\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n\n            patched_features = {}\n    \n            for key, tensor in features.items():\n                if key.startswith('target'):\n                    patched_features[key] = features[key]\n                elif key != self._col_id:\n                    small_patches = list(torch.split(features[key], self.small_patches_size))\n                    if small_patches[-1].size() != self.small_patches_size:\n                        small_patches[-1] = F.pad(small_patches[-1], (0, self.small_patches_size - len(small_patches[-1])), \"constant\", small_patches[-1][-1])\n                    small_patches = torch.stack(small_patches)\n                    \n                    large_patches = list(torch.split(features[key], self.large_patches_size))\n                    if large_patches[-1].size() != self.large_patches_size:\n                        large_patches[-1] = F.pad(large_patches[-1], (0, self.large_patches_size - len(large_patches[-1])), \"constant\", large_patches[-1][-1])\n                    large_patches = torch.stack(large_patches)\n\n                    patched_features[key] = features[key]\n                    patched_features['small_' + key] = small_patches\n                    patched_features['large_' + key] = large_patches\n                    # del features[key]\n    \n            yield patched_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=0'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=1'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=2'),\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch(),\n        # SplitToPatches()\n    ],\n    shuffle_files=True\n)\n\nvalid = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_DATA_PATH, 'fold=3')\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch(),\n        # SplitToPatches()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_module = ptls.frames.PtlsDataModule(\n    train_data=ptls.frames.coles.ColesIterableDataset(\n        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n            split_count=3,\n            cnt_min=16,\n            cnt_max=180\n        ),\n        data=train\n    ),\n    valid_data=ptls.frames.coles.ColesIterableDataset(\n        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n            split_count=3,\n            cnt_min=16,\n            cnt_max=180\n        ),\n        data=valid\n    ),\n    train_batch_size=64,\n    train_num_workers=0,\n    valid_batch_size=32,\n    valid_num_workers=0\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# next(iter(train))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = torch.tensor([[1, 2], [1, 3]])\na = F.pad(a, (0, 1), 'replicate')\na","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nfrom ptls.data_load import PaddedBatch\nfrom ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\nfrom ptls.nn.seq_encoder.transformer_encoder import TransformerEncoder\nfrom ptls.nn.seq_encoder.longformer_encoder import LongformerEncoder\nfrom ptls.nn.seq_encoder.custom_encoder import Encoder\nfrom ptls.nn.trx_encoder import TrxEncoder\nfrom ptls.nn.seq_encoder.containers import SeqEncoderContainer\nimport torch.nn.functional as F\nfrom ptls.nn.seq_encoder.custom_encoder import MLP\n\nclass RnnSeqEncoderCrossAttn(SeqEncoderContainer):\n    def __init__(self,\n                 trx_encoder=None,\n                 input_size=None,\n                 small_patches_size=3,\n                 large_patches_size=12,\n                 is_reduce_sequence=True,\n                 **seq_encoder_params,\n                 ):\n        super().__init__(\n            trx_encoder=trx_encoder,\n            seq_encoder_cls=RnnEncoder,\n            input_size=input_size,\n            seq_encoder_params=seq_encoder_params,\n            is_reduce_sequence=is_reduce_sequence,\n        )\n        self.small_patches_size = small_patches_size\n        self.large_patches_size = large_patches_size\n        self.emb_dim = 128\n        self.large_attn = nn.MultiheadAttention(\n            embed_dim=self.emb_dim,\n            num_heads=8,\n            dropout=0.3,\n            batch_first=True\n        )\n\n        # self.small_attn = nn.MultiheadAttention(\n        #     embed_dim=self.emb_dim,\n        #     num_heads=8,\n        #     dropout=0.3,\n        #     batch_first=True\n        # )\n\n        self.small_seq_encoder = RnnEncoder(\n            input_size=input_size if input_size is not None else trx_encoder.output_size,\n            is_reduce_sequence=is_reduce_sequence,\n            type='gru',\n            hidden_size=256\n        )\n\n        # MLP variation\n        self.head_small = MLP(\n                n_in=256,\n                n_hidden=256,\n                n_out=128\n            )\n        self.head_large = MLP(\n                n_in=256,\n                n_hidden=256,\n                n_out=128\n            ) \n\n    def forward(self, x, names=None, seq_len=None, h_0=None):\n        \"\"\"\n        Возможно стоит использовать разные енкодеры для маленьких и для больших патчей\n        \"\"\"\n        # for key, value in x.payload.items():\n        #     small_x[key] = list(torch.split(value, self.small_patches_size, dim=1))\n        #     if small_x[key][-1].size()[-1] != self.small_patches_size:\n        #         pad_size = self.small_patches_size - small_x[key][-1].size()[-1]\n        #         small_x[key][-1] = F.pad(small_x[key][-1], (0, pad_size), \"replicate\")\n        #     small_x[key] = torch.stack(small_x[key])\n\n        #     large_x[key] = list(torch.split(value, self.large_patches_size, dim=1))\n        #     if large_x[key][-1].size()[-1] != self.large_patches_size:\n        #         pad_size = self.large_patches_size - large_x[key][-1].size()[-1]\n        #         large_x[key][-1] = F.pad(large_x[key][-1], (0, pad_size), \"replicate\")\n        #     large_x[key] = torch.stack(large_x[key])\n        x = self.trx_encoder(x)\n        x_new = x.payload\n        # print(f\"{x_new.size()=}\")\n        # x_embs = self.seq_encoder(x)\n        # print(f\"{x_embs.size()=}\")\n\n        real_size = x_new.size()[1]\n        small_patches = list(torch.split(x_new, self.small_patches_size, dim=1))\n        large_patches = list(torch.split(x_new, self.large_patches_size, dim=1))\n\n        if small_patches[-1].size()[1] != self.large_patches_size:\n            pad_size = self.small_patches_size - small_patches[-1].size()[1]\n            # print(pad_size)\n            # print(small_patches[-1].size())\n            small_patches[-1] = F.pad(small_patches[-1], (0, 0, pad_size, 0), \"replicate\")\n\n        if large_patches[-1].size()[1] != self.large_patches_size:\n            pad_size = self.large_patches_size - large_patches[-1].size()[1]\n            large_patches[-1] = F.pad(large_patches[-1], (0, 0, pad_size, 0), \"replicate\")\n\n        small_patches = torch.stack(small_patches)\n        large_patches = torch.stack(large_patches)\n        \n        \n\n        large_comp_embed = torch.zeros(x_new.size()[0], 128).to(x.device)\n        for large_patch in large_patches:\n            large_patch = PaddedBatch(large_patch, [large_patch.size()[1]] * large_patch.size()[0])\n            large_emb = self.seq_encoder(large_patch)\n            large_emb = self.head_large(large_emb)\n            large_comp_embed = (large_comp_embed + large_emb) / 2\n\n        small_comp_embed = torch.zeros(x_new.size()[0], 128).to(x.device)\n        for small_patch in small_patches:\n            small_patch = PaddedBatch(small_patch, [small_patch.size()[1]] * small_patch.size()[0])\n            small_emb = self.small_seq_encoder(small_patch)\n            small_emb = self.head_small(small_emb)\n            small_comp_embed = (small_comp_embed + small_emb) / 2\n\n        # small_attn_emb, _ = self.small_attn(small_comp_embed, large_comp_embed, large_comp_embed)\n        large_attn_emb, _ = self.large_attn(large_comp_embed, small_comp_embed, small_comp_embed)\n\n        out = torch.cat((small_comp_embed, large_attn_emb), dim=1)\n\n        return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=2,\n    gamma=0.9025\n)\n\nseq_encoder = RnnSeqEncoderCrossAttn(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            },\n            numeric_values={\n                'amount': 'log'\n            }\n        ),\n        small_patches_size=3,\n        large_patches_size=12,\n        type='gru',\n        hidden_size=256\n    )\n\npl_module = ptls.frames.coles.CoLESModule(\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n        K=10,\n        metric='cosine'\n    ),\n    seq_encoder=seq_encoder,\n    optimizer_partial=optimizer_partial,\n    lr_scheduler_partial=lr_scheduler_partial\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"MBD_My_Code\", log_model=\"all\", name='mbd_uni_crossattn')\n\ntrainer = pl.Trainer(\n    logger=wandb_logger,\n    max_epochs=15,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Aggregate over time","metadata":{}},{"cell_type":"code","source":"from datetime import timedelta\n\nimport torch.nn.functional as F\n\nclass AggregateOverTime(IterableProcessingDataset):\n    \"\"\"\n    Create small and large patches for NN with cross-attention\n    \"\"\"\n    def __init__(\n        self,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n\n            start_date = datetime.fromtimestamp(features[self._col_time][0])\n            start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)\n            \n            end_date = datetime.fromtimestamp(features[self._col_time][-1])\n            end_date = end_date.replace(hour=0, minute=0, second=0, microsecond=0)\n\n            num_days = (end_date - start_date).days + 2\n\n            # print(start_date.timestamp())\n            \n            days_list = [(start_date + timedelta(days=i)).timestamp() for i in range(num_days)]\n            # print(f\"{features['event_time']=}\")\n\n            masks = {\n                days_list[i]: ((features['event_time'] < days_list[i + 1]) & (features['event_time'] > days_list[i])) for i in range(len(days_list) - 1)\n            }\n\n            truth_masks = {}\n\n            for key, value in masks.items():\n                if value.sum() > 0:\n                    truth_masks[key] = value\n\n            masks = truth_masks\n            del truth_masks\n\n            # print(f\"{masks=}\")\n\n            new_features = {}\n            for feat_key, feat_tensor in features.items():\n                new_features[feat_key] = []\n                for mask_key, mask_value in masks.items():\n                    if feat_key.startswith('target'):\n                        new_features[feat_key] = features[feat_key]\n                    elif feat_key == self._col_time:\n                        new_features[feat_key].append(int(mask_key))\n                    elif feat_key != self._col_id:\n                        if len(features[feat_key][mask_value]) > 1:\n                            if features[feat_key][mask_value].dtype == torch.float32:\n                                new_features[feat_key].append(features[feat_key][mask_value].mean().item())\n                            else:\n                                values, counts = torch.unique(features[feat_key][mask_value], return_counts=True)\n                                most_common_value = values[torch.argmax(counts)]\n                                new_features[feat_key].append(most_common_value.item())\n                        else:\n                            new_features[feat_key].append(features[feat_key][mask_value])\n\n            for key, tensor in features.items():\n                if key.startswith('target'):\n                    new_features[key] = new_features[key]\n                elif key == self._col_time:\n                    new_features[key] = torch.Tensor(new_features[key]).int()\n                elif key != self._col_id:\n                    new_features[key] = torch.tensor([t for t in new_features[key]])\n            \n            yield new_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=0'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=1'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=2'),\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        AggregateOverTime(),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch()\n    ],\n    shuffle_files=True\n)\n\nvalid = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_DATA_PATH, 'fold=3')\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        AggregateOverTime(),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"next(iter(train))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_module = ptls.frames.PtlsDataModule(\n    train_data=ptls.frames.coles.ColesIterableDataset(\n        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n            split_count=3,\n            cnt_min=16,\n            cnt_max=180\n        ),\n        data=train\n    ),\n    valid_data=ptls.frames.coles.ColesIterableDataset(\n        splitter=ptls.frames.coles.split_strategy.SampleSlices(\n            split_count=3,\n            cnt_min=16,\n            cnt_max=180\n        ),\n        data=valid\n    ),\n    train_batch_size=64,\n    train_num_workers=0,\n    valid_batch_size=32,\n    valid_num_workers=0\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=2,\n    gamma=0.9025\n)\n\nseq_encoder = ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            },\n            numeric_values={\n                'amount': 'log'\n            }\n        ),\n        type='gru',\n        hidden_size=256\n    )\n\npl_module = ptls.frames.coles.CoLESModule(\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n        K=4,\n        metric='cosine'\n    ),\n    seq_encoder=seq_encoder,\n    optimizer_partial=optimizer_partial,\n    lr_scheduler_partial=lr_scheduler_partial\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"MBD_My_Code\", log_model=\"all\", name='mbd_agg_overtime')\n\ntrainer = pl.Trainer(\n    logger=wandb_logger,\n    max_epochs=20,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Custom transformer block","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass SplitToPatches(IterableProcessingDataset):\n    \"\"\"\n    Create small and large patches for NN with cross-attention\n    \"\"\"\n    def __init__(\n        self,\n        small_patches_size=3,\n        large_patches_size=12,\n        col_id='client_id',\n        col_time='event_time'\n    ):\n        super().__init__()\n        self.small_patches_size = small_patches_size\n        self.large_patches_size = large_patches_size\n        self._col_id = col_id\n        self._col_time = col_time\n        \n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            features = features.copy()\n\n            patched_features = {}\n            small_patch = {}\n            large_patch = {}\n    \n            for key, tensor in features.items():\n                if key.startswith('target'):\n                    patched_features[key] = features[key]\n                elif key != self._col_id:\n                    small_patches = list(torch.split(features[key], self.small_patches_size))\n                    if small_patches[-1].size() != self.small_patches_size:\n                        small_patches[-1] = F.pad(small_patches[-1], (0, self.small_patches_size - len(small_patches[-1])), \"constant\", small_patches[-1][-1])\n                    small_patches = torch.stack(small_patches)\n                    \n                    large_patches = list(torch.split(features[key], self.large_patches_size))\n                    if large_patches[-1].size() != self.large_patches_size:\n                        large_patches[-1] = F.pad(large_patches[-1], (0, self.large_patches_size - len(large_patches[-1])), \"constant\", large_patches[-1][-1])\n                    large_patches = torch.stack(large_patches)\n\n                    # patched_features[key] = features[key]\n                    small_patch[key] = small_patches\n                    large_patch[key] = large_patches\n                    # del features[key]\n    \n            yield features, small_patch, large_patch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=0'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=1'),\n            os.path.join(TRX_SUPERVISED_PATH, 'fold=2'),\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch(),\n        # SplitToPatches()\n    ],\n    shuffle_files=True\n)\n\nvalid = ptls.data_load.datasets.ParquetDataset(\n        data_files=[\n            os.path.join(TRX_DATA_PATH, 'fold=3')\n        ],\n    i_filters=[\n        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=16),\n        ptls.data_load.iterable_processing.SeqLenFilter(max_seq_len=2048),\n        ptls.data_load.iterable_processing.feature_filter.FeatureFilter(\n            drop_feature_names=[\n                'client_id',\n                'target_1',\n                'target_2',\n                'target_3',\n                'target_4'\n            ]\n        ),\n        ptls.data_load.iterable_processing.to_torch_tensor.ToTorch(),\n        # SplitToPatches()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"next(iter(train))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Tabformer**","metadata":{}},{"cell_type":"code","source":"from ptls.frames.tabformer import TabformerIterableDataset\n\ndata_module = ptls.frames.PtlsDataModule(\n    train_data=TabformerIterableDataset(\n        data=train,\n        max_len=300,\n        min_len=80\n    ),\n    valid_data=TabformerIterableDataset(\n        data=valid,\n        max_len=300,\n        min_len=80\n    ),\n    train_batch_size=64,\n    train_num_workers=0,\n    valid_batch_size=32,\n    valid_num_workers=0,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=2,\n    gamma=0.9025\n)\n\ntrx_encoder = ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'event_type': {\"in\": 59, \"out\": 24},\n                'event_subtype': {\"in\": 60, \"out\": 24},\n                'src_type11': {\"in\": 86, \"out\": 24},\n                'src_type12': {\"in\": 350, \"out\": 24},\n                'dst_type11': {\"in\": 85, \"out\": 24},\n                'dst_type12': {\"in\": 418, \"out\": 24},\n                'src_type22': {\"in\": 91, \"out\": 24},\n                'src_type32': {\"in\": 92, \"out\": 24},\n                'amount': {\"in\": 11, \"out\": 24}\n            },\n        )\n\nseq_encoder = ptls.nn.seq_encoder.CustomSeqEncoder(\n    n_heads=2,\n    n_layers=8,\n    input_size=216,\n    use_positional_encoding=True\n)\n\nfeature_encoder = ptls.nn.TabFormerFeatureEncoder(\n    n_cols=9,\n    emb_dim=24\n)\n\npl_module = TabformerPretrainModule(\n    total_steps=20000,\n    mask_prob=0.2,\n    feature_encoder=feature_encoder,\n    seq_encoder=seq_encoder,\n    trx_encoder=trx_encoder\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"MBD_My_Code\", log_model=\"all\")\n\ntrainer = pl.Trainer(\n    logger=wandb_logger,\n    max_epochs=15,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=32\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(pl_module, data_module)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**----------------------------------------------------------------**","metadata":{}},{"cell_type":"code","source":"from ptls.nn.seq_encoder.abs_seq_encoder import AbsSeqEncoder\n\nclass CrossEncoder(AbsSeqEncoder):\n    \"\"\"\n    Custom transformer encoder with cross-attention mechanism\n    \"\"\"\n    def __init__(\n         self,\n         input_size: int,\n         intermediate_size: int = 2048,\n         num_hidden_layers: int = 8,\n         num_attention_heads: int = 8,\n         attn_block_mode: str = 'rezero',\n         self_attn_mode: str = 'quadratic',\n         aggregation_mode: str = 'mean',\n         layer_norm=None,\n         is_reduce_sequence=True\n        ):\n        super().__init__(is_reduce_sequence=is_reduce_sequence)\n\n        self.transformer = torch.nn.Sequential(\n            AttentionBlock(\n                input_size, intermediate_size, attn_block_mode, self_attn_mode, layer_norm, num_attention_heads\n            ) for _ in range(num_hidder_layer)\n        )\n        self.aggregation = Aggregation(reduction=aggregation_mode)\n        self.is_reduce_sequence = is_reduce_sequence\n\n    def forward(self, xs: PaddedBatch, xl: PaddedBatch):\n        out = self.transformer(x.payload)\n        out = self.aggregation(out)\n        if self.is_reduce_sequence:\n            return out\n        return PaddedBatch(out, x.seq_lens)\n\nclass MLP(torch.nn.Module):\n\n    def __init__(self, n_in, n_hidden, n_out, depth=2):\n        super().__init__()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(n_in, n_hidden),\n            torch.nn.GELU(),\n            *[torch.nn.Sequential(\n                torch.nn.Linear(n_hidden, n_hidden),\n                torch.nn.GELU(),\n            ) for _ in range(depth - 1)],\n            torch.nn.Linear(n_hidden, n_out)\n        )\n\n    def forward(self, X):\n        return self.mlp(X)\n\n\nclass Attention(torch.nn.Module):\n\n    def __init__(self, embed_dim, num_heads, self_attn):\n        super().__init__()\n\n        self.self_attn = self_attn\n        if self_attn == \"quadratic\":\n            self.attn = MultiheadAttention(embed_dim, num_heads, batch_first=True)\n        elif self_attn == \"linear-flow\":\n            self.attn = FlowAttention(embed_dim, num_heads)\n        elif self_attn == \"linear-cross\":\n            pass  # TODO\n\n    def forward(self, X):\n\n        if self.self_attn == \"quadratic\":\n            X, _ = self.attn(X, X, X)\n        elif self.self_attn == \"linear-flow\":\n            X = self.attn(X)\n        elif self.self_attn == \"linear-cross\":\n            pass\n\n        return X\n\n\nclass AttentionBlock(torch.nn.Module):\n\n    def __init__(self, embed_dim, mlp_hidden_dim, attn_block, self_attn, layer_norm, num_heads=4):\n        super().__init__()\n\n        self.attn_block = attn_block\n        self.layer_norm = layer_norm\n\n        if self.attn_block == \"rezero\":\n            self.alpha_attn = torch.nn.Parameter(torch.normal(torch.tensor(0.), torch.tensor(1e-6)))\n            self.alpha_mlp = torch.nn.Parameter(torch.normal(torch.tensor(0.), torch.tensor(1e-6)))\n\n        self.attn = Attention(embed_dim, num_heads, self_attn)\n        self.linear1 = torch.nn.Linear(embed_dim, mlp_hidden_dim)\n        self.linear2 = torch.nn.Linear(mlp_hidden_dim, embed_dim)\n\n    def forward(self, X):\n\n        if self.attn_block == \"rezero\":\n            if self.layer_norm == 'pre':\n                X = X / (X.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n            Z = X + self.alpha_attn * self.attn(X)\n            if self.layer_norm:\n                Z = Z / (Z.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n            Z = Z + self.alpha_mlp * self.linear2(gelu(self.linear1(Z)))\n            if self.layer_norm == 'post':\n                Z = Z / (Z.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n            X = X + Z  # double residual\n\n        else:  # no-ln\n            if self.layer_norm == 'pre':\n                X = X / (X.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n            Z = X + self.attn(X)\n            if self.layer_norm:\n                Z = Z / (Z.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n            Z = Z + self.linear2(gelu(self.linear1(Z)))\n            if self.layer_norm == 'post':\n                Z = Z / (Z.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n            X = X + Z  # double residual\n\n        return X\n\n\nclass Aggregation(torch.nn.Module):\n\n    def __init__(self, reduction=\"mean\"):\n        super().__init__()\n        self.reduction = reduction\n\n    def forward(self, X):\n\n        if self.reduction == \"mean\":\n            x = X.mean(dim=1)\n        elif self.reduction == \"sum\":\n            x = X.sum(dim=1)\n        elif self.reduction == \"max\":\n            x, _ = torch.max(X, dim=1)\n        else:\n            x = X[:, 0]\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_partial = partial(\n    torch.optim.AdamW,\n    lr=0.001,\n    weight_decay=1e-4\n)\n\nlr_scheduler_partial = partial(\n    torch.optim.lr_scheduler.StepLR,\n    step_size=2,\n    gamma=0.9025\n)\n\nseq_encoder = ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'event_type': {\"in\": 58, \"out\": 24},\n                'event_subtype': {\"in\": 59, \"out\": 24},\n                'src_type11': {\"in\": 85, \"out\": 24},\n                'src_type12': {\"in\": 349, \"out\": 24},\n                'dst_type11': {\"in\": 84, \"out\": 24},\n                'dst_type12': {\"in\": 417, \"out\": 24},\n                'src_type22': {\"in\": 90, \"out\": 24},\n                'src_type32': {\"in\": 91, \"out\": 24}\n            },\n            numeric_values={\n                'amount': 'log'\n            }\n        ),\n        type='gru',\n        hidden_size=256\n    )\n\npl_module = ptls.frames.coles.CoLESModule(\n    validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n        K=4,\n        metric='cosine'\n    ),\n    seq_encoder=seq_encoder,\n    optimizer_partial=optimizer_partial,\n    lr_scheduler_partial=lr_scheduler_partial\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"markdown","source":"**Baseline**\n\nROC-AUC target_0 = 0.6902993098249428\n\nROC-AUC target_1 = 0.8683783800091109\n\nROC-AUC target_2 = 0.7172133992848904\n\nROC-AUC target_3 = 0.7379677788955408\n\n**CoLES with RegionalAttention (region=5)**\n\nROC-AUC target_0 = 0.6511195928124079\n\nROC-AUC target_1 = 0.6579967058724159\n\nROC-AUC target_2 = 0.6670043759461615\n\nROC-AUC target_3 = 0.7515082250999511\n\n**CoLES with RegionalAttention (region=10)**\n\nROC-AUC target_0 = 0.6739120412871101\n\nROC-AUC target_1 = 0.706606596806981\n\nROC-AUC target_2 = 0.6463595608203014\n\nROC-AUC target_3 = 0.7783177461331754\n\n**Cross-Attention with RnnEncoders**\n\nsm = 4\n\nbig = 15 \n\nROC-AUC target_0 = 0.5912\n\nROC-AUC target_1 = 0.6111\n\nROC-AUC target_2 = 0.6073\n\nROC-AUC target_3 = 0.7231\n\n**Cross-Attention with RnnEncoders**\n\nsm = 5\n\nbig = 16 \n\nROC-AUC target_0 = 0.6163\n\nROC-AUC target_1 = 0.6415\n\nROC-AUC target_2 = 0.5926\n\nROC-AUC target_3 = 0.7196\n\n**Cross-Attention with RnnEncoders**\n\nsm = 3\n\nbig = 12 \n\nROC-AUC target_0 = 0.6200493519809905\n\nROC-AUC target_1 = 0.6213451372905097\n\nROC-AUC target_2 = 0.6341383714174937\n\nROC-AUC target_3 = 0.7323125712491827\n\n**CustomEncoder baseline**\n\nROC-AUC target_0 = 0.6500493519809905\n\nROC-AUC target_1 = 0.6913451372905097\n\nROC-AUC target_2 = 0.6135956082030145\n\nROC-AUC target_3 = 0.7123157124918271\n\n**GPT baseline**\n\nROC-AUC target_0 = 0.6700140091239141\n\nROC-AUC target_1 = 0.7719453941204589\n\nROC-AUC target_2 = 0.7441383714174937\n\nROC-AUC target_3 = 0.7423125712491827\n\n**Cross-Attention with CustomEncoder (Надо еще потюнить параметры)**\n\nROC-AUC target_0 = 0.7000493519809905\n\nROC-AUC target_1 = 0.6513451372905097\n\nROC-AUC target_2 = 0.6941383714174937\n\nROC-AUC target_3 = 0.7723125712491827\n\n**Перенести на datafusion, сделать transformer блоки с cross/reg - attention**","metadata":{}},{"cell_type":"markdown","source":"**Проверить влияние диалогов на каждый из таргетов**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}