{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install pytorch-lifestream","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:01:37.113568Z","iopub.execute_input":"2025-02-28T07:01:37.113856Z","iopub.status.idle":"2025-02-28T07:01:51.401698Z","shell.execute_reply.started":"2025-02-28T07:01:37.113835Z","shell.execute_reply":"2025-02-28T07:01:51.400672Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\nRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\nCollecting pytorch-lifestream\n  Downloading pytorch-lifestream-0.6.0.tar.gz (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.1.3)\nCollecting hydra-core>=1.1.2 (from pytorch-lifestream)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.26.4)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.3.0)\nRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.2.3)\nRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (19.0.1)\nRequirement already satisfied: pytorch-lightning>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.5.0.post0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.2.2)\nRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.5.1+cu121)\nRequirement already satisfied: torchmetrics>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.6.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (4.47.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2.4.1)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->pytorch-lifestream) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2025.1)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.67.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2024.12.0)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (0.12.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.12.0->pytorch-lifestream) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.29.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.4.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (3.11.12)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (75.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-lifestream) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lifestream) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.5->pytorch-lifestream) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.5->pytorch-lifestream) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2025.1.31)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.18.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pytorch-lifestream\n  Building wheel for pytorch-lifestream (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pytorch-lifestream: filename=pytorch_lifestream-0.6.0-py3-none-any.whl size=274639 sha256=b1b388f9531cb2195da8ca4272039753a1b3079361354a960c06e17d41ebc0a8\n  Stored in directory: /root/.cache/pip/wheels/90/76/b4/0a944bc7c5a69201e4d757cc54886971117a2a581740e7f11d\nSuccessfully built pytorch-lifestream\nInstalling collected packages: hydra-core, pytorch-lifestream\nSuccessfully installed hydra-core-1.3.2 pytorch-lifestream-0.6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"new_config = \"\"\"#!/usr/bin/env bash\n\nmkdir -p data\ncd data/\nmkdir -p raw_data\ncd raw_data/\n\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/0433a4ca/transactions.zip\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/0554f0cf/clickstream.zip\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/acfacf11/train_matching.csv\n\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/b949c04c/mcc_codes.csv\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/705abbab/click_categories.csv\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/e33f2201/currency_rk.csv\n\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/a3643657/sample_submission.zip\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/24687252/baseline_catboost.zip\n\ncurl -OL https://storage.yandexcloud.net/datasouls-ods/materials/b99fed70/puzzle.csv\n\ncd ../../\n\"\"\"\n\nwith open('/kaggle/working/get_data.sh', mode='w') as file:\n    file.write(new_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:01:51.403039Z","iopub.execute_input":"2025-02-28T07:01:51.403345Z","iopub.status.idle":"2025-02-28T07:01:51.408332Z","shell.execute_reply.started":"2025-02-28T07:01:51.403311Z","shell.execute_reply":"2025-02-28T07:01:51.407589Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!source /kaggle/working/get_data.sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:01:51.409465Z","iopub.execute_input":"2025-02-28T07:01:51.409688Z","iopub.status.idle":"2025-02-28T07:02:52.019482Z","shell.execute_reply.started":"2025-02-28T07:01:51.409661Z","shell.execute_reply":"2025-02-28T07:02:52.018646Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  250M  100  250M    0     0  15.5M      0  0:00:16  0:00:15  0:00:01 17.8M0  15.7M      0  0:00:15  0:00:15 --:--:-- 17.9M\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  469M  100  469M    0     0  12.7M      0  0:00:36  0:00:36 --:--:-- 13.8M\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1045k  100 1045k    0     0   604k      0  0:00:01  0:00:01 --:--:--  604k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  195k  100  195k    0     0   156k      0  0:00:01  0:00:01 --:--:--  156k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 13035  100 13035    0     0  19956      0 --:--:-- --:--:-- --:--:-- 19931\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    38  100    38    0     0     57      0 --:--:-- --:--:-- --:--:--    57\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  1390  100  1390    0     0   2163      0 --:--:-- --:--:-- --:--:--  2165\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  192k  100  192k    0     0   162k      0  0:00:01  0:00:01 --:--:--  162k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  319k  100  319k    0     0   235k      0  0:00:01  0:00:01 --:--:--  235k\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Prepare Data","metadata":{}},{"cell_type":"code","source":"!mkdir data/train_matching_folds\n!mkdir data/transactions_folds\n!mkdir data/clickstream_folds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:50:46.570817Z","iopub.execute_input":"2025-02-28T04:50:46.571117Z","iopub.status.idle":"2025-02-28T04:50:46.912786Z","shell.execute_reply.started":"2025-02-28T04:50:46.571095Z","shell.execute_reply":"2025-02-28T04:50:46.911684Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Get data splits","metadata":{}},{"cell_type":"code","source":"import logging\n\nimport numpy as np\nimport pandas as pd\nfrom zipfile import ZipFile\n\nfrom sklearn.model_selection import StratifiedKFold\n\nN_SPLITS = 6\nCNT_BIN_COUNT = 4\nSHUFFLE_RANDOM_STATE = 42\n\nlogger = logging.getLogger(__name__)\n\n\ndef get_split_data():\n    print('Data loading...')\n    df_train_matching = pd.read_csv('data/raw_data/train_matching.csv')\n\n    with ZipFile('data/raw_data/transactions.zip') as z:\n        df_transactions = pd.read_csv(z.open('transactions.csv'))\n    with ZipFile('data/raw_data/clickstream.zip') as z:\n        df_clickstream = pd.read_csv(z.open('clickstream.csv'))\n\n    print(f'Loaded {len(df_train_matching)} pairs, '\n                f'{len(df_transactions)} transactions, {len(df_clickstream)} clicks')\n\n    vc = df_transactions['user_id'].value_counts()\n    s_trx_cnt_bins = pd.cut(\n        vc,\n        vc.quantile(np.linspace(0, 1, CNT_BIN_COUNT + 1)),\n        labels=np.arange(CNT_BIN_COUNT),\n    ).fillna(0).astype(str).rename('trx_cnt_bins')\n    vc = df_clickstream['user_id'].value_counts()\n    s_click_cnt_bins = pd.cut(\n        vc,\n        vc.quantile(np.linspace(0, 1, CNT_BIN_COUNT + 1)),\n        labels=np.arange(CNT_BIN_COUNT),\n    ).fillna(0).astype(str).rename('click_cnt_bins')\n    print(f'Prepared {CNT_BIN_COUNT} bins for trx and clicks')\n\n    df_train_matching = pd.merge(df_train_matching, s_trx_cnt_bins, left_on='bank', right_index=True, how='left')\n    df_train_matching = pd.merge(df_train_matching, s_click_cnt_bins, left_on='rtk', right_index=True, how='left')\n    df_train_matching['trx_cnt_bins'] = df_train_matching['trx_cnt_bins'].fillna(str(CNT_BIN_COUNT))\n    df_train_matching['click_cnt_bins'] = df_train_matching['click_cnt_bins'].fillna(str(CNT_BIN_COUNT))\n    df_train_matching['cnt_bins'] = df_train_matching['trx_cnt_bins'] + df_train_matching['click_cnt_bins']\n    df_train_matching = df_train_matching[['bank', 'rtk', 'cnt_bins']]\n\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SHUFFLE_RANDOM_STATE)\n    for fold_id, (_, ix_folds) in enumerate(skf.split(df_train_matching, df_train_matching['cnt_bins'])):\n        df_match = df_train_matching[['bank', 'rtk']].iloc[ix_folds]\n        df_match.to_csv(f'data/train_matching_folds/train_matching_{fold_id}.csv', index=False)\n\n        df_trx = df_transactions[lambda x: x['user_id'].isin(df_match['bank'].values)]\n        df_trx.to_csv(f'data/transactions_folds/transactions_{fold_id}.csv', index=False)\n\n        df_click = df_clickstream[lambda x: x['user_id'].isin(df_match['rtk'].values)]\n        df_click.to_csv(f'data/clickstream_folds/clickstream_{fold_id}.csv', index=False)\n\n        print(f'Saved data for fold {fold_id}: {len(df_match)} pairs, '\n                    f'{len(df_trx)} transactions ({len(df_trx[\"user_id\"].unique())} unique users), '\n                    f'{len(df_click)} clicks ({len(df_click[\"user_id\"].unique())} unique users)')\n\n    df_trx = df_transactions[lambda x: ~x['user_id'].isin(df_train_matching['bank'].values)]\n    df_trx.to_csv(f'data/transactions_unmatched.csv', index=False)\n\n    df_click = df_clickstream[lambda x: ~x['user_id'].isin(df_train_matching['rtk'].values)]\n    df_click.to_csv(f'data/clickstream_unmatched.csv', index=False)\n    print(f'Saved unmatched data: '\n                f'{len(df_trx)} transactions ({len(df_trx[\"user_id\"].unique())} unique users), '\n                f'{len(df_click)} clicks ({len(df_click[\"user_id\"].unique())} unique users)')\n\n    print(f'All splits saved')\n\nget_split_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:50:46.913771Z","iopub.execute_input":"2025-02-28T04:50:46.914058Z","iopub.status.idle":"2025-02-28T04:59:12.014937Z","shell.execute_reply.started":"2025-02-28T04:50:46.914036Z","shell.execute_reply":"2025-02-28T04:59:12.014105Z"}},"outputs":[{"name":"stdout","text":"Data loading...\nLoaded 17581 pairs, 19821910 transactions, 126752515 clicks\nPrepared 4 bins for trx and clicks\nSaved data for fold 0: 2931 pairs, 2572365 transactions (2931 unique users), 15124893 clicks (2446 unique users)\nSaved data for fold 1: 2930 pairs, 2583449 transactions (2930 unique users), 16898083 clicks (2445 unique users)\nSaved data for fold 2: 2930 pairs, 2579526 transactions (2930 unique users), 16838662 clicks (2445 unique users)\nSaved data for fold 3: 2930 pairs, 2568464 transactions (2930 unique users), 15739400 clicks (2445 unique users)\nSaved data for fold 4: 2930 pairs, 2576772 transactions (2930 unique users), 15029891 clicks (2445 unique users)\nSaved data for fold 5: 2930 pairs, 2559992 transactions (2930 unique users), 15165618 clicks (2445 unique users)\nSaved unmatched data: 4381342 transactions (4952 unique users), 31955968 clicks (4952 unique users)\nAll splits saved\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from glob import glob\ndata_path = \"data/train_matching_folds/train_matching_*.csv\"\n\nvalid_fold_id = 4\nfolds_count = len(glob(f'{data_path}'))\ntrain_folds = [i for i in range(folds_count) if valid_fold_id is not None and i != valid_fold_id]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:12.015894Z","iopub.execute_input":"2025-02-28T04:59:12.016223Z","iopub.status.idle":"2025-02-28T04:59:12.020967Z","shell.execute_reply.started":"2025-02-28T04:59:12.016188Z","shell.execute_reply":"2025-02-28T04:59:12.020121Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_folds = [0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:12.021918Z","iopub.execute_input":"2025-02-28T04:59:12.022127Z","iopub.status.idle":"2025-02-28T04:59:12.034227Z","shell.execute_reply.started":"2025-02-28T04:59:12.022109Z","shell.execute_reply":"2025-02-28T04:59:12.033604Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport torch\n\n\ndef trx_types(df):\n    df['mcc_code'] = df['mcc_code'].astype(str)\n    df['currency_rk'] = df['currency_rk'].astype(str)\n    df['event_time'] = pd.to_datetime(df['transaction_dttm']).astype(int) / 1e9\n    return df[['user_id', 'event_time', 'mcc_code', 'currency_rk', 'transaction_amt']]\n\n\ndef click_types(df):\n    df['event_time'] = pd.to_datetime(df['timestamp']).astype(int) / 1e9\n    df = pd.merge(df, pd.read_csv('./data/raw_data/click_categories.csv'), on='cat_id')\n    df['cat_id'] = df['cat_id'].astype(str)\n    return df[['user_id', 'event_time', 'cat_id', 'level_0', 'level_1', 'level_2', 'new_uid']]\n\n\ndef trx_to_torch(seq):\n    for x in seq:\n        yield x['user_id'], {\n            'event_time': x['event_time'],\n            'mcc_code': x['mcc_code'],\n            'currency_rk': x['currency_rk'],\n            'transaction_amt': x['transaction_amt'],\n        }\n\n\ndef click_to_torch(seq):\n    for x in seq:\n        yield x['user_id'], {\n            'event_time': torch.from_numpy(x['event_time']).float(),\n            'cat_id': torch.from_numpy(x['cat_id']).int(),\n            'level_0': torch.from_numpy(x['level_0']).int(),\n            'level_1': torch.from_numpy(x['level_1']).int(),\n            'level_2': torch.from_numpy(x['level_2']).int(),\n            'new_uid': torch.from_numpy(x['new_uid']).int(),\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:12.036353Z","iopub.execute_input":"2025-02-28T04:59:12.036567Z","iopub.status.idle":"2025-02-28T04:59:15.101393Z","shell.execute_reply.started":"2025-02-28T04:59:12.036549Z","shell.execute_reply":"2025-02-28T04:59:15.100509Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = \"./data/\"\ndf_matching_train = pd.concat([pd.read_csv(f'{data_path}/train_matching_folds/train_matching_{i}.csv') for i in train_folds])\ndf_trx_train = pd.concat([trx_types(pd.read_csv(f'{data_path}/transactions_folds/transactions_{i}.csv')) for i in train_folds])\ndf_click_train = pd.concat([click_types(pd.read_csv(f'{data_path}/clickstream_folds/clickstream_{i}.csv')) for i in train_folds])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:15.102920Z","iopub.execute_input":"2025-02-28T04:59:15.103287Z","iopub.status.idle":"2025-02-28T04:59:43.937801Z","shell.execute_reply.started":"2025-02-28T04:59:15.103265Z","shell.execute_reply":"2025-02-28T04:59:43.936855Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_click_train['user_id'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:43.938739Z","iopub.execute_input":"2025-02-28T04:59:43.939093Z","iopub.status.idle":"2025-02-28T04:59:44.888537Z","shell.execute_reply.started":"2025-02-28T04:59:43.939059Z","shell.execute_reply":"2025-02-28T04:59:44.887711Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array(['0016b2dad12c450b8308e5c3ec2548fe',\n       '001cad12665b4483b54b314346a44c69',\n       '003c5614416a4c81ab4ee74b72035842', ...,\n       'ff8f13a5976147d9b9cf640daa36417a',\n       'ffc5887cddb44824bb1e9cb2c59de4e0',\n       'ffd1cfa7a0e64b848d439f9040b37f92'], dtype=object)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from ptls.preprocessing.pandas_preprocessor import PandasDataPreprocessor\n\npreprocessor_trx = PandasDataPreprocessor(\n    col_id='user_id',\n    col_event_time='event_time',\n    event_time_transformation='none',\n    cols_category=[\"mcc_code\", \"currency_rk\"],\n    cols_identity=[],\n)\npreprocessor_click = PandasDataPreprocessor(\n    col_id='user_id',\n    col_event_time='event_time',\n    event_time_transformation='none',\n    cols_category=['cat_id', 'level_0', 'level_1', 'level_2'],\n    cols_identity=['new_uid'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:44.889385Z","iopub.execute_input":"2025-02-28T04:59:44.889702Z","iopub.status.idle":"2025-02-28T04:59:45.160445Z","shell.execute_reply.started":"2025-02-28T04:59:44.889670Z","shell.execute_reply":"2025-02-28T04:59:45.159785Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\n\ndef trx_to_torch(seq):\n    for x in seq:\n        yield x['user_id'], {\n            'event_time': x['event_time'],\n            'mcc_code': x['mcc_code'],\n            'currency_rk': x['currency_rk'],\n            'transaction_amt': x['transaction_amt'],\n        }\n\n\ndef click_to_torch(seq):\n    for x in seq:\n        yield x['user_id'], {\n            'event_time': x['event_time'],\n            'cat_id': x['cat_id'],\n            'level_0': x['level_0'],\n            'level_1': x['level_1'],\n            'level_2': x['level_2'],\n            'new_uid': x['new_uid'],\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:45.161207Z","iopub.execute_input":"2025-02-28T04:59:45.161489Z","iopub.status.idle":"2025-02-28T04:59:45.166273Z","shell.execute_reply.started":"2025-02-28T04:59:45.161460Z","shell.execute_reply":"2025-02-28T04:59:45.165630Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"features_trx_train = dict(trx_to_torch(preprocessor_trx.fit_transform(df_trx_train)))\nfeatures_click_train = dict(click_to_torch(preprocessor_click.fit_transform(df_click_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:59:45.167194Z","iopub.execute_input":"2025-02-28T04:59:45.167460Z","iopub.status.idle":"2025-02-28T05:00:24.701042Z","shell.execute_reply.started":"2025-02-28T04:59:45.167427Z","shell.execute_reply":"2025-02-28T05:00:24.700347Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import gc\n\ndel df_trx_train\ndel df_click_train\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:24.701811Z","iopub.execute_input":"2025-02-28T05:00:24.702039Z","iopub.status.idle":"2025-02-28T05:00:25.281790Z","shell.execute_reply.started":"2025-02-28T05:00:24.702020Z","shell.execute_reply":"2025-02-28T05:00:25.281093Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import warnings\nfrom enum import Enum\nimport torch\n\n\nfrom ptls.data_load.padded_batch import PaddedBatch\nfrom ptls.nn.trx_encoder.batch_norm import RBatchNorm, RBatchNormWithLens\nfrom ptls.nn.trx_encoder.noisy_embedding import NoisyEmbedding\nfrom ptls.nn.trx_encoder.trx_encoder_base import TrxEncoderBase\n\nclass TorchDataTypeConstant(Enum):\n    TORCH_FLOAT16 = torch.float16\n    TORCH_BFLOAT16 = torch.bfloat16\n    TORCH_FLOAT32 = torch.float32\n    TORCH_FLOAT64 = torch.float64\n    TORCH_INT8 = torch.int8\n    TORCH_INT16 = torch.int16\n    TORCH_INT32 = torch.int32\n    TORCH_INT64 = torch.int64\n    TORCH_BOOL = torch.bool\nTORCH_FLOAT32 = TorchDataTypeConstant.TORCH_FLOAT32.value\nTORCH_EMB_DTYPE = TORCH_FLOAT32\n\nclass TrxEncoder(TrxEncoderBase):\n    \"\"\"Network layer which makes representation for single transactions\n\n     Input is `PaddedBatch` with ptls-format dictionary, with feature arrays of shape (B, T)\n     Output is `PaddedBatch` with transaction embeddings of shape (B, T, H)\n     where:\n        B - batch size, sequence count in batch\n        T - sequence length\n        H - hidden size, representation dimension\n\n    `ptls.nn.trx_encoder.noisy_embedding.NoisyEmbedding` implementation are used for categorical features.\n\n    Parameters\n        embeddings:\n            dict with categorical feature names.\n            Values must be like this `{'in': dictionary_size, 'out': embedding_size}`\n            These features will be encoded with lookup embedding table of shape (dictionary_size, embedding_size)\n            Values can be a `torch.nn.Embedding` implementation\n        numeric_values:\n            dict with numerical feature names.\n            Values must be a string with scaler_name.\n            Possible values are: 'identity', 'sigmoid', 'log', 'year'.\n            These features will be scaled with selected scaler.\n            Values can be `ptls.nn.trx_encoder.scalers.BaseScaler` implementatoin\n\n            One field can have many scalers. In this case key become alias and col name should be in scaler.\n            Check `TrxEncoderBase.numeric_values` for more details\n\n        embeddings_noise (float):\n            Noise level for embedding. `0` meens without noise\n        emb_dropout (float):\n            Probability of an element of embedding to be zeroed\n        spatial_dropout (bool):\n            Whether to dropout full dimension of embedding in the whole sequence\n\n        use_batch_norm:\n            True - All numerical values will be normalized after scaling\n            False - No normalizing for numerical values\n        use_batch_norm_with_lens:\n            True - Respect seq_lens during batch_norm. Padding zeroes will be ignored\n            False - Batch norm ower all time axis. Padding zeroes will included.\n\n        orthogonal_init:\n            if True then `torch.nn.init.orthogonal` applied\n        linear_projection_size:\n            Linear layer at the end will be added for non-zero value\n\n        out_of_index:\n            How to process a categorical indexes which are greater than dictionary size.\n            'clip' - values will be collapsed to maximum index. This works well for frequency encoded categories.\n                We join infrequent categories to one.\n            'assert' - raise an error of invalid index appear.\n\n        norm_embeddings: keep default value for this parameter\n        clip_replace_value: Not useed. keep default value for this parameter\n        positions: Not used. Keep default value for this parameter\n\n    Examples:\n        >>> B, T = 5, 20\n        >>> trx_encoder = TrxEncoder(\n        >>>     embeddings={'mcc_code': {'in': 100, 'out': 5}},\n        >>>     numeric_values={'amount': 'log'},\n        >>> )\n        >>> x = PaddedBatch(\n        >>>     payload={\n        >>>         'mcc_code': torch.randint(0, 99, (B, T)),\n        >>>         'amount': torch.randn(B, T),\n        >>>     },\n        >>>     length=torch.randint(10, 20, (B,)),\n        >>> )\n        >>> z = trx_encoder(x)\n        >>> assert z.payload.shape == (5, 20, 6)  # B, T, H\n    \"\"\"\n    def __init__(self,\n                 embeddings=None,\n                 numeric_values=None,\n                 custom_embeddings=None,\n                 embeddings_noise: float = 0,\n                 norm_embeddings=None,\n                 use_batch_norm=False,\n                 use_batch_norm_with_lens=False,\n                 clip_replace_value=None,\n                 positions=None,\n                 emb_dropout=0,\n                 spatial_dropout=False,\n                 orthogonal_init=False,\n                 linear_projection_size=0,\n                 out_of_index: str = 'clip',\n                 ):\n        if clip_replace_value is not None:\n            warnings.warn('`clip_replace_value` attribute is deprecated. Always \"clip to max\" used. '\n                          'Use `out_of_index=\"assert\"` to avoid categorical values clip', DeprecationWarning)\n\n        if positions is not None:\n            warnings.warn('`positions` is deprecated. positions is not used', UserWarning)\n\n        if embeddings is None:\n            embeddings = {}\n        if custom_embeddings is None:\n            custom_embeddings = {}\n\n        noisy_embeddings = {}\n        for emb_name, emb_props in embeddings.items():\n            if emb_props.get('disabled', False):\n                continue\n            if emb_props['in'] == 0 or emb_props['out'] == 0:\n                continue\n            noisy_embeddings[emb_name] = NoisyEmbedding(\n                num_embeddings=emb_props['in'],\n                embedding_dim=emb_props['out'],\n                padding_idx=0,\n                max_norm=1 if norm_embeddings else None,\n                noise_scale=embeddings_noise,\n                dropout=emb_dropout,\n                spatial_dropout=spatial_dropout,\n            )\n\n        super().__init__(\n            embeddings=noisy_embeddings,\n            numeric_values=numeric_values,\n            custom_embeddings=custom_embeddings,\n            out_of_index=out_of_index,\n        )\n\n        custom_embedding_size = self.custom_embedding_size\n        if use_batch_norm and custom_embedding_size > 0:\n            # :TODO: Should we use Batch norm with not-numerical custom embeddings?\n            if use_batch_norm_with_lens:\n                self.custom_embedding_batch_norm = RBatchNormWithLens(custom_embedding_size)\n            else:\n                self.custom_embedding_batch_norm = RBatchNorm(custom_embedding_size)\n        else:\n            self.custom_embedding_batch_norm = None\n\n        if linear_projection_size > 0:\n            self.linear_projection_head = torch.nn.Linear(super().output_size, linear_projection_size)\n        else:\n            self.linear_projection_head = None\n\n        if orthogonal_init:\n            for n, p in self.named_parameters():\n                if n.startswith('embeddings.') and n.endswith('.weight'):\n                    torch.nn.init.orthogonal_(p.data[1:])\n                if n == 'linear_projection_head.weight':\n                    torch.nn.init.orthogonal_(p.data)\n\n    def forward(self, x: PaddedBatch, names=None, seq_len=None):\n        if isinstance(x, PaddedBatch) is False:\n            pre_x = dict()\n            for i, field_name in enumerate(names):\n                pre_x[field_name] = x[i]\n            x = PaddedBatch(pre_x, seq_len)\n\n        processed_embeddings = [self.get_category_embeddings(x, field_name)\n                                for field_name in self.embeddings.keys()]\n        processed_custom_embeddings = [self.get_custom_embeddings(x, field_name)\n                                       for field_name in self.custom_embeddings.keys()]\n        if len(processed_custom_embeddings):\n            processed_custom_embeddings = torch.cat(processed_custom_embeddings, dim=2)\n            if self.custom_embedding_batch_norm is not None:\n                processed_custom_embeddings = PaddedBatch(processed_custom_embeddings, x.seq_lens)\n                processed_custom_embeddings = self.custom_embedding_batch_norm(processed_custom_embeddings)\n                processed_custom_embeddings = processed_custom_embeddings.payload\n            processed_embeddings.append(processed_custom_embeddings)\n\n        out = torch.cat(processed_embeddings, dim=2)\n        out = out.type(TORCH_EMB_DTYPE)\n        out = self.linear_projection_head(out) if self.linear_projection_head is not None else out\n        return PaddedBatch(out, x.seq_lens)\n\n    @property\n    def output_size(self):\n        \"\"\"Returns hidden size of output representation\n        \"\"\"\n        if self.linear_projection_head is not None:\n            return self.linear_projection_head.out_features\n        return super().output_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:25.282661Z","iopub.execute_input":"2025-02-28T05:00:25.282935Z","iopub.status.idle":"2025-02-28T05:00:40.537322Z","shell.execute_reply.started":"2025-02-28T05:00:25.282907Z","shell.execute_reply":"2025-02-28T05:00:40.536634Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"def add_nulls(df_dict):\n    new_df_dict = {}\n    for user_id, user_dict in df_dict.items():\n        filled_event_time = []\n        prev_time = -1\n        max_date = 1720828799\n        event_time_int = user_dict['event_time'].int()\n        for time in event_time_int:\n            if time / 86400 > prev_time / 86400 + 1:\n                # Если между предыдущим временем и текущим есть пропуск, заполняем пропуски\n                for t in range(prev_time + 1, time):\n                    filled_event_time.append(t)\n            filled_event_time.append(time)\n            prev_time = time\n        for time in range(event_time_int[-1], max_date):\n            filled_event_time.append(time)\n            \n        # Преобразуем в тензор\n        filled_event_time = torch.tensor(filled_event_time)\n\n        # Обработка остальных признаков\n        filled_features = {key: [] for key in user_dict.keys()}\n\n        event_time_index = 0  # Индекс для event_time\n\n        # Пробегаем по всем значениям в filled_event_time\n        for i in range(len(filled_event_time)):\n            # Если текущий момент времени совпадает с событием в исходном event_time\n            if event_time_index < len(event_time_int) and filled_event_time[i] == event_time_int[event_time_index]:\n                # Для каждого признака сохраняем значение, если оно есть в event_time\n                for key in user_dict.keys():\n                    filled_features[key].append(user_dict[key][event_time_index])\n                event_time_index += 1\n            else:\n                # Если нет события, заполняем значением из dict_sizes для каждого признака\n                for key in user_dict.keys():\n                    filled_features[key].append(user_dict[key])\n\n        # Преобразуем все заполненные признаки в тензоры\n        filled_feature_tensors = {key: torch.tensor(filled_features[key]) for key in filled_features}\n        filled_feature_tensors['event_time'] = filled_event_time\n        new_df_dict[user_id] = filled_feature_tensors\n    return new_df_dict\n    \nfeatures_trx_train = add_nulls(features_trx_train)\nfeatures_click_train = add_nulls(features_click_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**При использовании add_nulls mrr~0.025 на одной модели. на ансамбле из 3-х моделей ~0.074. На 2-х фолдах**","metadata":{}},{"cell_type":"markdown","source":"# MLM TRX Module","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pytorch_lightning as pl\nimport torch\nfrom ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\nfrom ptls.nn.seq_encoder.utils import LastStepEncoder\n# from ptls.nn.trx_encoder import TrxEncoder\nfrom ptls.data_load.padded_batch import PaddedBatch\nimport torchmetrics\nfrom torchmetrics import Metric\n\nclass MeanLoss(torchmetrics.Metric):\n    def __init__(self, **params):\n        super().__init__(**params)\n\n        self.add_state('_sum', torch.tensor([0.0]))\n        self.add_state('_cnt', torch.tensor([0]))\n\n    def update(self, x):\n        self._sum += x.sum()\n        self._cnt += x.numel()\n\n    def compute(self):\n        return self._sum / self._cnt.float()\n\nclass MLMPretrainModule(pl.LightningModule):\n    def __init__(self, data_type, params,\n                 lr, weight_decay,\n                 max_lr, pct_start, total_steps,\n                 ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        common_trx_size = params.common_trx_size\n        self.seq_encoder = None\n\n        self.token_mask = torch.nn.Parameter(torch.randn(1, 1, common_trx_size), requires_grad=True)\n        self.transf = torch.nn.TransformerEncoder(\n            encoder_layer=torch.nn.TransformerEncoderLayer(\n                d_model=common_trx_size,\n                nhead=params.transf.nhead,\n                dim_feedforward=params.transf.dim_feedforward,\n                dropout=params.transf.dropout,\n                batch_first=True,\n            ),\n            num_layers=params.transf.num_layers,\n            norm=torch.nn.LayerNorm(common_trx_size) if params.transf.norm else None,\n        )\n\n        if params.transf.use_pe:\n            self.pe = torch.nn.Parameter(self.get_pe(), requires_grad=False)\n        else:\n            self.pe = None\n        self.padding_mask = torch.nn.Parameter(torch.tensor([True, False]).bool(), requires_grad=False)\n\n        self.train_mlm_loss_all = MeanLoss()\n        self.valid_mlm_loss_all = MeanLoss()\n        self.train_mlm_loss_self = MeanLoss()\n        self.valid_mlm_loss_self = MeanLoss()\n\n    def get_pe(self):\n        max_len = self.hparams.params.transf.max_len\n        H = self.hparams.params.common_trx_size\n        f = 2 * np.pi * torch.arange(max_len).view(1, -1, 1) / \\\n            torch.exp(torch.linspace(*np.log([4, max_len]), H // 2)).view(1, 1, -1)\n        return torch.cat([torch.sin(f), torch.cos(f)], dim=2)\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer=optim,\n            max_lr=self.hparams.max_lr,\n            total_steps=self.hparams.total_steps,\n            pct_start=self.hparams.pct_start,\n            anneal_strategy='cos',\n            cycle_momentum=False,\n            div_factor=25.0,\n            final_div_factor=10000.0,\n            three_phase=True,\n        )\n        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n        return [optim], [scheduler]\n\n    def get_mask(self, x: PaddedBatch):\n        return torch.bernoulli(x.seq_len_mask.float() * self.hparams.params.mlm.replace_proba).bool()\n\n    def mask_x(self, x: PaddedBatch, mask):\n        return torch.where(mask.unsqueeze(2).expand_as(x.payload),\n                           self.token_mask.expand_as(x.payload), x.payload)\n\n    def get_neg_ix(self, mask, neg_type):\n        \"\"\"Sample from predicts, where `mask == True`, without self element.\n        For `neg_type='all'` - sample from predicted tokens from batch\n        For `neg_type='self'` - sample from predicted tokens from row\n        \"\"\"\n        if neg_type == 'all':\n            mn = mask.float().view(1, -1) - \\\n                 torch.eye(mask.numel(), device=mask.device)[mask.flatten()]\n            neg_ix = torch.multinomial(mn, self.hparams.params.mlm.neg_count_all)\n            b_ix = neg_ix.div(mask.size(1), rounding_mode='trunc')\n            neg_ix = neg_ix % mask.size(1)\n            return b_ix, neg_ix\n        if neg_type == 'self':\n            mask_ix = mask.nonzero(as_tuple=False)\n            one_pos = torch.eye(mask.size(1), device=mask.device)[mask_ix[:, 1]]\n            mn = mask[mask_ix[:, 0]].float() - one_pos\n            mn = mn + 1e-9 * (1 - one_pos)\n            neg_ix = torch.multinomial(mn, self.hparams.params.mlm.neg_count_self, replacement=True)\n            b_ix = mask_ix[:, 0].view(-1, 1).expand_as(neg_ix)\n            return b_ix, neg_ix\n        raise AttributeError(f'Unknown neg_type: {neg_type}')\n\n    def sentence_encoding(self, x: PaddedBatch):\n        return None\n\n    def mlm_loss(self, x: PaddedBatch, neg_type, x_orig: PaddedBatch):\n        mask = self.get_mask(x)\n        masked_x = self.mask_x(x, mask)\n        B, T, H = masked_x.size()\n\n        if self.pe is not None:\n            if self.training:\n                start_pos = np.random.randint(0, self.hparams.params.transf.max_len - T, 1)[0]\n            else:\n                start_pos = 0\n            pe = self.pe[:, start_pos:start_pos + T]\n            masked_x = masked_x + pe\n\n        se = self.sentence_encoding(x_orig)\n        if se is not None:\n            masked_x = masked_x + se\n\n        out = self.transf(masked_x, src_key_padding_mask=self.padding_mask[x.seq_len_mask])\n\n        if self.pe is not None:\n            out = out - pe\n        if se is not None:\n            out = out - se\n\n        target = x.payload[mask].unsqueeze(1)  # N, 1, H\n        predict = out[mask].unsqueeze(1)  # N, 1, H\n        neg_ix = self.get_neg_ix(mask, neg_type)\n        negative = out[neg_ix[0], neg_ix[1]]  # N, nneg, H\n        out_samples = torch.cat([predict, negative], dim=1)\n        probas = torch.softmax((target * out_samples).sum(dim=2), dim=1)\n        loss = -torch.log(probas[:, 0])\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        (x_trx, _), = batch\n\n        z_trx = self.seq_encoder(x_trx)  # PB: B, T, H\n\n        loss_mlm = self.mlm_loss(z_trx, neg_type='all', x_orig=x_trx)\n        self.train_mlm_loss_all(loss_mlm)\n        loss_mlm_all = loss_mlm.mean()\n        self.log(f'loss/mlm_{self.hparams.data_type}', loss_mlm_all)\n\n        loss_mlm = self.mlm_loss(z_trx, neg_type='self', x_orig=x_trx)\n        self.train_mlm_loss_self(loss_mlm)\n        loss_mlm_self = loss_mlm.mean()\n        self.log(f'loss/mlm_{self.hparams.data_type}_self', loss_mlm_self)\n\n        return loss_mlm_all + loss_mlm_self\n\n    def validation_step(self, batch, batch_idx):\n        (x_trx, _), = batch\n        z_trx = self.seq_encoder(x_trx)  # PB: B, T, H\n\n        loss_mlm = self.mlm_loss(z_trx, neg_type='all', x_orig=x_trx)\n        self.valid_mlm_loss_all(loss_mlm)\n\n        loss_mlm = self.mlm_loss(z_trx, neg_type='self', x_orig=x_trx)\n        self.valid_mlm_loss_self(loss_mlm)\n\n    def on_training_epoch_end(self, _):\n        self.log(f'metrics/train_{self.hparams.data_type}_mlm', self.train_mlm_loss_all, prog_bar=True)\n        self.log(f'metrics/train_{self.hparams.data_type}_mlm_self', self.train_mlm_loss_self, prog_bar=True)\n\n    def on_validation_epoch_end(self, _):\n        self.log(f'metrics/valid_{self.hparams.data_type}_mlm', self.valid_mlm_loss_all, prog_bar=True)\n\nclass CustomTrxTransform(torch.nn.Module):\n    def __init__(self, trx_amnt_quantiles):\n        super().__init__()\n        self.trx_amnt_quantiles = torch.nn.Parameter(trx_amnt_quantiles, requires_grad=False)\n\n    def forward(self, x):\n        x.payload['transaction_amt_q'] = torch.bucketize(x.payload['transaction_amt'], self.trx_amnt_quantiles) + 1\n        return x\n\nclass DateFeaturesTransform(torch.nn.Module):\n    def forward(self, x):\n        et = x.payload['event_time'].int()\n        et_day = et.div(24 * 60 * 60, rounding_mode='floor').int()\n        x.payload['hour'] = et.div(60 * 60, rounding_mode='floor') % 24 + 1\n        x.payload['weekday'] = et.div(60 * 60 * 24, rounding_mode='floor') % 7 + 1\n        x.payload['day_diff'] = torch.clamp(torch.diff(et_day, prepend=et_day[:, :1], dim=1), 0, 14)\n        return x\n\nclass PBLinear(torch.nn.Linear):\n    def forward(self, x: PaddedBatch):\n        return PaddedBatch(super().forward(x.payload), x.seq_lens)\n\nclass PBL2Norm(torch.nn.Module):\n    def __init__(self, beta):\n        super().__init__()\n        self.beta = beta\n\n    def forward(self, x):\n        return PaddedBatch(self.beta * x.payload / (x.payload.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5),\n                           x.seq_lens)\n\nclass TransactionEncoder(torch.nn.Module):\n    def __init__(self, params, trx_amnt_quantiles):\n        super().__init__()\n\n        self.trx_amnt_quantiles = trx_amnt_quantiles\n        print(params.trx_seq.trx_encoder)\n        t = TrxEncoder(\n            norm_embeddings=params.trx_seq.trx_encoder.norm_embeddings,\n            embeddings_noise=params.trx_seq.trx_encoder.embeddings_noise,\n            embeddings=params.trx_seq.trx_encoder.embeddings\n        )\n        self.seq_encoder = torch.nn.Sequential(\n            CustomTrxTransform(trx_amnt_quantiles=trx_amnt_quantiles),\n            DateFeaturesTransform(),\n            t, PBLinear(t.output_size, params.common_trx_size),\n            PBL2Norm(params.mlm.beta),\n        )\n\n    def forward(self, x):\n        return self.seq_encoder(x)\n\nclass MLMPretrainModuleTrx(MLMPretrainModule):\n    def __init__(self,\n                 trx_amnt_quantiles,\n                 params,\n                 lr, weight_decay,\n                 max_lr, pct_start, total_steps,\n                 ):\n        super().__init__(data_type='trx',\n                         params=params,\n                         lr=lr, weight_decay=weight_decay,\n                         max_lr=max_lr, pct_start=pct_start, total_steps=total_steps,\n                         )\n        self.save_hyperparameters()\n        self.seq_encoder = TransactionEncoder(params, trx_amnt_quantiles)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:40.538298Z","iopub.execute_input":"2025-02-28T05:00:40.538963Z","iopub.status.idle":"2025-02-28T05:00:42.207614Z","shell.execute_reply.started":"2025-02-28T05:00:40.538929Z","shell.execute_reply":"2025-02-28T05:00:42.206925Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nfrom ptls.data_load import augmentation_chain\nfrom ptls.data_load.augmentations.random_slice import RandomSlice\nfrom ptls.preprocessing.pandas_preprocessor import PandasDataPreprocessor\nimport random\nfrom ptls.data_load.data_module.coles_data_module import coles_collate_fn\n\n\nclass PairedDataset(torch.utils.data.Dataset):\n    def __init__(self, pairs, data, augmentations, n_sample):\n        super().__init__()\n\n        self.pairs = pairs\n        self.data = data\n        self.augmentations = augmentations\n        self.n_sample = n_sample\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, item):\n        ids = self.pairs[item]\n        return tuple([[a(d[i]) for _ in range(self.n_sample)]\n                      for i, d, a in zip(ids, self.data, self.augmentations)])\n\n    @staticmethod\n    def collate_fn(batch):\n        return [coles_collate_fn(c) for c in zip(*batch)]\n\nclass DropDuplicate:\n    def __init__(self, col_check, col_new_cnt=None, keep='first'):\n        super().__init__()\n\n        self.col_check = col_check\n        self.col_new_cnt = col_new_cnt\n        if keep != 'first':\n            raise NotImplementedError()\n\n    def __call__(self, x):\n        idx, new_cnt = self.get_idx(x[self.col_check])\n        new_x = {k: v[idx] for k, v in x.items()}\n        if self.col_new_cnt is not None:\n            new_x[self.col_new_cnt] = torch.from_numpy(new_cnt)\n        return new_x\n\n    def get_idx(self, x):\n        diff = np.diff(x, prepend=x[0] - 1)\n        new_ix = np.where(diff != 0)[0]\n        new_cnt = np.diff(new_ix, append=len(x))\n        return new_ix, new_cnt\n\ndef pretrain_mlm_trx(features_trx_train, cfg):\n    train_dl_mlm_trx = torch.utils.data.DataLoader(\n        PairedDataset(\n            np.sort(np.array(list(features_trx_train.keys()))).reshape(-1, 1),\n            data=[features_trx_train],\n            augmentations=[augmentation_chain(\n                DropDuplicate('mcc_code', col_new_cnt='c_cnt'),\n                RandomSlice(32, 128)\n            )],\n            n_sample=1,\n        ),\n        collate_fn=PairedDataset.collate_fn,\n        shuffle=True,\n        num_workers=12,\n        batch_size=128,\n        persistent_workers=True,\n    )\n\n    # calculate trx_amnt_quantiles\n    v = []\n    for batch in train_dl_mlm_trx:\n        v.append(batch[0][0].payload['transaction_amt'][batch[0][0].seq_len_mask.bool()])\n    v = torch.cat(v)\n    trx_amnt_quantiles = torch.quantile(torch.unique(v), torch.linspace(0, 1, 100, dtype=v.dtype))\n\n    mlm_model_trx = MLMPretrainModuleTrx(\n        params=cfg.model_config,\n        lr=0.001, weight_decay=0,\n        max_lr=0.001, pct_start=9000 / 2 / 10000, total_steps=10000,\n        trx_amnt_quantiles=trx_amnt_quantiles,\n    )\n\n    trainer = pl.Trainer(\n        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        max_steps=4000,\n        enable_progress_bar=True,\n        callbacks=[\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelCheckpoint(\n                every_n_train_steps=50, save_top_k=-1,\n            ),\n        ]\n    )\n    model_version_trx = trainer.logger.version\n    print('Trx pretrain start')\n    print('baseline loss all + self:  {:.3f} + {:.3f}'.format(\n        np.log(mlm_model_trx.hparams.params.mlm.neg_count_all + 1),\n        np.log(mlm_model_trx.hparams.params.mlm.neg_count_self + 1)\n    ))\n    print(f'version = {model_version_trx}')\n    trainer.fit(mlm_model_trx, train_dl_mlm_trx)\n    trainer.save_checkpoint(f'{cfg.objects_path}/pretrain_trx.cpt', weights_only=True)\n    print('Trx pretrain done')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:42.208397Z","iopub.execute_input":"2025-02-28T05:00:42.208891Z","iopub.status.idle":"2025-02-28T05:00:42.910414Z","shell.execute_reply.started":"2025-02-28T05:00:42.208867Z","shell.execute_reply":"2025-02-28T05:00:42.909589Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!mkdir conf\n!mkdir objects","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:42.911252Z","iopub.execute_input":"2025-02-28T05:00:42.911455Z","iopub.status.idle":"2025-02-28T05:00:43.232931Z","shell.execute_reply.started":"2025-02-28T05:00:42.911437Z","shell.execute_reply":"2025-02-28T05:00:43.231854Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# %load /kaggle/working/MBD/scenario_mbd/conf/trx_coles.yaml\nnew_config = \"\"\"defaults:\n  - override hydra/job_logging: disabled\n\nvalid_fold_id: 4\n\nensemble_size: 5\ndata_path: ./data\nobjects_path: \"./objects_${valid_fold_id}\"\n\nmodel_config:\n    common_trx_size: 256\n    transf:\n        nhead: 4\n        dim_feedforward: 1024\n        dropout: 0.1\n        num_layers: 3\n        norm: false\n        max_len: 6000\n        use_pe: true\n    mlm:\n        replace_proba: 0.1\n        neg_count_all: 64\n        neg_count_self: 8\n        beta: 10\n\n    trx_seq:\n        trx_encoder:\n          norm_embeddings: false\n          embeddings_noise: 0.003\n          embeddings:\n            mcc_code:\n              in: 350\n              out: 64\n            currency_rk:\n              in: 10\n              out: 4\n            transaction_amt_q:\n              in: 110\n              out: 8\n            hour:\n              in: 30\n              out: 16\n            weekday:\n              in: 10\n              out: 4\n            day_diff:\n              in: 15\n              out: 8\n          numeric_values:\n            transaction_amt: identity\n            c_cnt: log\n\n    click_seq:\n        trx_encoder:\n          use_batch_norm_with_lens: false\n          norm_embeddings: false\n          embeddings_noise: 0.003\n          embeddings:\n            cat_id:\n              in: 400\n              out: 64\n            level_0:\n              in: 400\n              out: 16\n            level_1:\n              in: 400\n              out: 8\n            level_2:\n              in: 400\n              out: 4\n            hour:\n              in: 30\n              out: 16\n            weekday:\n              in: 10\n              out: 4\n            day_diff:\n              in: 15\n              out: 8\n          numeric_values:\n            c_cnt: log\n\n    rnn:\n      type: gru\n      hidden_size: 256\n      bidir: false\n      trainable_starter: static\n\n\"\"\"\n\nwith open('/kaggle/working/conf/config.yaml', mode='w') as file:\n    file.write(new_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.234179Z","iopub.execute_input":"2025-02-28T05:00:43.234491Z","iopub.status.idle":"2025-02-28T05:00:43.239579Z","shell.execute_reply.started":"2025-02-28T05:00:43.234453Z","shell.execute_reply":"2025-02-28T05:00:43.238877Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from hydra import initialize, compose\n\ninitialize(version_base=None, config_path=\"conf\")\ncfg = compose(config_name=\"config.yaml\", return_hydra_config=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.240526Z","iopub.execute_input":"2025-02-28T05:00:43.240845Z","iopub.status.idle":"2025-02-28T05:00:43.717694Z","shell.execute_reply.started":"2025-02-28T05:00:43.240776Z","shell.execute_reply":"2025-02-28T05:00:43.716692Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# pretrain_mlm_trx(features_trx_train, cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.718868Z","iopub.execute_input":"2025-02-28T05:00:43.719223Z","iopub.status.idle":"2025-02-28T05:00:43.723265Z","shell.execute_reply.started":"2025-02-28T05:00:43.719189Z","shell.execute_reply":"2025-02-28T05:00:43.722492Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Click encoder","metadata":{}},{"cell_type":"code","source":"class CustomClickTransform(torch.nn.Module):\n    def forward(self, x):\n        #         x.payload['cat_id'] = torch.clamp(x.payload['cat_id'], 0, 300)\n        #         x.payload['level_0'] = torch.clamp(x.payload['level_0'], 0, 200)\n        #         x.payload['level_1'] = torch.clamp(x.payload['level_1'], 0, 200)\n        #         x.payload['level_2'] = torch.clamp(x.payload['level_2'], 0, 200)\n        #         x.payload['c_cnt_clamp'] = torch.clamp(x.payload['c_cnt'], 0, 20).int()\n        return x\n\nclass ClickEncoder(torch.nn.Module):\n    def __init__(self, params):\n        super().__init__()\n\n        t = TrxEncoder(\n            use_batch_norm_with_lens=params.click_seq.trx_encoder.use_batch_norm_with_lens,\n            norm_embeddings=params.click_seq.trx_encoder.norm_embeddings,\n            embeddings_noise=params.click_seq.trx_encoder.embeddings_noise,\n            embeddings=params.click_seq.trx_encoder.embeddings\n        )\n        self.seq_encoder = torch.nn.Sequential(\n            CustomClickTransform(),\n            DateFeaturesTransform(),\n            t, PBLinear(t.output_size, params.common_trx_size),\n            PBL2Norm(params.mlm.beta),\n        )\n\n    def forward(self, x):\n        return self.seq_encoder(x)\n\nclass MLMPretrainModuleClick(MLMPretrainModule):\n    def __init__(self, params,\n                 lr, weight_decay,\n                 max_lr, pct_start, total_steps,\n                 ):\n        super().__init__(data_type='click',\n                         params=params,\n                         lr=lr, weight_decay=weight_decay,\n                         max_lr=max_lr, pct_start=pct_start, total_steps=total_steps,\n                         )\n        self.save_hyperparameters()\n        self.seq_encoder = ClickEncoder(params)\n\ndef pretrain_mlm_click(features_click_train, cfg):\n    train_dl_mlm_click = torch.utils.data.DataLoader(\n        PairedDataset(\n            np.sort(np.array(list(features_click_train.keys()))).reshape(-1, 1),\n            data=[features_click_train],\n            augmentations=[augmentation_chain(\n                DropDuplicate('cat_id', col_new_cnt='c_cnt'),\n                RandomSlice(32, 128)\n            )],\n            n_sample=1,\n        ),\n        collate_fn=PairedDataset.collate_fn,\n        shuffle=True,\n        num_workers=12,\n        batch_size=64,\n        persistent_workers=True,\n    )\n\n    mlm_model_click = MLMPretrainModuleClick(\n        params=cfg.model_config,\n        lr=0.001, weight_decay=0,\n        max_lr=0.001, pct_start=9000 / 2 / 10000, total_steps=10000,\n    )\n\n    trainer = pl.Trainer(\n        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        max_steps=3000,\n        enable_progress_bar=True,\n        callbacks=[\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelCheckpoint(\n                every_n_train_steps=2000, save_top_k=-1,\n            ),\n        ]\n    )\n    model_version_click = trainer.logger.version\n    print('Click pretrain start')\n    print('baseline loss all + self:  {:.3f} + {:.3f}'.format(\n        np.log(mlm_model_click.hparams.params.mlm.neg_count_all + 1),\n        np.log(mlm_model_click.hparams.params.mlm.neg_count_self + 1)\n    ))\n    trainer.fit(mlm_model_click, train_dl_mlm_click)\n    trainer.save_checkpoint(f'{cfg.objects_path}/pretrain_click.cpt', weights_only=True)\n    print('Click pretrain done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.724094Z","iopub.execute_input":"2025-02-28T05:00:43.724367Z","iopub.status.idle":"2025-02-28T05:00:43.740184Z","shell.execute_reply.started":"2025-02-28T05:00:43.724339Z","shell.execute_reply":"2025-02-28T05:00:43.739410Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# pretrain_mlm_click(features_click_train, cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.745403Z","iopub.execute_input":"2025-02-28T05:00:43.745721Z","iopub.status.idle":"2025-02-28T05:00:43.761849Z","shell.execute_reply.started":"2025-02-28T05:00:43.745691Z","shell.execute_reply":"2025-02-28T05:00:43.760961Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class PairedFullDataset(torch.utils.data.Dataset):\n    def __init__(self, pairs, data, augmentations, n_sample):\n        super().__init__()\n\n        self.pairs = pairs\n        self.data = data\n        self.augmentations = augmentations\n        self.n_sample = n_sample\n        self.full_pairs = self.get_full_pairs()\n\n    @staticmethod\n    def collate_fn(batch):\n        \"\"\"\n        In:\n        [1, 2 ,3], [4, 5]\n        [6, 7], [None, None]\n        [None, None], [8, 9]\n\n        Out:\n        x, labels, out_of_match\n\n        PaddedBatch([1, 2, 3, 6, 7]), [0, 0, 0, 1, 1], [0, 0, 0, 1, 1]\n        PaddedBatch([4, 5, 8, 9]), [0, 0, 2, 2], [0, 0, 1, 1]\n        \"\"\"\n        data_1 = [t for p, _ in batch for t in p if t is not None]\n        data_2 = [t for _, p in batch for t in p if t is not None]\n\n        labels = torch.arange(len(batch), dtype=torch.int32)\n        labels_1 = torch.repeat_interleave(labels,\n                                           torch.tensor([len([t for t in p if t is not None]) for p, _ in batch]))\n        labels_2 = torch.repeat_interleave(labels,\n                                           torch.tensor([len([t for t in p if t is not None]) for _, p in batch]))\n        out_of_match_1 = torch.tensor([1 if p2[0] is None else 0 for p1, p2 in batch for t in p1 if t is not None])\n        out_of_match_2 = torch.tensor([1 if p1[0] is None else 0 for p1, p2 in batch for t in p2 if t is not None])\n        return (\n            padded_collate_wo_target(data_1), labels_1, out_of_match_1.int(),\n            padded_collate_wo_target(data_2), labels_2, out_of_match_2.int(),\n        )\n\n    @staticmethod\n    def not_in(v, items_to_exclude):\n        a = np.sort(items_to_exclude)\n        return v[np.pad(a, pad_width=(0, 1), constant_values='')[np.searchsorted(a, v)] != v]\n\n    def get_full_pairs(self):\n        free_trx = self.not_in(np.array(list(self.data[0].keys())), self.pairs[:, 0]).reshape(-1, 1)\n        free_clicks = self.not_in(np.array(list(self.data[1].keys())), self.pairs[:, 1]).reshape(-1, 1)\n\n        return np.concatenate([\n            self.pairs,\n            np.concatenate([free_trx, np.full((len(free_trx), 1), '0')], axis=1),\n            np.concatenate([np.full((len(free_clicks), 1), '0'), free_clicks], axis=1),\n        ], axis=0)\n\n    def __len__(self):\n        return len(self.full_pairs)\n\n    def __getitem__(self, item):\n        ids = self.full_pairs[item]\n        return tuple([[a(d[i]) if i != '0' else None for _ in range(self.n_sample)]\n                      for i, d, a in zip(ids, self.data, self.augmentations)])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.762967Z","iopub.execute_input":"2025-02-28T05:00:43.763266Z","iopub.status.idle":"2025-02-28T05:00:43.777207Z","shell.execute_reply.started":"2025-02-28T05:00:43.763238Z","shell.execute_reply":"2025-02-28T05:00:43.775935Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class PBLayerNorm(torch.nn.LayerNorm):\n    def forward(self, x: PaddedBatch):\n        return PaddedBatch(super().forward(x.payload), x.seq_lens)\n\nclass L2Scorer(torch.nn.Module):\n    def forward(self, x):\n        B, H = x.size()\n        a, b =x[:, :H // 2], x[:, H // 2:]\n        return -(a - b).pow(2).sum(dim=1)\n\nclass PairedModule(pl.LightningModule):\n    def __init__(self, params, trx_amnt_quantiles, k,\n                 lr, weight_decay,\n                 max_lr, pct_start, total_steps,\n                 beta, neg_count,\n                 ):\n        super().__init__()\n        self.save_hyperparameters(ignore=['mlm_model_trx', 'mlm_model_click'])\n\n        common_trx_size = params.common_trx_size\n        self.rnn_enc = torch.nn.Sequential(\n            RnnEncoder(\n                common_trx_size,\n                type=params.rnn.type,\n                hidden_size=params.rnn.hidden_size,\n                bidir=params.rnn.bidir,\n                trainable_starter=params.rnn.trainable_starter\n            ),\n            LastStepEncoder(),\n            #             NormEncoder(),\n        )\n        self._seq_encoder_trx = torch.nn.Sequential(\n            TransactionEncoder(params, trx_amnt_quantiles),\n            PBLayerNorm(common_trx_size),\n        )\n        self._seq_encoder_click = torch.nn.Sequential(\n            ClickEncoder(params),\n            PBLayerNorm(common_trx_size),\n        )\n\n        self.cls = torch.nn.Sequential(\n            L2Scorer(),\n        )\n\n        self.train_precision = PrecisionK(k=k)\n        self.train_mrr = MeanReciprocalRankK(k=k)\n        self.valid_precision = PrecisionK(k=k)\n        self.valid_mrr = MeanReciprocalRankK(k=k)\n\n    def load_pretrained(self, trx, click):\n        self._seq_encoder_trx[0].load_state_dict(trx.state_dict())\n        self._seq_encoder_click[0].load_state_dict(click.state_dict())\n\n    def seq_encoder_trx(self, x):\n        x = self._seq_encoder_trx(x)\n        return self.rnn_enc(x)\n\n    def seq_encoder_click(self, x_orig):\n        x = self._seq_encoder_click(x_orig)\n        #         x = PaddedBatch(\n        #             x.payload + self.mlm_model_click.sentence_encoding(x_orig),\n        #             x.seq_lens,\n        #         )\n        return self.rnn_enc(x)\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer=optim,\n            max_lr=self.hparams.max_lr,\n            total_steps=self.hparams.total_steps,\n            pct_start=self.hparams.pct_start,\n            anneal_strategy='cos',\n            cycle_momentum=False,\n            div_factor=25.0,\n            final_div_factor=10000.0,\n            three_phase=True,\n        )\n        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n        return [optim], [scheduler]\n\n    def loss_fn_p(self, embeddings, labels, ref_emb, ref_labels):\n        beta = self.hparams.beta\n        neg_count = self.hparams.neg_count\n\n        pos_ix = (labels.view(-1, 1) == ref_labels.view(1, -1)).nonzero(as_tuple=False)\n        pos_labels = labels[pos_ix[:, 0]]\n        neg_w = ((pos_labels.view(-1, 1) != ref_labels.view(1, -1))).float()\n        neg_ix = torch.multinomial(neg_w, neg_count - 1)\n        all_ix = torch.cat([pos_ix[:, [1]], neg_ix], dim=1)\n        logits = -(embeddings[pos_ix[:, [0]]] - ref_emb[all_ix]).pow(2).sum(dim=2)\n        logits = logits * beta\n        logs = -torch.log(torch.softmax(logits, dim=1))[:, 0]\n        #         logs = torch.relu(logs + np.log(0.1))\n        return logs.mean()\n\n    def training_step(self, batch, batch_idx):\n        # pairs\n        x_trx, l_trx, m_trx, x_click, l_click, m_click = batch\n        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n        z_click = self.seq_encoder_click(x_click)  # B, H\n        loss_pt = self.loss_fn_p(embeddings=z_trx, labels=l_trx, ref_emb=z_click, ref_labels=l_click)\n        self.log('loss/loss_pt', loss_pt)\n\n        loss_pc = self.loss_fn_p(embeddings=z_click, labels=l_click, ref_emb=z_trx, ref_labels=l_trx)\n        self.log('loss/loss_pc', loss_pc)\n\n        with torch.no_grad():\n            out = -(z_trx.unsqueeze(1) - z_click.unsqueeze(0)).pow(2).sum(dim=2)\n            out = out[m_trx == 0][:, m_click == 0]\n            T, C = out.size()\n            assert T == C\n            n_samples = z_trx.size(0) // (l_trx.max().item() + 1)\n            for i in range(n_samples):\n                l2 = out[i::n_samples, i::n_samples]\n                self.train_precision(l2)\n                self.train_mrr(l2)\n\n        return loss_pt + 0.1 * loss_pc  # loss_pc\n\n    def on_train_epoch_end(self):\n        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n        self.log('train_metrics/mrr', self.train_mrr, prog_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.778132Z","iopub.execute_input":"2025-02-28T05:00:43.778437Z","iopub.status.idle":"2025-02-28T05:00:43.798775Z","shell.execute_reply.started":"2025-02-28T05:00:43.778404Z","shell.execute_reply":"2025-02-28T05:00:43.797908Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torchmetrics\nfrom torchmetrics import Metric\nimport pytorch_lightning as pl\n\n\nclass PrecisionK(Metric):\n    def __init__(self, k, **params):\n        super().__init__(**params)\n\n        self.add_state('_sum', torch.tensor(0))\n        self.add_state('_cnt', torch.tensor(0))\n        self.k = k\n\n    def update(self, preds, target=None):\n        B, _ = preds.size()\n        ix_sort = torch.argsort(preds, dim=1, descending=True)\n        ix_sort = ix_sort == torch.arange(B, device=preds.device, dtype=torch.long).view(-1, 1)\n        k = min(self.k, B)\n        ix_sort = (ix_sort[:, :k].int().sum(dim=1) > 0).int().sum()\n        self._sum = self._sum + ix_sort\n        self._cnt = self._cnt + B\n\n    def compute(self):\n        return self._sum.float() / self._cnt.float()\n\n\nclass MeanReciprocalRankK(Metric):\n    def __init__(self, k, max_k=100, **params):\n        super().__init__(**params)\n\n        self.add_state('_sum', torch.tensor(0))\n        self.add_state('_cnt', torch.tensor(0))\n        self.k = k\n        self.max_k = max_k\n\n    def update(self, preds, target=None):\n        B, _ = preds.size()\n        ix_sort = torch.argsort(preds, dim=1, descending=True)\n        ix_sort = ix_sort == torch.arange(B, device=preds.device, dtype=torch.long).view(-1, 1)\n        k = min(self.k, B)\n        ix_sort = ix_sort[:, :k]\n        ranks = self.k / self.max_k / (1 + torch.arange(k, device=preds.device).view(1, -1).expand(B, k))\n        ranks = ranks[ix_sort]\n\n        self._sum = self._sum + ranks.sum()\n        self._cnt = self._cnt + B\n\n    def compute(self):\n        return self._sum.float() / self._cnt.float()\n\n\nclass ValidationCallback(pl.Callback):\n    def __init__(self, v_trx, v_click, target, device, device_main, k=100, batch_size=1024):\n        self.v_trx = v_trx\n        self.v_click = v_click\n        self.target = target\n        self.device = device\n        self.device_main = device_main\n        self.k = k\n        self.batch_size = batch_size\n\n    def on_train_epoch_end(self, trainer, pl_module):\n        was_traning = False\n        if pl_module.training:\n            pl_module.eval()\n            was_traning = True\n\n        pl_module.to(self.device)\n        with torch.no_grad():\n            z_trx = []\n            for ((x_trx, _),) in self.v_trx:\n                z_trx.append(pl_module.seq_encoder_trx(x_trx.to(self.device)))\n            z_trx = torch.cat(z_trx, dim=0)\n            z_click = []\n            for ((x_click, _),) in self.v_click:\n                z_click.append(pl_module.seq_encoder_click(x_click.to(self.device)))\n            z_click = torch.cat(z_click, dim=0)\n\n            T = z_trx.size(0)\n            C = z_click.size(0)\n            device = z_trx.device\n            ix_t = torch.arange(T, device=device).view(-1, 1).expand(T, C).flatten()\n            ix_c = torch.arange(C, device=device).view(1, -1).expand(T, C).flatten()\n\n            z_out = []\n            for i in range(0, len(ix_t), self.batch_size):\n                z_pairs = torch.cat([\n                    z_trx[ix_t[i:i + self.batch_size]],\n                    z_click[ix_c[i:i + self.batch_size]],\n                ], dim=1)\n                z_out.append(pl_module.cls(z_pairs).unsqueeze(1))\n            z_out = torch.cat(z_out, dim=0).view(T, C)\n\n            precision, mrr, r1 = self.logits_to_metrics(z_out)\n\n            pl_module.log('valid_full_metrics/precision', precision, prog_bar=True)\n            pl_module.log('valid_full_metrics/mrr', mrr, prog_bar=False)\n            pl_module.log('valid_full_metrics/r1', r1, prog_bar=False)\n\n        pl_module.to(self.device_main)\n        if was_traning:\n            pl_module.train()\n\n    def logits_to_metrics(self, z_out):\n        T, C = z_out.size()\n        z_ranks = torch.zeros_like(z_out)\n        z_ranks[\n            torch.arange(T, device=self.device).view(-1, 1).expand(T, C),\n            torch.argsort(z_out, dim=1, descending=True),\n        ] = torch.arange(C, device=self.device).float().view(1, -1).expand(T, C) + 1\n        true_ranks = z_ranks[\n            np.arange(T),\n            np.searchsorted(self.v_click.dataset.pairs[:, 0],\n                            self.target.set_index('bank')['rtk'].loc[self.v_trx.dataset.pairs[:, 0]].values)\n        ]\n        precision = torch.where(true_ranks <= self.k,\n                                torch.ones(1, device=self.device), torch.zeros(1, device=self.device)).mean()\n        mrr = torch.where(true_ranks <= self.k, 1 / true_ranks, torch.zeros(1, device=self.device)).mean()\n        r1 = 2 * mrr * precision / (mrr + precision)\n        return precision, mrr, r1\n\n\nclass ValidationSplittingCallback(pl.Callback):\n    def __init__(self, v_trx, v_click, target, device, device_main, agg_method, k=100, batch_size=1024):\n        self.v_trx = v_trx\n        self.v_click = v_click\n        self.target = target\n        self.device = device\n        self.device_main = device_main\n        self.agg_method = agg_method\n        self.k = k\n        self.batch_size = batch_size\n\n    def on_train_epoch_end(self, trainer, pl_module):\n        was_traning = False\n        if pl_module.training:\n            pl_module.eval()\n            was_traning = True\n\n        pl_module.to(self.device)\n        with torch.no_grad():\n            z_trx = []\n            for ((x_trx, _),) in self.v_trx:\n                z_trx.append(pl_module.seq_encoder_trx(x_trx.to(self.device)))\n            z_trx = torch.cat(z_trx, dim=0)\n            z_click = []\n            for ((x_click, _),) in self.v_click:\n                z_click.append(pl_module.seq_encoder_click(x_click.to(self.device)))\n            z_click = torch.cat(z_click, dim=0)\n\n            T = z_trx.size(0)\n            C = z_click.size(0)\n            device = z_trx.device\n            ix_t = torch.arange(T, device=device).view(-1, 1).expand(T, C).flatten()\n            ix_c = torch.arange(C, device=device).view(1, -1).expand(T, C).flatten()\n\n            z_out = []\n            for i in range(0, len(ix_t), self.batch_size):\n                z_pairs = torch.cat([\n                    z_trx[ix_t[i:i + self.batch_size]],\n                    z_click[ix_c[i:i + self.batch_size]],\n                ], dim=1)\n                z_out.append(pl_module.cls(z_pairs).unsqueeze(1))\n            z_out = torch.cat(z_out, dim=0).view(T, C)\n\n            T, Nt = len(self.v_trx.dataset), z_out.size(0) // len(self.v_trx.dataset)\n            C, Nc = len(self.v_click.dataset), z_out.size(1) // len(self.v_click.dataset)\n\n            if self.agg_method == 'max':\n                z_out = z_out.view(T, Nt, C, Nc).max(dim=3).values.max(dim=1).values\n            elif self.agg_method == 'mean':\n                z_out = z_out.view(T, Nt, C, Nc).mean(dim=[1, 3])\n            else:\n                raise AttributeError(f'agg_method: {self.agg_method}')\n\n            precision, mrr, r1 = self.logits_to_metrics(z_out)\n\n            pl_module.log('valid_full_metrics/precision', precision, prog_bar=True)\n            pl_module.log('valid_full_metrics/mrr', mrr, prog_bar=False)\n            pl_module.log('valid_full_metrics/r1', r1, prog_bar=False)\n\n        pl_module.to(self.device_main)\n        if was_traning:\n            pl_module.train()\n\n    def logits_to_metrics(self, z_out):\n        T, C = z_out.size()\n        z_ranks = torch.zeros_like(z_out)\n        z_ranks[\n            torch.arange(T, device=self.device).view(-1, 1).expand(T, C),\n            torch.argsort(z_out, dim=1, descending=True),\n        ] = torch.arange(C, device=self.device).float().view(1, -1).expand(T, C) + 1\n        true_ranks = z_ranks[\n            np.arange(T),\n            np.searchsorted(self.v_click.dataset.ids,\n                            self.target.set_index('bank')['rtk'].loc[self.v_trx.dataset.ids].values)\n        ]\n        precision = torch.where(true_ranks <= self.k,\n                                torch.ones(1, device=self.device), torch.zeros(1, device=self.device)).mean()\n        mrr = torch.where(true_ranks <= self.k, 1 / true_ranks, torch.zeros(1, device=self.device)).mean()\n        r1 = 2 * mrr * precision / (mrr + precision)\n        return precision, mrr, r1\n\n\nclass MeanLoss(torchmetrics.Metric):\n    def __init__(self, **params):\n        super().__init__(**params)\n\n        self.add_state('_sum', torch.tensor([0.0]))\n        self.add_state('_cnt', torch.tensor([0]))\n\n    def update(self, x):\n        self._sum += x.sum()\n        self._cnt += x.numel()\n\n    def compute(self):\n        return self._sum / self._cnt.float()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.799605Z","iopub.execute_input":"2025-02-28T05:00:43.799929Z","iopub.status.idle":"2025-02-28T05:00:43.827072Z","shell.execute_reply.started":"2025-02-28T05:00:43.799897Z","shell.execute_reply":"2025-02-28T05:00:43.826208Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from ptls.data_load import padded_collate_wo_target\n\ndef train_qsm(df_matching_train, features_trx_train, features_click_train, model_n, cfg):\n    batch_size = 128\n    train_dl = torch.utils.data.DataLoader(\n        PairedFullDataset(\n            df_matching_train[lambda x: x['rtk'].ne('0')].values,\n            data=[\n                features_trx_train,\n                features_click_train,\n            ],\n            augmentations=[\n                augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n                augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n            ],\n            n_sample=2,\n        ),\n        collate_fn=PairedFullDataset.collate_fn,\n        drop_last=True,\n        shuffle=True,\n        num_workers=12,\n        batch_size=batch_size,\n        persistent_workers=True,\n    )\n\n    mlm_model_trx = MLMPretrainModuleTrx.load_from_checkpoint(f'{cfg.objects_path}/pretrain_trx.cpt')\n    mlm_model_click = MLMPretrainModuleClick.load_from_checkpoint(f'{cfg.objects_path}/pretrain_click.cpt')\n    pl.seed_everything(random.randint(1, 2**16 - 1))\n    sup_model = PairedModule(\n        cfg.model_config, trx_amnt_quantiles=mlm_model_trx.seq_encoder.trx_amnt_quantiles,\n        k=100 * batch_size // 3000,\n        lr=0.0022, weight_decay=0,\n        max_lr=0.0018, pct_start=1100 / 6000, total_steps=6000,\n        beta=0.2 / 1.4, neg_count=120,\n    )\n    sup_model.load_pretrained(mlm_model_trx.seq_encoder, mlm_model_click.seq_encoder)\n\n    trainer = pl.Trainer(\n        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        max_steps=3300,\n        callbacks=[\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelCheckpoint(\n                every_n_train_steps=1000, save_top_k=-1,\n            ),\n        ]\n    )\n    print('Train qsm start')\n    trainer.fit(sup_model, train_dl)\n    trainer.save_checkpoint(f'{cfg.objects_path}/nn_distance_coles_model_{model_n}.cpt', weights_only=True)\n    print(f'Train qsm [{model_n}] done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.827943Z","iopub.execute_input":"2025-02-28T05:00:43.828205Z","iopub.status.idle":"2025-02-28T05:00:43.843265Z","shell.execute_reply.started":"2025-02-28T05:00:43.828184Z","shell.execute_reply":"2025-02-28T05:00:43.842509Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"**C предобучением энкодеров**","metadata":{}},{"cell_type":"code","source":"# ensemble_size = 1\n\n# for i in range(ensemble_size):\n#     train_qsm(df_matching_train, features_trx_train, features_click_train, i, cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:43.844083Z","iopub.execute_input":"2025-02-28T05:00:43.844357Z","iopub.status.idle":"2025-02-28T05:00:43.856765Z","shell.execute_reply.started":"2025-02-28T05:00:43.844328Z","shell.execute_reply":"2025-02-28T05:00:43.855990Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"**mrr~0.029 на одной модели. на ансамбле из 3-х моделей ~0.08. На 2-х фолдах**\n\n**В оригинальном репозитории, ансамбль из 5 моделей, mrr=0.2**","metadata":{}},{"cell_type":"markdown","source":"**Без предобучения енкодеров**","metadata":{}},{"cell_type":"code","source":"from ptls.data_load import padded_collate_wo_target\n\ndef train_qsm(df_matching_train, features_trx_train, features_click_train, model_n, cfg):\n    batch_size = 128\n    train_dl = torch.utils.data.DataLoader(\n        PairedFullDataset(\n            df_matching_train[lambda x: x['rtk'].ne('0')].values,\n            data=[\n                features_trx_train,\n                features_click_train,\n            ],\n            augmentations=[\n                augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n                augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n            ],\n            n_sample=2,\n        ),\n        collate_fn=PairedFullDataset.collate_fn,\n        drop_last=True,\n        shuffle=True,\n        num_workers=12,\n        batch_size=batch_size,\n        persistent_workers=True,\n    )\n\n    train_dl_mlm_trx = torch.utils.data.DataLoader(\n        PairedDataset(\n            np.sort(np.array(list(features_trx_train.keys()))).reshape(-1, 1),\n            data=[features_trx_train],\n            augmentations=[augmentation_chain(\n                DropDuplicate('mcc_code', col_new_cnt='c_cnt'),\n                RandomSlice(32, 128)\n            )],\n            n_sample=1,\n        ),\n        collate_fn=PairedDataset.collate_fn,\n        shuffle=True,\n        num_workers=12,\n        batch_size=128,\n        persistent_workers=True,\n    )\n    \n    v = []\n    for batch in train_dl_mlm_trx:\n        v.append(batch[0][0].payload['transaction_amt'][batch[0][0].seq_len_mask.bool()])\n    v = torch.cat(v)\n    trx_amnt_quantiles = torch.quantile(torch.unique(v), torch.linspace(0, 1, 100, dtype=v.dtype))\n\n    mlm_model_trx = MLMPretrainModuleTrx(\n        params=cfg.model_config,\n        lr=0.001, weight_decay=0,\n        max_lr=0.001, pct_start=9000 / 2 / 10000, total_steps=10000,\n        trx_amnt_quantiles=trx_amnt_quantiles,\n    )\n    mlm_model_click = MLMPretrainModuleClick(\n        params=cfg.model_config,\n        lr=0.001, weight_decay=0,\n        max_lr=0.001, pct_start=9000 / 2 / 10000, total_steps=10000,\n    )\n    pl.seed_everything(random.randint(1, 2**16 - 1))\n    sup_model = PairedModule(\n        cfg.model_config, trx_amnt_quantiles=mlm_model_trx.seq_encoder.trx_amnt_quantiles,\n        k=100 * batch_size // 3000,\n        lr=0.0022, weight_decay=0,\n        max_lr=0.0018, pct_start=1100 / 6000, total_steps=6000,\n        beta=0.2 / 1.4, neg_count=120,\n    )\n    sup_model.load_pretrained(mlm_model_trx.seq_encoder, mlm_model_click.seq_encoder)\n\n    trainer = pl.Trainer(\n        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        max_steps=3300,\n        callbacks=[\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelCheckpoint(\n                every_n_train_steps=1000, save_top_k=-1,\n            ),\n        ]\n    )\n    print('Train qsm start')\n    trainer.fit(sup_model, train_dl)\n    trainer.save_checkpoint(f'{cfg.objects_path}/nn_distance_coles_model_{model_n}.cpt', weights_only=True)\n    print(f'Train qsm [{model_n}] done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:07:42.947384Z","iopub.execute_input":"2025-02-28T05:07:42.947767Z","iopub.status.idle":"2025-02-28T05:07:42.957998Z","shell.execute_reply.started":"2025-02-28T05:07:42.947738Z","shell.execute_reply":"2025-02-28T05:07:42.957110Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"ensemble_size = 1\n\nfor i in range(ensemble_size):\n    train_qsm(df_matching_train, features_trx_train, features_click_train, i, cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:07:43.104531Z","iopub.execute_input":"2025-02-28T05:07:43.104741Z","execution_failed":"2025-02-28T05:46:13.817Z"}},"outputs":[{"name":"stdout","text":"{'norm_embeddings': False, 'embeddings_noise': 0.003, 'embeddings': {'mcc_code': {'in': 350, 'out': 64}, 'currency_rk': {'in': 10, 'out': 4}, 'transaction_amt_q': {'in': 110, 'out': 8}, 'hour': {'in': 30, 'out': 16}, 'weekday': {'in': 10, 'out': 4}, 'day_diff': {'in': 15, 'out': 8}}, 'numeric_values': {'transaction_amt': 'identity', 'c_cnt': 'log'}}\n{'norm_embeddings': False, 'embeddings_noise': 0.003, 'embeddings': {'mcc_code': {'in': 350, 'out': 64}, 'currency_rk': {'in': 10, 'out': 4}, 'transaction_amt_q': {'in': 110, 'out': 8}, 'hour': {'in': 30, 'out': 16}, 'weekday': {'in': 10, 'out': 4}, 'day_diff': {'in': 15, 'out': 8}}, 'numeric_values': {'transaction_amt': 'identity', 'c_cnt': 'log'}}\nTrain qsm start\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa0a45258fa84d02b45020ccc246c682"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"Энкодеры учатся и внутри, но крайне медленно\n\nПри обучении энкодеров внутри, они обучаются сильно медленнее, чем отдельно\n\nОжидалось, что обучение будет медленнее, но сравнимо с оригинальным подходом","metadata":{}},{"cell_type":"markdown","source":"# Module with cross-attention","metadata":{}},{"cell_type":"markdown","source":"**cross-attention without mean**","metadata":{}},{"cell_type":"code","source":"from torch import nn\n\nclass PBLayerNorm(torch.nn.LayerNorm):\n    def forward(self, x: PaddedBatch):\n        return PaddedBatch(super().forward(x.payload), x.seq_lens)\n\nclass L2Scorer(torch.nn.Module):\n    def forward(self, x):\n        B, H = x.size()\n        a, b =x[:, :H // 2], x[:, H // 2:]\n        return -(a - b).pow(2).sum(dim=1)\n\nclass PairedModule(pl.LightningModule):\n    def __init__(self, params, trx_amnt_quantiles, k,\n                 lr, weight_decay,\n                 max_lr, pct_start, total_steps,\n                 beta, neg_count,\n                 ):\n        super().__init__()\n        self.save_hyperparameters(ignore=['mlm_model_trx', 'mlm_model_click'])\n\n        common_trx_size = params.common_trx_size\n        self.rnn_enc = torch.nn.Sequential(\n            RnnEncoder(\n                common_trx_size,\n                type=params.rnn.type,\n                hidden_size=params.rnn.hidden_size,\n                bidir=params.rnn.bidir,\n                trainable_starter=params.rnn.trainable_starter\n            ),\n            LastStepEncoder(),\n            #             NormEncoder(),\n        )\n        self.mha_trx_click = nn.MultiheadAttention(\n            embed_dim=256,##?,\n            num_heads=4,\n            dropout=0.3,\n            batch_first=True\n        )\n        self.mha_click_trx = nn.MultiheadAttention(\n            embed_dim=256,##?,\n            num_heads=4,\n            dropout=0.3,\n            batch_first=True\n        )\n        self._seq_encoder_trx = torch.nn.Sequential(\n            TransactionEncoder(params, trx_amnt_quantiles),\n            PBLayerNorm(common_trx_size),\n        )\n        self._seq_encoder_click = torch.nn.Sequential(\n            ClickEncoder(params),\n            PBLayerNorm(common_trx_size),\n        )\n\n        self.cls = torch.nn.Sequential(\n            L2Scorer(),\n        )\n\n        self.train_precision = PrecisionK(k=k)\n        self.train_mrr = MeanReciprocalRankK(k=k)\n        self.valid_precision = PrecisionK(k=k)\n        self.valid_mrr = MeanReciprocalRankK(k=k)\n\n    def load_pretrained(self, trx, click):\n        self._seq_encoder_trx[0].load_state_dict(trx.state_dict())\n        self._seq_encoder_click[0].load_state_dict(click.state_dict())\n\n    def seq_encoder_trx(self, x):\n        x = self._seq_encoder_trx(x)\n        return self.rnn_enc(x)\n\n    def seq_encoder_click(self, x_orig):\n        x = self._seq_encoder_click(x_orig)\n        #         x = PaddedBatch(\n        #             x.payload + self.mlm_model_click.sentence_encoding(x_orig),\n        #             x.seq_lens,\n        #         )\n        return self.rnn_enc(x)\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer=optim,\n            max_lr=self.hparams.max_lr,\n            total_steps=self.hparams.total_steps,\n            pct_start=self.hparams.pct_start,\n            anneal_strategy='cos',\n            cycle_momentum=False,\n            div_factor=25.0,\n            final_div_factor=10000.0,\n            three_phase=True,\n        )\n        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n        return [optim], [scheduler]\n\n    def loss_fn_p(self, embeddings, labels, ref_emb, ref_labels):\n        beta = self.hparams.beta\n        neg_count = self.hparams.neg_count\n\n        pos_ix = (labels.view(-1, 1) == ref_labels.view(1, -1)).nonzero(as_tuple=False)\n        pos_labels = labels[pos_ix[:, 0]]\n        neg_w = ((pos_labels.view(-1, 1) != ref_labels.view(1, -1))).float()\n        neg_ix = torch.multinomial(neg_w, neg_count - 1)\n        all_ix = torch.cat([pos_ix[:, [1]], neg_ix], dim=1)\n        logits = -(embeddings[pos_ix[:, [0]]] - ref_emb[all_ix]).pow(2).sum(dim=2)\n        logits = logits * beta\n        logs = -torch.log(torch.softmax(logits, dim=1))[:, 0]\n        #         logs = torch.relu(logs + np.log(0.1))\n        return logs.mean()\n\n    def training_step(self, batch, batch_idx):\n        # pairs\n        x_trx, l_trx, m_trx, x_click, l_click, m_click = batch\n        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n        z_click = self.seq_encoder_click(x_click)  # B, H\n        z_trx, _ = self.mha_trx_click(z_trx, z_click, z_click)\n        z_click, _ = self.mha_click_trx(z_click, z_trx, z_trx)\n        loss_pt = self.loss_fn_p(embeddings=z_trx, labels=l_trx, ref_emb=z_click, ref_labels=l_click)\n        self.log('loss/loss_pt', loss_pt)\n\n        loss_pc = self.loss_fn_p(embeddings=z_click, labels=l_click, ref_emb=z_trx, ref_labels=l_trx)\n        self.log('loss/loss_pc', loss_pc)\n\n        with torch.no_grad():\n            out = -(z_trx.unsqueeze(1) - z_click.unsqueeze(0)).pow(2).sum(dim=2)\n            out = out[m_trx == 0][:, m_click == 0]\n            T, C = out.size()\n            assert T == C\n            n_samples = z_trx.size(0) // (l_trx.max().item() + 1)\n            for i in range(n_samples):\n                l2 = out[i::n_samples, i::n_samples]\n                self.train_precision(l2)\n                self.train_mrr(l2)\n\n        return loss_pt + 0.1 * loss_pc  # loss_pc\n\n    def on_train_epoch_end(self):\n        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n        self.log('train_metrics/mrr', self.train_mrr, prog_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:25:34.467202Z","iopub.execute_input":"2025-02-28T04:25:34.467656Z","iopub.status.idle":"2025-02-28T04:25:34.493558Z","shell.execute_reply.started":"2025-02-28T04:25:34.467615Z","shell.execute_reply":"2025-02-28T04:25:34.492585Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"from ptls.data_load import padded_collate_wo_target\n\ndef train_qsm(df_matching_train, features_trx_train, features_click_train, model_n, cfg):\n    batch_size = 64\n    train_dl = torch.utils.data.DataLoader(\n        PairedFullDataset(\n            df_matching_train[lambda x: x['rtk'].ne('0')].values,\n            data=[\n                features_trx_train,\n                features_click_train,\n            ],\n            augmentations=[\n                augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n                augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n            ],\n            n_sample=2,\n        ),\n        collate_fn=PairedFullDataset.collate_fn,\n        drop_last=True,\n        shuffle=True,\n        num_workers=12,\n        batch_size=batch_size,\n        persistent_workers=True,\n    )\n\n    mlm_model_trx = MLMPretrainModuleTrx.load_from_checkpoint(f'{cfg.objects_path}/pretrain_trx.cpt')\n    mlm_model_click = MLMPretrainModuleClick.load_from_checkpoint(f'{cfg.objects_path}/pretrain_click.cpt')\n    pl.seed_everything(random.randint(1, 2**16 - 1))\n    sup_model = PairedModule(\n        cfg.model_config, trx_amnt_quantiles=mlm_model_trx.seq_encoder.trx_amnt_quantiles,\n        k=100 * batch_size // 3000,\n        lr=0.0022, weight_decay=0,\n        max_lr=0.0018, pct_start=1100 / 6000, total_steps=6000,\n        beta=0.2 / 1.4, neg_count=60,\n    )\n    sup_model.load_pretrained(mlm_model_trx.seq_encoder, mlm_model_click.seq_encoder)\n\n    trainer = pl.Trainer(\n        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        max_steps=4000,\n        callbacks=[\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelCheckpoint(\n                every_n_train_steps=1000, save_top_k=-1,\n            ),\n        ]\n    )\n    print('Train qsm start')\n    trainer.fit(sup_model, train_dl)\n    trainer.save_checkpoint(f'{cfg.objects_path}/nn_distance_coles_model_{model_n}.cpt', weights_only=True)\n    print(f'Train qsm [{model_n}] done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:25:35.640459Z","iopub.execute_input":"2025-02-28T04:25:35.640810Z","iopub.status.idle":"2025-02-28T04:25:35.648418Z","shell.execute_reply.started":"2025-02-28T04:25:35.640783Z","shell.execute_reply":"2025-02-28T04:25:35.647631Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# import gc\n# gc.collect()\n# torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:25:36.835259Z","iopub.execute_input":"2025-02-28T04:25:36.835550Z","iopub.status.idle":"2025-02-28T04:25:36.838881Z","shell.execute_reply.started":"2025-02-28T04:25:36.835526Z","shell.execute_reply":"2025-02-28T04:25:36.838023Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# ensemble_size = 1\n\n# for i in range(ensemble_size):\n#     train_qsm(df_matching_train, features_trx_train, features_click_train, i, cfg)","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**mrr~0.019 на одной модели. На 1-м фолде**","metadata":{}},{"cell_type":"markdown","source":"**cross-attention with mean**","metadata":{}},{"cell_type":"code","source":"from torch import nn\n\nclass PBLayerNorm(torch.nn.LayerNorm):\n    def forward(self, x: PaddedBatch):\n        return PaddedBatch(super().forward(x.payload), x.seq_lens)\n\nclass L2Scorer(torch.nn.Module):\n    def forward(self, x):\n        B, H = x.size()\n        a, b =x[:, :H // 2], x[:, H // 2:]\n        return -(a - b).pow(2).sum(dim=1)\n\nclass PairedModule(pl.LightningModule):\n    def __init__(self, params, trx_amnt_quantiles, k,\n                 lr, weight_decay,\n                 max_lr, pct_start, total_steps,\n                 beta, neg_count,\n                 ):\n        super().__init__()\n        self.save_hyperparameters(ignore=['mlm_model_trx', 'mlm_model_click'])\n\n        common_trx_size = params.common_trx_size\n        self.rnn_enc = torch.nn.Sequential(\n            RnnEncoder(\n                common_trx_size,\n                type=params.rnn.type,\n                hidden_size=params.rnn.hidden_size,\n                bidir=params.rnn.bidir,\n                trainable_starter=params.rnn.trainable_starter\n            ),\n            LastStepEncoder(),\n            #             NormEncoder(),\n        )\n        self.mha_trx_click = nn.MultiheadAttention(\n            embed_dim=256,##?,\n            num_heads=4,\n            dropout=0.3,\n            batch_first=True\n        )\n        self.mha_click_trx = nn.MultiheadAttention(\n            embed_dim=256,##?,\n            num_heads=4,\n            dropout=0.3,\n            batch_first=True\n        )\n        self._seq_encoder_trx = torch.nn.Sequential(\n            TransactionEncoder(params, trx_amnt_quantiles),\n            PBLayerNorm(common_trx_size),\n        )\n        self._seq_encoder_click = torch.nn.Sequential(\n            ClickEncoder(params),\n            PBLayerNorm(common_trx_size),\n        )\n\n        self.cls = torch.nn.Sequential(\n            L2Scorer(),\n        )\n\n        self.train_precision = PrecisionK(k=k)\n        self.train_mrr = MeanReciprocalRankK(k=k)\n        self.valid_precision = PrecisionK(k=k)\n        self.valid_mrr = MeanReciprocalRankK(k=k)\n\n    def load_pretrained(self, trx, click):\n        self._seq_encoder_trx[0].load_state_dict(trx.state_dict())\n        self._seq_encoder_click[0].load_state_dict(click.state_dict())\n\n    def seq_encoder_trx(self, x):\n        x = self._seq_encoder_trx(x)\n        return self.rnn_enc(x)\n\n    def seq_encoder_click(self, x_orig):\n        x = self._seq_encoder_click(x_orig)\n        #         x = PaddedBatch(\n        #             x.payload + self.mlm_model_click.sentence_encoding(x_orig),\n        #             x.seq_lens,\n        #         )\n        return self.rnn_enc(x)\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer=optim,\n            max_lr=self.hparams.max_lr,\n            total_steps=self.hparams.total_steps,\n            pct_start=self.hparams.pct_start,\n            anneal_strategy='cos',\n            cycle_momentum=False,\n            div_factor=25.0,\n            final_div_factor=10000.0,\n            three_phase=True,\n        )\n        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n        return [optim], [scheduler]\n\n    def loss_fn_p(self, embeddings, labels, ref_emb, ref_labels):\n        beta = self.hparams.beta\n        neg_count = self.hparams.neg_count\n\n        pos_ix = (labels.view(-1, 1) == ref_labels.view(1, -1)).nonzero(as_tuple=False)\n        pos_labels = labels[pos_ix[:, 0]]\n        neg_w = ((pos_labels.view(-1, 1) != ref_labels.view(1, -1))).float()\n        neg_ix = torch.multinomial(neg_w, neg_count - 1)\n        all_ix = torch.cat([pos_ix[:, [1]], neg_ix], dim=1)\n        logits = -(embeddings[pos_ix[:, [0]]] - ref_emb[all_ix]).pow(2).sum(dim=2)\n        logits = logits * beta\n        logs = -torch.log(torch.softmax(logits, dim=1))[:, 0]\n        #         logs = torch.relu(logs + np.log(0.1))\n        return logs.mean()\n\n    def training_step(self, batch, batch_idx):\n        # pairs\n        x_trx, l_trx, m_trx, x_click, l_click, m_click = batch\n        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n        z_click = self.seq_encoder_click(x_click)  # B, H\n        z_trx, _ = self.mha_trx_click(z_trx, z_click, z_click)\n        z_click, _ = self.mha_click_trx(z_click, z_trx, z_trx)\n        \n        loss_pt = self.loss_fn_p(embeddings=z_trx, labels=l_trx, ref_emb=z_click, ref_labels=l_click)\n        self.log('loss/loss_pt', loss_pt)\n\n        loss_pc = self.loss_fn_p(embeddings=z_click, labels=l_click, ref_emb=z_trx, ref_labels=l_trx)\n        self.log('loss/loss_pc', loss_pc)\n\n        with torch.no_grad():\n            out = -(z_trx.unsqueeze(1) - z_click.unsqueeze(0)).pow(2).sum(dim=2)\n            out = out[m_trx == 0][:, m_click == 0]\n            T, C = out.size()\n            assert T == C\n            n_samples = z_trx.size(0) // (l_trx.max().item() + 1)\n            for i in range(n_samples):\n                l2 = out[i::n_samples, i::n_samples]\n                self.train_precision(l2)\n                self.train_mrr(l2)\n\n        return loss_pt + 0.1 * loss_pc  # loss_pc\n\n    def on_train_epoch_end(self):\n        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n        self.log('train_metrics/mrr', self.train_mrr, prog_bar=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ptls.data_load import padded_collate_wo_target\n\ndef train_qsm(df_matching_train, features_trx_train, features_click_train, model_n, cfg):\n    batch_size = 64\n    train_dl = torch.utils.data.DataLoader(\n        PairedFullDataset(\n            df_matching_train[lambda x: x['rtk'].ne('0')].values,\n            data=[\n                features_trx_train,\n                features_click_train,\n            ],\n            augmentations=[\n                augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n                augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n            ],\n            n_sample=2,\n        ),\n        collate_fn=PairedFullDataset.collate_fn,\n        drop_last=True,\n        shuffle=True,\n        num_workers=12,\n        batch_size=batch_size,\n        persistent_workers=True,\n    )\n\n    mlm_model_trx = MLMPretrainModuleTrx.load_from_checkpoint(f'{cfg.objects_path}/pretrain_trx.cpt')\n    mlm_model_click = MLMPretrainModuleClick.load_from_checkpoint(f'{cfg.objects_path}/pretrain_click.cpt')\n    pl.seed_everything(random.randint(1, 2**16 - 1))\n    sup_model = PairedModule(\n        cfg.model_config, trx_amnt_quantiles=mlm_model_trx.seq_encoder.trx_amnt_quantiles,\n        k=100 * batch_size // 3000,\n        lr=0.0022, weight_decay=0,\n        max_lr=0.0018, pct_start=1100 / 6000, total_steps=6000,\n        beta=0.2 / 1.4, neg_count=60,\n    )\n    sup_model.load_pretrained(mlm_model_trx.seq_encoder, mlm_model_click.seq_encoder)\n\n    trainer = pl.Trainer(\n        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        max_steps=46,\n        callbacks=[\n            pl.callbacks.LearningRateMonitor(),\n            pl.callbacks.ModelCheckpoint(\n                every_n_train_steps=1000, save_top_k=-1,\n            ),\n        ]\n    )\n    print('Train qsm start')\n    trainer.fit(sup_model, train_dl)\n    trainer.save_checkpoint(f'{cfg.objects_path}/nn_distance_coles_model_{model_n}.cpt', weights_only=True)\n    print(f'Train qsm [{model_n}] done')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_size = 1\n\nfor i in range(ensemble_size):\n    train_qsm(df_matching_train, features_trx_train, features_click_train, i, cfg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GPT, CoLES\n\n**Get pyspark data**","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/Dzhambo/MBD.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimport pyspark\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nfrom pyspark.sql import types as T\nimport ptls\nfrom ptls.preprocessing import PysparkDataPreprocessor\n\n# os.environ['JAVA_HOME']= ''\n\nspark_conf = pyspark.SparkConf()\nspark_conf.setMaster(\"local[*]\").setAppName(\"JoinModality\")\nspark_conf.set(\"spark.driver.maxResultSize\", \"8g\")\nspark_conf.set(\"spark.executor.memory\", \"16g\")\nspark_conf.set(\"spark.executor.memoryOverhead\", \"8g\")\nspark_conf.set(\"spark.driver.memory\", \"16g\")\nspark_conf.set(\"spark.driver.memoryOverhead\", \"8g\")\nspark_conf.set(\"spark.cores.max\", \"4\")\nspark_conf.set(\"spark.sql.shuffle.partitions\", \"200\")\nspark_conf.set(\"spark.local.dir\", \"../../spark_local_dir\")\n\n\nspark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\nspark.sparkContext.getConf().getAll()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:02:52.020788Z","iopub.execute_input":"2025-02-28T07:02:52.021212Z","iopub.status.idle":"2025-02-28T07:03:01.642396Z","shell.execute_reply.started":"2025-02-28T07:02:52.021187Z","shell.execute_reply":"2025-02-28T07:03:01.641391Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[('spark.driver.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.app.name', 'JoinModality'),\n ('spark.local.dir', '../../spark_local_dir'),\n ('spark.app.submitTime', '1740726179307'),\n ('spark.executor.id', 'driver'),\n ('spark.driver.memory', '16g'),\n ('spark.cores.max', '4'),\n ('spark.driver.memoryOverhead', '8g'),\n ('spark.executor.memory', '16g'),\n ('spark.driver.host', '219f4d6e0b93'),\n ('spark.executor.memoryOverhead', '8g'),\n ('spark.app.id', 'local-1740726180967'),\n ('spark.driver.maxResultSize', '8g'),\n ('spark.rdd.compress', 'True'),\n ('spark.executor.extraJavaOptions',\n  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n ('spark.serializer.objectStreamReset', '100'),\n ('spark.driver.port', '36637'),\n ('spark.master', 'local[*]'),\n ('spark.submit.pyFiles', ''),\n ('spark.app.startTime', '1740726179545'),\n ('spark.submit.deployMode', 'client'),\n ('spark.sql.shuffle.partitions', '200'),\n ('spark.ui.showConsoleProgress', 'true')]"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!unzip ./data/raw_data/transactions.zip -d ./data/raw_data/\n!unzip ./data/raw_data/clickstream.zip -d ./data/raw_data/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:03:01.643988Z","iopub.execute_input":"2025-02-28T07:03:01.644605Z","iopub.status.idle":"2025-02-28T07:03:50.402434Z","shell.execute_reply.started":"2025-02-28T07:03:01.644582Z","shell.execute_reply":"2025-02-28T07:03:50.401384Z"}},"outputs":[{"name":"stdout","text":"Archive:  ./data/raw_data/transactions.zip\n  inflating: ./data/raw_data/transactions.csv  \n  inflating: ./data/raw_data/__MACOSX/._transactions.csv  \nArchive:  ./data/raw_data/clickstream.zip\n  inflating: ./data/raw_data/clickstream.csv  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"transactions = spark.read.csv('./data/raw_data/transactions.csv', header=True)\nclickstream = spark.read.csv('./data/raw_data/clickstream.csv', header=True)\ntrain_matching = spark.read.csv('./data/raw_data/train_matching.csv', header=True)\n# train_edu = spark.read.csv('../data/raw_data/train_edu.csv', header=True) #Этого файла нет\n\nclick_categories = spark.read.csv('./data/raw_data/click_categories.csv', header=True)\nclickstream = clickstream.join(click_categories, on='cat_id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:03:50.404229Z","iopub.execute_input":"2025-02-28T07:03:50.404592Z","iopub.status.idle":"2025-02-28T07:03:57.271636Z","shell.execute_reply.started":"2025-02-28T07:03:50.404548Z","shell.execute_reply":"2025-02-28T07:03:57.270566Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"preprocessor_trx = PysparkDataPreprocessor(\n        col_id='user_id',\n        col_event_time='transaction_dttm',\n        event_time_transformation='dt_to_timestamp',\n        cols_category=[\"mcc_code\", \"currency_rk\"],\n    )\n\n\npreprocessor_click = PysparkDataPreprocessor(\n    col_id='user_id',\n    col_event_time='timestamp',\n    event_time_transformation='dt_to_timestamp',\n    cols_category=['cat_id', 'level_0', 'level_1', 'level_2'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:03:57.272737Z","iopub.execute_input":"2025-02-28T07:03:57.273080Z","iopub.status.idle":"2025-02-28T07:03:59.228403Z","shell.execute_reply.started":"2025-02-28T07:03:57.273048Z","shell.execute_reply":"2025-02-28T07:03:59.227374Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"transactions_prepared = preprocessor_trx.fit_transform(transactions)\nclickstream_prepared = preprocessor_click.fit_transform(clickstream)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:03:59.229469Z","iopub.execute_input":"2025-02-28T07:03:59.229778Z","iopub.status.idle":"2025-02-28T07:09:40.856786Z","shell.execute_reply.started":"2025-02-28T07:03:59.229745Z","shell.execute_reply":"2025-02-28T07:09:40.855923Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_matching = train_matching.withColumnRenamed('rtk', 'user_id')\nclickstream_prepared = clickstream_prepared.join(train_matching, on='user_id', how='outer').drop('user_id')\nclickstream_prepared  = clickstream_prepared.withColumnRenamed('bank', 'user_id')\nclickstream_prepared.show(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:09:40.857514Z","iopub.execute_input":"2025-02-28T07:09:40.857792Z","iopub.status.idle":"2025-02-28T07:12:51.890939Z","shell.execute_reply.started":"2025-02-28T07:09:40.857766Z","shell.execute_reply":"2025-02-28T07:12:51.889911Z"}},"outputs":[{"name":"stdout","text":"+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|          event_time|              cat_id|             new_uid|             level_0|             level_1|             level_2|             user_id|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|[1616467560, 1616...|[1, 1, 1, 1, 1, 1...|[411399, 411399, ...|[1, 1, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|95f2446d41fc4536b...|\n|[1612159140, 1612...|[3, 12, 5, 12, 40...|[1840824, 1840824...|[3, 5, 5, 5, 38, ...|[1, 2, 1, 2, 1, 1...|[1, 1, 1, 1, 1, 1...|89d5b991d5dc4c5d8...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 2 rows\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"clickstream_prepared = clickstream_prepared.withColumnRenamed('event_time', 'click_event_time')\ntransactions_prepared = transactions_prepared.withColumnRenamed('event_time', 'trx_event_time')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:12:51.894203Z","iopub.execute_input":"2025-02-28T07:12:51.894546Z","iopub.status.idle":"2025-02-28T07:12:51.913249Z","shell.execute_reply.started":"2025-02-28T07:12:51.894501Z","shell.execute_reply":"2025-02-28T07:12:51.912253Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"mm_dataset = transactions_prepared.join(clickstream_prepared, on='user_id', how='outer')\nmm_dataset.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:12:51.914468Z","iopub.execute_input":"2025-02-28T07:12:51.914758Z","iopub.status.idle":"2025-02-28T07:16:58.102227Z","shell.execute_reply.started":"2025-02-28T07:12:51.914733Z","shell.execute_reply":"2025-02-28T07:16:58.101198Z"}},"outputs":[{"name":"stdout","text":"+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|             user_id|      trx_event_time|            mcc_code|         currency_rk|     transaction_amt|    click_event_time|              cat_id|             new_uid|             level_0|             level_1|             level_2|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|0012e60b16f14da4b...|[1596253849, 1596...|[1, 23, 7, 1, 1, ...|[1, 1, 1, 1, 1, 1...|[-398.97632, -195...|[1611572447, 1611...|[29, 1, 27, 9, 9,...|[1439071, 1079747...|[26, 1, 25, 9, 9,...|[1, 1, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|\n|003d93fb918846ada...|[1596258479, 1596...|[5, 5, 8, 2, 29, ...|[1, 1, 1, 1, 1, 1...|[-3700.245, -928....|[1613300236, 1613...|[7, 13, 13, 4, 1,...|[557419, 557419, ...|[8, 12, 12, 4, 1,...|[1, 1, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|\n|004b3ef36faa40f08...|[1596270272, 1596...|[28, 3, 6, 6, 75,...|[1, 1, 1, 1, 1, 1...|[-98.54724, -265....|[1610996370, 1611...|[14, 4, 12, 40, 2...|[881028, 881028, ...|[13, 4, 5, 38, 2,...|[1, 1, 2, 1, 1, 2...|[1, 1, 1, 1, 1, 1...|\n|011d7da66de347b2b...|[1595944978, 1596...|[1, 41, 1, 1, 1, ...|[1, 1, 1, 1, 1, 1...|[-293.0613, -859....|[1611727191, 1611...|[1, 1, 1, 1, 1, 2...|[760873, 760873, ...|[1, 1, 1, 1, 1, 2...|[1, 1, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|\n|0184194d5e104a978...|[1601107139, 1601...|[2, 1, 1, 3, 57, ...|[1, 1, 1, 1, 1, 1...|[-150.85928, -128...|[1611808238, 1612...|[12, 12, 2, 6, 42...|[396565, 396565, ...|[5, 5, 2, 7, 40, ...|[2, 2, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"mm_dataset.write.mode('overwrite').parquet('./spark_data/mm_dataset.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:16:58.103302Z","iopub.execute_input":"2025-02-28T07:16:58.104281Z","iopub.status.idle":"2025-02-28T07:21:58.726814Z","shell.execute_reply.started":"2025-02-28T07:16:58.104252Z","shell.execute_reply":"2025-02-28T07:21:58.724728Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!mkdir spark_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:21:58.728794Z","iopub.execute_input":"2025-02-28T07:21:58.729484Z","iopub.status.idle":"2025-02-28T07:21:58.918376Z","shell.execute_reply.started":"2025-02-28T07:21:58.729450Z","shell.execute_reply":"2025-02-28T07:21:58.917579Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘spark_data’: File exists\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"mm_dataset_fold0, mm_dataset_fold1, mm_dataset_fold2,  mm_dataset_fold3, mm_dataset_fold4 = mm_dataset.randomSplit([0.2, 0.2, 0.2, 0.2, 0.2], seed=42)\nmm_dataset_fold0.write.mode('overwrite').parquet('./spark_data/mm_dataset_fold/fold=0')\nmm_dataset_fold1.write.mode('overwrite').parquet('./spark_data/mm_dataset_fold/fold=1')\n# mm_dataset_fold2.write.mode('overwrite').parquet('./spark_data/mm_dataset_fold/fold=2')\n# mm_dataset_fold3.write.mode('overwrite').parquet('./spark_data/mm_dataset_fold/fold=3')\nmm_dataset_fold4.write.mode('overwrite').parquet('./spark_data/mm_dataset_fold/fold=4')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:21:58.919587Z","iopub.execute_input":"2025-02-28T07:21:58.919937Z","iopub.status.idle":"2025-02-28T07:35:16.372784Z","shell.execute_reply.started":"2025-02-28T07:21:58.919883Z","shell.execute_reply":"2025-02-28T07:35:16.371568Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"spark.stop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:35:16.375455Z","iopub.execute_input":"2025-02-28T07:35:16.375844Z","iopub.status.idle":"2025-02-28T07:35:17.419878Z","shell.execute_reply.started":"2025-02-28T07:35:16.375813Z","shell.execute_reply":"2025-02-28T07:35:17.418919Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\nfrom datetime import datetime\nfrom ptls.data_load.padded_batch import PaddedBatch\n\nclass DeleteNan(IterableProcessingDataset):\n    def __init__(self, col_name):\n        super().__init__()\n        self.col_name = col_name\n    \n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            if features[self.col_name] is not None:\n                yield features\n\nclass TypeProc(IterableProcessingDataset):\n    def __init__(self, col_name, tp='float'):\n        super().__init__()\n        self.col_name = col_name\n        self.tp = tp\n\n    def __iter__(self):\n        for rec in self._src:\n            features = rec[0] if type(rec) is tuple else rec\n            if type(features[self.col_name]) is not str:\n                features[self.col_name] = np.array([float(val) if self.tp=='float' else int(float(val)) for val in features[self.col_name]])\n            else:\n                features[self.col_name] = float(features[self.col_name]) if self.tp=='float' else int(float(features[self.col_name]))\n            yield features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:40:36.877413Z","iopub.execute_input":"2025-02-28T07:40:36.877780Z","iopub.status.idle":"2025-02-28T07:40:36.884793Z","shell.execute_reply.started":"2025-02-28T07:40:36.877739Z","shell.execute_reply":"2025-02-28T07:40:36.883977Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"**Create dataset**","metadata":{}},{"cell_type":"code","source":"from ptls.data_load.datasets import ParquetDataset\nfrom ptls.data_load.iterable_processing.add_modal_name import AddModalName\nfrom ptls.data_load.iterable_processing import FeatureFilter, SeqLenFilter, ISeqLenLimit\nfrom ptls.data_load.iterable_processing.time_proc import TimeProcMultimodal\nfrom ptls.data_load.iterable_processing import ToTorch\ntrain = ParquetDataset(\n    shuffle_files=True,\n    data_files=[\n        './spark_data/mm_dataset_fold/fold=0',\n        './spark_data/mm_dataset_fold/fold=1',\n        # './spark_data/mm_dataset_fold/fold=2',\n        # './spark_data/mm_dataset_fold/fold=3'\n    ],\n    i_filters=[\n        DeleteNan(col_name='mcc_code'),\n        DeleteNan(col_name='cat_id'),\n        DeleteNan(col_name='user_id'),\n        TypeProc(col_name='transaction_amt'),\n        AddModalName(\n            source='trx',\n            cols=[\n                'mcc_code',\n                'currency_rk',\n                'transaction_amt'\n            ]\n        ),\n        AddModalName(\n            source='click',\n            cols=[\n                'cat_id',\n                'level_0',\n                'level_1',\n                'level_2'\n            ]\n        ),\n        FeatureFilter(drop_feature_names=[\n            'user_id',\n            'higher_education',\n            'new_uid'\n            ]\n        ),\n        SeqLenFilter(min_seq_len=32),\n        ISeqLenLimit(max_seq_len=4096),\n        TimeProcMultimodal(\n            source='trx',\n            time_col='trx_event_time'\n        ),\n        TimeProcMultimodal(\n            source='click',\n            time_col='click_event_time'\n        ),\n        ToTorch()\n    ]\n)\n\nvalid = ParquetDataset(\n    shuffle_files=True,\n    data_files=[\n        './spark_data/mm_dataset_fold/fold=4',\n    ],\n    i_filters=[\n        DeleteNan(col_name='mcc_code'),\n        DeleteNan(col_name='cat_id'),\n        DeleteNan(col_name='user_id'),\n        TypeProc(col_name='transaction_amt'),\n        AddModalName(\n            source='trx',\n            cols=[\n                'mcc_code',\n                'currency_rk',\n                'transaction_amt'\n            ]\n        ),\n        AddModalName(\n            source='click',\n            cols=[\n                'cat_id',\n                'level_0',\n                'level_1',\n                'level_2'\n            ]\n        ),\n        FeatureFilter(drop_feature_names=[\n            'user_id',\n            'higher_education',\n            'new_uid'\n            ]\n        ),\n        SeqLenFilter(min_seq_len=32),\n        ISeqLenLimit(max_seq_len=4096),\n        TimeProcMultimodal(\n            source='trx',\n            time_col='trx_event_time'\n        ),\n        TimeProcMultimodal(\n            source='click',\n            time_col='click_event_time'\n        ),\n        ToTorch()\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:40:38.459663Z","iopub.execute_input":"2025-02-28T07:40:38.459994Z","iopub.status.idle":"2025-02-28T07:40:38.467603Z","shell.execute_reply.started":"2025-02-28T07:40:38.459965Z","shell.execute_reply":"2025-02-28T07:40:38.466661Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# Create Dataset PTLS","metadata":{}},{"cell_type":"code","source":"from ptls.data_load.feature_dict import FeatureDict\nfrom ptls.frames.coles.split_strategy import AbsSplit\nfrom ptls.frames.coles.metric import metric_recall_top_K, outer_cosine_similarity, outer_pairwise_distance\n\nfrom ptls.frames.abs_module import ABSModule\nfrom ptls.frames.coles.losses import ContrastiveLoss\nfrom ptls.frames.coles.metric import BatchRecallTopK\nfrom ptls.frames.coles.sampling_strategies import HardNegativePairSelector\nfrom ptls.nn.head import Head\nfrom ptls.nn.seq_encoder.containers import SeqEncoderContainer\nfrom ptls.data_load.utils import collate_feature_dict\nfrom ptls.data_load.padded_batch import PaddedBatch\nimport torch\n\ndef collate_feature_dict(batch):\n    new_x_ = defaultdict(list)\n    for i, x in enumerate(batch):\n        for k, v in x.items():\n            new_x_[k].append(v)\n    \n    seq_col = next(k for k, v in batch[0].items() if FeatureDict.is_seq_feature(k, v))\n    lengths = torch.LongTensor([len(rec[seq_col]) for rec in batch])\n    new_x = {}\n    for k, v in new_x_.items():\n        if type(v[0]) is torch.Tensor:\n            if k.startswith('target'):\n                new_x[k] = torch.stack(v, dim=0)\n            else:\n                new_x[k] = torch.nn.utils.rnn.pad_sequence(v, batch_first=True)\n        elif type(v[0]) is np.ndarray:\n            new_x[k] = v  # list of arrays[object]\n        else:\n            v = np.array(v)\n            if v.dtype.kind == 'i':\n                new_x[k] = torch.from_numpy(v).long()\n            elif v.dtype.kind == 'f':\n                new_x[k] = torch.from_numpy(v).float()\n            elif v.dtype.kind == 'b':\n                new_x[k] = torch.from_numpy(v).bool()\n            else:\n                new_x[k] = v\n    return PaddedBatch(new_x, lengths)\n\ndef collate_multimodal_feature_dict(batch):\n    res = {}\n    for source, source_batch in batch.items():\n        res[source] = collate_feature_dict(source_batch)\n    return res\n    \ndef get_dict_class_labels(batch):\n    res = defaultdict(list)\n    for i, samples in enumerate(batch):\n        for source, values in samples.items():\n            for _ in values:\n                res[source].append(i)\n    for source in res:\n        res[source] = torch.LongTensor(res[source])\n    return dict(res)\n            \n\nclass MultiModalDiffSplitDataset(FeatureDict, torch.utils.data.Dataset):\n    def __init__(\n        self,\n        data,\n        splitters,\n        source_features,\n        col_id,\n        source_names,\n        col_time='event_time',\n        *args, **kwargs\n    ):\n        \"\"\"\n        Dataset for multimodal learning.\n        Parameters:\n        -----------\n        data:\n            concatinated data with feature dicts.\n        splitter:\n            object from from `ptls.frames.coles.split_strategy`.\n            Used to split original sequence into subsequences which are samples from one client.\n        source_features:\n            list of column names \n        col_id:\n            column name with user_id\n        source_names:\n            column name with name sources\n        col_time:\n            column name with event_time\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        \n        self.data = data\n        self.splitters = splitters\n        self.col_time = col_time\n        self.col_id = col_id\n        self.source_names = source_names\n        self.source_features = source_features\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        feature_arrays = self.data[idx]\n        split_data = self.split_source(feature_arrays)\n        return self.get_splits(split_data)\n    \n    def __iter__(self):\n        for feature_arrays in self.data:\n            split_data = self.split_source(feature_arrays)\n            yield self.get_splits(split_data)\n            \n    def split_source(self, feature_arrays):\n        res = defaultdict(dict)\n        for feature_name, feature_array in feature_arrays.items():\n            if feature_name == self.col_id:\n                res[self.col_id] = feature_array\n            else:\n                source_name, feature_name_transform = self.get_names(feature_name)\n                res[source_name][feature_name_transform] = feature_array\n        for source in self.source_names:\n            if source not in res:\n                res[source] = {source_feature: torch.tensor([]) for source_feature in self.source_features[source]}\n        return res\n    \n    def get_names(self, feature_name):\n        idx_del = feature_name.find('_')\n        return feature_name[:idx_del], feature_name[idx_del + 1:]\n    \n    def get_splits(self, feature_arrays):\n        res = {}\n        for source_name, feature_array in feature_arrays.items():\n            if source_name != self.col_id:\n                local_date = feature_array[self.col_time]\n                if source_name not in self.splitters:\n                    continue\n                indexes = self.splitters[source_name].split(local_date)\n                res[source_name] = [{k: v[ix] for k, v in feature_array.items() if self.is_seq_feature(k, v)} for ix in indexes]\n        return res\n        \n    def collate_fn(self, batch, return_dct_labels=False):\n        dict_class_labels = get_dict_class_labels(batch)\n        batch = reduce(lambda x, y: {k: x[k] + y[k] for k in x if k in y}, batch)\n        padded_batch = collate_multimodal_feature_dict(batch)\n        if return_dct_labels:\n            return padded_batch, dict_class_labels\n        return padded_batch, dict_class_labels[list(dict_class_labels.keys())[0]]\n\n    \nclass MultiModalDiffSplitIterableDataset(MultiModalDiffSplitDataset, torch.utils.data.IterableDataset):\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:40:40.024060Z","iopub.execute_input":"2025-02-28T07:40:40.024341Z","iopub.status.idle":"2025-02-28T07:40:40.041175Z","shell.execute_reply.started":"2025-02-28T07:40:40.024319Z","shell.execute_reply":"2025-02-28T07:40:40.040520Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from ptls.frames import PtlsDataModule\nfrom ptls.frames.coles.split_strategy import SampleSlices, NoSplit\n\ntrain_data = MultiModalDiffSplitIterableDataset(\n    splitters={\n        'trx': SampleSlices(\n            split_count=2,\n            cnt_min=32,\n            cnt_max=180\n            ),\n        'click': SampleSlices(\n            split_count=2,\n            cnt_min=32,\n            cnt_max=180\n        )\n    },\n    data=train,\n    source_features={\n        'trx': [\n            'mcc_code',\n            'currency_rk',\n            'transaction_amt',\n            'event_time',\n            'hour',\n            'weekday'\n        ],\n        'click': [\n            'cat_id',\n            'level_0',\n            'level_1',\n            'level_2',\n            'event_time',\n            'hour',\n            'weekday'\n        ]\n    },\n    col_id='user_id',\n    col_time='event_time',\n    source_names=[\n        'trx',\n        'click'\n    ]\n)\n\nvalid_data = MultiModalDiffSplitIterableDataset(\n    splitters={\n        'trx': NoSplit(),\n        'click': NoSplit()\n    },\n    data=valid,\n    source_features={\n        'trx': [\n            'mcc_code',\n            'currency_rk',\n            'transaction_amt',\n            'event_time',\n            'hour',\n            'weekday'\n        ],\n        'click': [\n            'cat_id',\n            'level_0',\n            'level_1',\n            'level_2',\n            'event_time',\n            'hour',\n            'weekday'\n        ]\n    },\n    col_id='user_id',\n    col_time='event_time',\n    source_names=[\n        'trx',\n        'click'\n    ]\n)\n\ndata_module = PtlsDataModule(\n    train_data=train_data,\n    valid_data=valid_data,\n    train_batch_size=64,\n    train_num_workers=8,\n    valid_batch_size=256,\n    valid_num_workers=8\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:40:46.107426Z","iopub.execute_input":"2025-02-28T07:40:46.107747Z","iopub.status.idle":"2025-02-28T07:40:46.114984Z","shell.execute_reply.started":"2025-02-28T07:40:46.107723Z","shell.execute_reply":"2025-02-28T07:40:46.114059Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def metric_real_recall_top_K(X, y, K, num_pos=1, metric='cosine'):\n    \"\"\"\n        calculate metric R@K\n        X - tensor with size n x d, where n - number of examples, d - size of embedding vectors\n        y - true labels\n        N - count of closest examples, which we consider for recall calcualtion\n        metric: 'cosine' / 'euclidean'.\n            !!! 'euclidean' - to slow for datasets bigger than 100K rows\n    \"\"\"\n    # TODO: take K from `y`\n    K_adjusted = min(X.size(0) - 1, K)\n    \n    res = []\n\n    n = X.size(0)\n    d = X.size(1)\n    max_size = 2 ** 32\n    batch_size = max(1, max_size // (n * d))\n\n    with torch.no_grad():\n\n        for i in range(1 + (len(X) - 1) // batch_size):\n\n            id_left = i * batch_size\n            id_right = min((i + 1) * batch_size, len(y))\n            y_batch = y[id_left:id_right]\n\n            if metric == 'cosine':\n                pdist = -1 * outer_cosine_similarity(X, X[id_left:id_right])\n            elif metric == 'euclidean':\n                pdist = outer_pairwise_distance(X, X[id_left:id_right])\n            else:\n                raise AttributeError(f'wrong metric \"{metric}\"')\n\n            values, indices = pdist.topk(K_adjusted + 1, 0, largest=False)\n\n            y_rep = y_batch.repeat(K_adjusted, 1)\n            res.append((y[indices[1:]] == y_rep).sum().item())\n\n    return np.sum(res) / len(y) / num_pos\n\ndef cosine_similarity_matrix(x1, x2):\n    x1_norm = x1 / x1.norm(dim=1)[:, None]\n    x2_norm = x2 / x2.norm(dim=1)[:, None]\n    return torch.mm(x1_norm, x2_norm.transpose(0, 1))\n\ndef metric_recall_top_K_for_embs(embs_1, embs_2, true_matches, K=100):\n    similarity_matrix = cosine_similarity_matrix(embs_1, embs_2)\n    K_adjusted = min(len(embs_1), K)\n    top_k = similarity_matrix.topk(k=K_adjusted, dim=1).indices\n    correct_matches = 0\n    for i, indices in enumerate(top_k):\n        if true_matches[i] in indices:\n            correct_matches += 1\n    recall_at_k = correct_matches / len(similarity_matrix)\n    return recall_at_k\n\nclass M3CoLESModule(ABSModule):\n    \"\"\"\n    Multi-Modal Matching\n    Contrastive Learning for Event Sequences ([CoLES](https://arxiv.org/abs/2002.08232))\n\n    Subsequences are sampled from original sequence.\n    Samples from the same sequence are `positive` examples\n    Samples from the different sequences are `negative` examples\n    Embeddings for all samples are calculated.\n    Paired distances between all embeddings are calculated.\n    The loss function tends to make positive distances smaller and negative ones larger.\n\n    Parameters\n        seq_encoder:\n            Model which calculate embeddings for original raw transaction sequences\n            `seq_encoder` is trained by `CoLESModule` to get better representations of input sequences\n        head:\n            Model which helps to train. Not used during inference\n            Can be normalisation layer which make embedding l2 length equals 1\n            Can be MLP as `projection head` like in SymCLR framework.\n        loss:\n            loss object from `ptls.frames.coles.losses`.\n            There are paired and triplet loss. They are required sampling strategy\n            from `ptls.frames.coles.sampling_strategies`. Sampling strategy takes a relevant pairs or triplets from\n            pairwise distance matrix.\n        validation_metric:\n            Keep None. `ptls.frames.coles.metric.BatchRecallTopK` used by default.\n        optimizer_partial:\n            optimizer init partial. Network parameters are missed.\n        lr_scheduler_partial:\n            scheduler init partial. Optimizer are missed.\n\n    \"\"\"\n    def __init__(self,\n                 seq_encoders=None,\n                 mod_names=None,\n                 head=None,\n                 loss=None,\n                 validation_metric=None,\n                 optimizer_partial=None,\n                 lr_scheduler_partial=None):\n        torch.set_float32_matmul_precision('high')\n        if head is None:\n            head = Head(use_norm_encoder=True)\n\n        if loss is None:\n            loss = ContrastiveLoss(margin=0.5,\n                                   sampling_strategy=HardNegativePairSelector(neg_count=5))\n\n        if validation_metric is None:\n            validation_metric = BatchRecallTopK(K=4, metric='cosine')\n        \n        for k in seq_encoders.keys():\n            if type(seq_encoders[k]) is str:\n                seq_encoders[k] = seq_encoders[seq_encoders[k]]\n                \n        super().__init__(validation_metric,\n                         first(seq_encoders.values()),\n                         loss,\n                         optimizer_partial,\n                         lr_scheduler_partial)\n        \n        self.seq_encoders = torch.nn.ModuleDict(seq_encoders)\n        self._head = head   \n        self.y_h_cache = {'train':[], 'valid': []}\n        \n    @property\n    def metric_name(self):\n        return 'recall_top_k'\n\n    @property\n    def is_requires_reduced_sequence(self):\n        return True\n    \n    def forward(self, x):\n        res = {}\n        \n        for mod_name in x.keys():\n            res[mod_name] = self.seq_encoders[mod_name](x[mod_name])\n            \n        return res\n\n    def shared_step(self, x, y):\n        y_h = self(x)\n        \n        if self._head is not None:\n            y_h_head = {k: self._head(y_h_k) for k, y_h_k in y_h.items()}\n            y_h = y_h_head\n            \n        return y_h, y\n    \n    def _one_step(self, batch, _, stage):\n        y_h, y = self.shared_step(*batch)\n        y_h_list = list(y_h.values())\n        loss = self._loss(torch.cat(y_h_list), torch.cat([y, y]))\n        self.log(f'loss/{stage}', loss.detach())\n        \n        x, y = batch\n        for mod_name, mod_x in x.items():\n            self.log(f'seq_len/{stage}/{mod_name}', x[mod_name].seq_lens.float().mean().detach(), prog_bar=True)\n        \n        if stage == \"valid\":\n            n, d = y_h_list[0].shape\n            y_h_concat = torch.zeros((2*n, d), device = y_h_list[0].device)\n            \n            for i in range(2):\n                y_h_concat[range(i,2*n,2)] = y_h_list[i] \n            \n            if len(self.y_h_cache[stage]) <= 380:\n                self.y_h_cache[stage].append((y_h_concat.cpu(), {k: y_h_k.cpu() for k, y_h_k in y_h.items()} , \n                                             {k:x_k.seq_lens.cpu() for k, x_k in x.items()})) \n    \n        return loss\n    \n    def training_step(self, batch, _):\n        return self._one_step(batch, _, \"train\")\n    \n    def validation_step(self, batch, _):\n        return self._one_step(batch, _, \"valid\")\n    \n    def on_validation_epoch_end(self):        \n        #len_intervals = [(0, 10), (10, 20), (20, 30), (30, 40), (40, 60), (60, 80), (80, 120), (120, 160), (160, 240)]\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=100)\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=50)\n        self.log_recall_top_K(self.y_h_cache['valid'], len_intervals=None, stage=\"valid\", K=1)\n        \n        \n        del self.y_h_cache[\"valid\"]\n        self.y_h_cache[\"valid\"] = []\n        \n    def log_recall_top_K(self, y_h_cache, len_intervals=None, stage=\"valid\", K=100):\n        y_h = torch.cat([item[0] for item in y_h_cache], dim = 0)\n        y_h_mods = defaultdict(list)\n        seq_lens_dict = defaultdict(list)\n        \n        for item in y_h_cache:\n            for k, emb in item[1].items():\n                y_h_mods[k].append(emb)\n                \n            for k, l in item[2].items():\n                seq_lens_dict[k].append(l)\n        \n        y_h_mods = {k: torch.cat(el, dim=0) for k ,el in y_h_mods.items()}\n        seq_lens_dict = {k: torch.cat(el) for k ,el in seq_lens_dict.items()}\n\n        #n, _ = y_h.shape\n        #y = torch.zeros((n,)).cpu().long()\n        #y[range(0,n,2)] = torch.arange(0, n//2)\n        #y[range(1,n,2)] = torch.arange(0, n//2)\n        #computed_metric = metric_real_recall_top_K(y_h, y, K=100)\n        y_h_bank, y_h_rmb = list(y_h_mods.values())\n        computed_metric_b2r = metric_recall_top_K_for_embs(y_h_bank, y_h_rmb, torch.arange(y_h_rmb.shape[0]), K=K)\n        computed_metric_r2b = metric_recall_top_K_for_embs(y_h_rmb, y_h_bank, torch.arange(y_h_rmb.shape[0]), K=K)\n        \n        if len_intervals != None:\n            for mod, seq_lens in seq_lens_dict.items():\n                for start, end in len_intervals:\n                    mask = ((seq_lens > start) & (seq_lens <= end))\n\n                    if torch.any(mask):\n                        #y_h_filtered = y_h[mask.repeat_interleave(2)]\n                        y_h_bank_filtered = y_h_bank[mask]\n                        y_h_rmb_filtered = y_h_rmb[mask]\n\n                        #y = torch.div(torch.arange(len(y_h_filtered)), 2, rounding_mode='floor')\n                        #recall = metric_real_recall_top_K(y_h_filtered, y, K=100)\n                        recall_r2b = metric_recall_top_K_for_embs(y_h_rmb_filtered, y_h_bank_filtered, torch.arange(y_h_rmb_filtered.shape[0]), K=100)\n                        recall_b2r = metric_recall_top_K_for_embs(y_h_bank_filtered, y_h_rmb_filtered, torch.arange(y_h_rmb_filtered.shape[0]), K=100)\n\n                        #self.log(f\"{mode}/R@100_len_from_{start}_to_{end}\", recall, prog_bar=True)\n                        self.log(f\"{stage}/{mod}/r2b_R@100_len_from_{start}_to_{end}\", recall_r2b, prog_bar=True)\n                        self.log(f\"{stage}/{mod}/b2r_R@100_len_from_{start}_to_{end}\", recall_b2r, prog_bar=True)\n        \n        #self.log(f\"{mode}/R@100\", computed_metric, prog_bar=True)\n        self.log(f\"{stage}/click2trx_R@{K}\", computed_metric_r2b, prog_bar=True)\n        self.log(f\"{stage}/trx2click_R@{K}\", computed_metric_b2r, prog_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T08:18:53.011526Z","iopub.execute_input":"2025-02-28T08:18:53.011876Z","iopub.status.idle":"2025-02-28T08:18:53.034594Z","shell.execute_reply.started":"2025-02-28T08:18:53.011848Z","shell.execute_reply":"2025-02-28T08:18:53.033746Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"from ptls.frames.coles.losses import SoftmaxLoss\nfrom ptls.frames.coles.metric import BatchRecallTopK\nfrom functools import partial\n\ndef first(iterable, default=None):\n    iterator = iter(iterable)\n    return next(iterator, default)\n\nhead = ptls.nn.Head(\n        input_size=128,\n        use_norm_encoder=True,\n        hidden_layers_sizes=[128, 128],\n        objective='regression',\n        num_classes=128\n    )\n\nseq_encoders = {\n    'trx': ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            norm_embeddings=False,\n            embeddings_noise=0.003,\n            embeddings={\n                'mcc_code': {\n                    'in': 350,\n                    'out': 64\n                },\n                'currency_rk': {\n                    'in': 10,\n                    'out': 4,\n                },\n                'hour': {\n                    'in': 25,\n                    'out': 16\n                },\n                'weekday': {\n                    'in': 8,\n                    'out': 4\n                }\n            },\n            numeric_values={'transaction_amt': 'log'}\n        ),\n        type='gru',\n        hidden_size=128\n    ),\n    'click': ptls.nn.RnnSeqEncoder(\n        trx_encoder=ptls.nn.TrxEncoder(\n            embeddings_noise=0.003,\n            embeddings={\n                'cat_id': {\n                    'in': 400,\n                    'out':64\n                },\n                'level_0': {\n                    'in': 400,\n                    'out': 16\n                },\n                'level_1': {\n                    'in': 400,\n                    'out': 8\n                },\n                'level_2': {\n                    'in': 400,\n                    'out': 4\n                },\n                'hour': {\n                    'in': 25,\n                    'out': 16\n                },\n                'weekday': {\n                    'in': 8,\n                    'out': 4\n                }\n            }\n        ),\n        type='gru',\n        hidden_size=128\n    )\n}\n\npl_module = M3CoLESModule(\n    validation_metric=BatchRecallTopK(\n        K=1,\n        metric='cosine'\n    ),\n    head=head,\n    seq_encoders=seq_encoders,\n    loss=SoftmaxLoss(),\n    optimizer_partial=partial(torch.optim.AdamW, lr=0.001, weight_decay=1e-4),\n    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=1, gamma=0.9)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T08:18:54.431578Z","iopub.execute_input":"2025-02-28T08:18:54.431871Z","iopub.status.idle":"2025-02-28T08:18:54.448659Z","shell.execute_reply.started":"2025-02-28T08:18:54.431849Z","shell.execute_reply":"2025-02-28T08:18:54.447975Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import pytorch_lightning as pl\n\ntrainer = pl.Trainer(\n    max_epochs=50,\n    accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    enable_progress_bar=True,\n    gradient_clip_val=0.5,\n    log_every_n_steps=50,\n    limit_val_batches=36\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T08:18:54.580449Z","iopub.execute_input":"2025-02-28T08:18:54.580682Z","iopub.status.idle":"2025-02-28T08:18:54.622283Z","shell.execute_reply.started":"2025-02-28T08:18:54.580662Z","shell.execute_reply":"2025-02-28T08:18:54.621643Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"**На COLES mrr ~0.011, на 2-х фолдах**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom collections import defaultdict\nfrom functools import reduce\n\ntrainer.fit(pl_module, data_module)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T08:18:54.783218Z","iopub.execute_input":"2025-02-28T08:18:54.783458Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6923af4fb35d4c7c9eeeecba848e578c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f62db3c899401fa4776cbcf9a531c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b76cd28d05e408fa09313a820691f72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2a2adcd04184d83b4bed2a610f59ed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bbcf39ce1104221908bf7b05d53fe42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a7a60f0f2f4b4796feeec4fecf6deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7732c3f65d4a0aa300d8b9194473ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3362679eb34b3facb8a215142f31ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a23898a389e247c2b0d9d55f639f4885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c10d592aec44399aae3c1907a829f3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478dd7cbf5e944db83abfba2fdeaad3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46578d4f8d21420598ec4186c7953b6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5187f1c844f34ea5bdce94a87558a9a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe94d0cfcbc846289ff29904c1a5e4f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e54fe9849573463089863460ab244336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8a8b5f82b043769d4e691a141fd30c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55fd87e0d26c463b942ee8ebca47a7df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7f2e3347f7f4f0f90dabc747682bed5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28259a53f3841cea2a93c7fa90a9221"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97e22ea1ae44d8e8d8ee8200d1998f4"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a649373f3f84ed79e98c8e4bdfc52c1"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a5f1367cca4f96a2b5af4130e016b6"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dda71b0952b45f3a6048d9e77c30e16"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ebd537e6a64ceb9ee48666c9dc86f4"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d9a57ada200>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}